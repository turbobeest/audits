# ============================================================
# AUDIT FILE TEMPLATE - BLANK SLATE v2.0
# ============================================================
#
# GUIDANCE FOR AUDIT AUTHORS (HUMAN OR AI):
#
# This template is DOMAIN-AGNOSTIC. The structure adapts to:
# - Code/security audits (grep patterns, static analysis)
# - Infrastructure audits (metrics queries, config checks)  
# - Organizational audits (interviews, surveys, document review)
# - Process audits (checklist verification, artifact existence)
# - Qualitative audits (expert judgment, heuristic evaluation)
#
# NOT ALL SECTIONS APPLY TO ALL AUDITS:
# - Bash verification commands work for code/config audits
# - Organizational audits may use interview questions instead
# - Some audits have no automation - that's valid (automatable: "manual")
#
# ADAPT THE STRUCTURE TO THE DOMAIN - don't force-fit patterns.
#
# ============================================================

# ============================================================
# SECTION 1: IDENTITY & METADATA
# ============================================================

audit:
  # Hierarchical ID: {category-id}.{subcategory-id}.{audit-slug}
  id: "{category-id}.{subcategory-id}.{audit-slug}"              # [REQUIRED]
  
  name: "{Human-Readable Audit Name}"                            # [REQUIRED]
  
  version: "1.0.0"                                               # [REQUIRED]
  last_updated: "{YYYY-MM-DD}"                                   # [REQUIRED]
  status: "active"                                               # [REQUIRED] active|draft|deprecated|archived
  
  # Taxonomy placement
  category: "{category-id}"                                      # [REQUIRED]
  category_number: 0                                             # [REQUIRED] 1-43
  subcategory: "{subcategory-id}"                                # [REQUIRED]
  
  # Complexity
  tier: "expert"                                                 # [REQUIRED] focused|expert|phd
  estimated_duration: "{X hours/minutes}"                        # [OPTIONAL]
  
  # Execution characteristics
  completeness: "complete"                                       # [REQUIRED] complete|requires_discovery
  requires_runtime: false                                        # [REQUIRED] Does this need a running system?
  destructive: false                                             # [REQUIRED] Could this modify state?

# ============================================================
# SECTION 2: EXECUTION CLASSIFICATION
# ============================================================

execution:
  # How much can be automated?
  # - "yes": Fully automatable with tooling
  # - "partial": Some automated, some judgment required
  # - "manual": Requires human/LLM analysis, interviews, or expert review
  automatable: "partial"                                         # [REQUIRED]
  
  severity: "high"                                               # [REQUIRED] critical|high|medium|low
  
  # What type of artifact does this audit examine?
  # Options: prd|architecture|codebase|config|testing|security|
  #          deployment|runtime|documentation|process|organizational|
  #          infrastructure|data|metrics|qualitative
  scope: "{scope-type}"                                          # [REQUIRED]
  
  default_profiles:                                              # [REQUIRED]
    - "full"
    # Add others as appropriate: quick|security|production
    
  blocks_phase: false                                            # [OPTIONAL]
  parallelizable: true                                           # [OPTIONAL]

# ============================================================
# SECTION 3: DESCRIPTION & RATIONALE
# ============================================================

description:
  what: |                                                        # [REQUIRED]
    {What this audit examines. Be specific about scope,
    artifacts reviewed, and analysis performed.}
    
  why_it_matters: |                                              # [REQUIRED]
    {Business/technical impact of issues in this area.
    What goes wrong if this is neglected?}
    
  when_to_run:                                                   # [OPTIONAL]
    - "{Trigger condition 1}"
    - "{Trigger condition 2}"

# ============================================================
# SECTION 4: PREREQUISITES
# ============================================================

prerequisites:
  required_artifacts:                                            # [CONDITIONAL]
    # What must exist before this audit can run?
    # Examples vary by domain:
    # - Code audits: "Source code access"
    # - Org audits: "Team roster", "Org chart"
    # - Process audits: "Runbook repository", "Incident history"
    - type: "{artifact-type}"
      description: "{What is needed}"
      
  access_requirements:                                           # [OPTIONAL]
    - "{Access needed - code repo, metrics system, people for interviews, etc.}"

# ============================================================
# SECTION 5: DISCOVERY SPECIFICATION
# ============================================================
# ADAPT THIS SECTION TO YOUR DOMAIN:
# - Code audits: code_patterns, file_patterns
# - Org audits: people to interview, documents to review
# - Metrics audits: queries to run, dashboards to examine

discovery:
  # FOR CODE/CONFIG AUDITS:
  code_patterns:                                                 # [CONDITIONAL]
    - pattern: "{regex or keyword}"
      type: "regex"                                              # regex|keyword|ast
      scope: "{source|config|docs}"
      purpose: "{Why we're looking for this}"
      
  file_patterns:                                                 # [CONDITIONAL]
    - glob: "{**/pattern/**}"
      purpose: "{What we expect to find}"
      
  # FOR ORGANIZATIONAL/QUALITATIVE AUDITS:
  interviews:                                                    # [CONDITIONAL]
    - role: "{Who to interview - e.g., 'Service owners', 'On-call engineers'}"
      questions:
        - "{Interview question 1}"
        - "{Interview question 2}"
      purpose: "{What we're trying to learn}"
      
  documents_to_review:                                           # [CONDITIONAL]
    - type: "{Document type - runbook, org chart, meeting notes, etc.}"
      purpose: "{What we're looking for}"
      
  # FOR METRICS/INFRASTRUCTURE AUDITS:
  metrics_queries:                                               # [CONDITIONAL]
    - system: "{Prometheus, CloudWatch, Datadog, etc.}"
      query: "{PromQL, SQL, or query syntax}"
      purpose: "{What this tells us}"
      threshold: "{Expected value or range}"

# ============================================================
# SECTION 6: EXTERNAL KNOWLEDGE SOURCES
# ============================================================
# What external references inform this audit?
# Adapt to domain - not everything has RFCs!

knowledge_sources:
  # Standards, specifications, regulatory documents
  specifications:                                                # [OPTIONAL]
    - id: "{short-id}"
      name: "{Full name}"
      url: "{URL}"
      offline_cache: true
      priority: "required"                                       # required|recommended|optional
      
  # Best practice guides, industry resources
  guides:                                                        # [OPTIONAL]
    - id: "{short-id}"
      name: "{Guide name}"
      url: "{URL}"
      offline_cache: true
      
  # Academic research, case studies
  papers:                                                        # [OPTIONAL]
    - id: "{short-id}"
      title: "{Paper title}"
      url: "{URL}"
      
  # Books, courses, training materials
  learning_resources:                                            # [OPTIONAL]
    - id: "{short-id}"
      title: "{Resource title}"
      type: "book"                                               # book|course|video|article
      reference: "{ISBN, URL, or citation}"

# ============================================================
# SECTION 7: TOOLING & AUTOMATION
# ============================================================
# ADAPT TO DOMAIN - not all audits use static analysis!

tooling:
  # FOR CODE AUDITS: Static analysis, linters
  static_analysis:                                               # [OPTIONAL]
    - tool: "{tool name}"
      purpose: "{What it checks}"
      offline_capable: true
      
  # FOR INFRASTRUCTURE AUDITS: Cloud tools, kubectl, terraform
  infrastructure_tools:                                          # [OPTIONAL]
    - tool: "{tool name}"
      purpose: "{What it checks}"
      command: "{Example command}"
      
  # FOR METRICS AUDITS: Monitoring queries
  monitoring_queries:                                            # [OPTIONAL]
    - system: "{Monitoring system}"
      query: "{Query}"
      purpose: "{What it reveals}"
      
  # FOR ORGANIZATIONAL AUDITS: Survey tools, analysis frameworks
  assessment_tools:                                              # [OPTIONAL]
    - tool: "{Survey tool, assessment framework, etc.}"
      purpose: "{How it's used}"
      
  # Universal: Custom scripts
  scripts:                                                       # [OPTIONAL]
    - id: "{script-id}"
      language: "{python|bash|etc}"
      purpose: "{What it does}"
      source: "inline"
      code: |
        # Script content
        pass

# ============================================================
# SECTION 8: SIGNALS & FINDINGS TAXONOMY
# ============================================================
# What findings might this audit produce?
# ADAPT EVIDENCE PATTERNS TO DOMAIN

signals:
  critical:                                                      # [REQUIRED - at least describe what critical means]
    - id: "{CATEGORY-CRIT-001}"
      signal: "{Description of critical finding}"
      # FOR CODE AUDITS:
      evidence_pattern: "{What to grep/search for}"
      # FOR ORG AUDITS:
      evidence_indicators: 
        - "{Observable indicator 1}"
        - "{Observable indicator 2}"
      # FOR METRICS AUDITS:
      evidence_threshold: "{Metric > X or < Y}"
      explanation: |
        {Why this is critical - impact and risk}
      remediation: "{How to fix}"
      
  high:                                                          # [REQUIRED]
    - id: "{CATEGORY-HIGH-001}"
      signal: "{Description}"
      explanation: "{Why it matters}"
      remediation: "{How to fix}"
      
  medium:                                                        # [REQUIRED]
    - id: "{CATEGORY-MED-001}"
      signal: "{Description}"
      remediation: "{How to fix}"
      
  low:                                                           # [OPTIONAL]
    - id: "{CATEGORY-LOW-001}"
      signal: "{Description}"
      
  positive:                                                      # [OPTIONAL]
    - id: "{CATEGORY-POS-001}"
      signal: "{Evidence of good practice}"

# ============================================================
# SECTION 9: EXECUTION PROCEDURE
# ============================================================

procedure:
  context:
    cognitive_mode: "critical"                                   # [REQUIRED] informative|critical|evaluative
    ensemble_role: "auditor"                                     # [REQUIRED]
    
  steps:                                                         # [REQUIRED]
    - id: "1"
      name: "{Step name}"
      description: |
        {What to do in this step}
      duration_estimate: "{X min}"
      
      # FOR CODE/CONFIG AUDITS - commands to run:
      commands:                                                  # [OPTIONAL]
        - purpose: "{What this reveals}"
          command: "{bash command}"
          
      # FOR ORGANIZATIONAL AUDITS - questions to answer:
      questions:                                                 # [OPTIONAL]
        - "{Question to investigate}"
        
      # FOR ALL - what we expect to learn:
      expected_findings:
        - "{What this step should reveal}"

# ============================================================
# SECTION 10: OUTPUT SPECIFICATION
# ============================================================

output:
  deliverables:                                                  # [REQUIRED]
    - type: "finding_list"
      format: "structured"
      
    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Key Findings"
        - "Recommendations"
        
  confidence_guidance:                                           # [REQUIRED]
    high: "Direct evidence observed, verified through multiple methods"
    medium: "Strong indicators present, limited verification possible"
    low: "Circumstantial evidence or inference-based"

# ============================================================
# SECTION 11: OFFLINE SUPPORT
# ============================================================

offline:
  capability: "full"                                             # [REQUIRED] full|partial|online_only
  
  cache_manifest:                                                # [CONDITIONAL]
    knowledge:
      - source_id: "{knowledge-source-id}"
        priority: "required"

# ============================================================
# SECTION 12: PROFILES
# ============================================================

profiles:
  membership:                                                    # [REQUIRED]
    quick:
      included: false
      reason: "{Why not in quick profile, or remove if included}"
    full:
      included: true
      priority: 1

# ============================================================
# SECTION 13: DETERMINISTIC VERIFICATION
# ============================================================
# IMPORTANT: Not all audits have bash verification!
#
# FOR CODE/CONFIG AUDITS: Use bash commands
# FOR ORG/QUALITATIVE AUDITS: Use checklist items verified by human review
# FOR METRICS AUDITS: Use threshold checks

closeout_checklist:                                              # [REQUIRED]
  # CODE AUDIT EXAMPLE:
  - id: "{audit-slug}-001"
    item: "{What is being verified}"
    level: "CRITICAL"                                            # CRITICAL|BLOCKING|WARNING
    verification: "{bash command that outputs PASS or FAIL}"
    expected: "PASS"
    
  # ORGANIZATIONAL AUDIT EXAMPLE (human-verified):
  - id: "{audit-slug}-002"
    item: "{What is being verified}"
    level: "BLOCKING"
    verification: "manual"                                       # Indicates human review required
    verification_notes: "{What the reviewer should confirm}"
    expected: "Confirmed by reviewer"
    
  # METRICS AUDIT EXAMPLE:
  - id: "{audit-slug}-003"
    item: "{What is being verified}"
    level: "WARNING"
    verification: "{metrics query or API call}"
    threshold: "{> X or < Y}"

# ============================================================
# SECTION 14: GOVERNANCE
# ============================================================

governance:
  applicable_to:                                                 # [OPTIONAL]
    archetypes: ["all"]                                          # Or specific types
    
  compliance_frameworks:                                         # [OPTIONAL]
    - framework: "{Framework name}"
      controls: ["{Control IDs}"]

# ============================================================
# SECTION 15: RELATIONSHIPS
# ============================================================

relationships:
  commonly_combined:                                             # [OPTIONAL]
    - "{related-audit-id}"

# ============================================================
# SECTION 16: SDLC PHASE APPLICABILITY
# ============================================================
# Which software development lifecycle phases does this audit apply to?
# Set each phase to true if the audit is relevant during that phase.

sdlc_phases:
  discovery: false                                               # [REQUIRED] Initial project discovery
  prd: false                                                     # [REQUIRED] Product requirements definition
  task_decomposition: false                                      # [REQUIRED] Breaking down work
  specification: true                                            # [REQUIRED] Technical specification
  implementation: true                                           # [REQUIRED] Active development
  testing: true                                                  # [REQUIRED] QA and testing
  integration: true                                              # [REQUIRED] System integration
  deployment: true                                               # [REQUIRED] Deployment and release
  post_production: true                                          # [REQUIRED] Production monitoring
