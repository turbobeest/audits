# Semantic Meta-Audit for Categories 36-43
# Generated: 2026-01-24
# Auditor: LLM Evaluation (Claude Opus 4.5)
# Focus: Issues a regex/script would MISS

semantic_audit:
  categories:
    - "36-internationalization-localization"
    - "37-machine-learning-ai"
    - "38-sensors-physical-systems"
    - "39-real-time-embedded"
    - "40-signal-processing-data-acquisition"
    - "41-blockchain-distributed-ledger"
    - "42-quantum-computing"
    - "43-metaverse-immersive"

  audits_evaluated: 323

  category_counts:
    "36-internationalization-localization": 51
    "37-machine-learning-ai": 51
    "38-sensors-physical-systems": 53
    "39-real-time-embedded": 52
    "40-signal-processing-data-acquisition": 36
    "41-blockchain-distributed-ledger": 38
    "42-quantum-computing": 27
    "43-metaverse-immersive": 43

  findings:
    # =====================================================================
    # CLARITY ISSUES
    # =====================================================================

    - audit_id: "quantum-computing.error-handling.error-correction-code"
      file: "/mnt/walnut-drive/dev/audits/audits/42-quantum-computing/error-handling/error-correction-code.yaml"
      dimension: "clarity"
      severity: "high"
      issue: "Description assumes deep quantum computing expertise without explanation"
      recommendation: |
        The audit mentions 'stabilizer', 'syndrome measurement', 'decoder', 'logical error rate'
        without explaining these concepts. Add a brief glossary or inline definitions for key
        quantum error correction terminology. A non-QEC expert auditor would struggle to
        understand what they're evaluating.

    - audit_id: "signal-processing.filtering.adaptive-filter"
      file: "/mnt/walnut-drive/dev/audits/audits/40-signal-processing-data-acquisition/filtering/adaptive-filter.yaml"
      dimension: "clarity"
      severity: "medium"
      issue: "Signal patterns use unexplained abbreviations and formulas"
      recommendation: |
        The signal mentions 'LMS stability requires mu < 2/(N*Pmax)' without explaining what
        mu, N, or Pmax represent. Add parameter explanations: mu = step size, N = filter length,
        Pmax = maximum input power. DSP jargon should be defined for non-specialists.

    - audit_id: "real-time-embedded.timing-analysis.wcet-analysis"
      file: "/mnt/walnut-drive/dev/audits/audits/39-real-time-embedded/wcet-analysis.yaml"
      dimension: "clarity"
      severity: "medium"
      issue: "WCET concept not explained for those unfamiliar with real-time systems"
      recommendation: |
        While 'Worst-Case Execution Time' is expanded, the audit doesn't explain WHY this matters
        for real-time systems or the consequence of underestimation vs overestimation. Add a
        practical explanation connecting WCET to deadline misses and system failure modes.

    - audit_id: "blockchain.governance.timelock"
      file: "/mnt/walnut-drive/dev/audits/audits/41-blockchain-distributed-ledger/governance/timelock.yaml"
      dimension: "clarity"
      severity: "low"
      issue: "Governance-specific terminology assumes blockchain familiarity"
      recommendation: |
        Terms like 'queue and execution flow', 'emergency operations', 'guardian cancel' assume
        familiarity with DAO governance patterns. Briefly explain the timelock's role in
        preventing malicious governance proposals from executing immediately.

    - audit_id: "metaverse-immersive.rendering-performance.latency-motion-to-photon"
      file: "/mnt/walnut-drive/dev/audits/audits/43-metaverse-immersive/rendering-performance/latency-motion-to-photon.yaml"
      dimension: "clarity"
      severity: "low"
      issue: "Timewarp/spacewarp mentioned without explanation"
      recommendation: |
        The audit references 'timewarp/spacewarp' as a mitigation technique but doesn't explain
        what these are. Add brief explanation: 'timewarp rotates the rendered frame to match
        the latest head pose, compensating for render latency'.

    - audit_id: "sensors-physical-systems.safety-systems.emergency-stop-coverage"
      file: "/mnt/walnut-drive/dev/audits/audits/38-sensors-physical-systems/safety-systems/emergency-stop-coverage.yaml"
      dimension: "clarity"
      severity: "medium"
      issue: "Stop categories (0, 1, 2) referenced without definition"
      recommendation: |
        The audit mentions 'stop categories' per ISO 13850 but doesn't define them. Add definitions:
        Category 0 = immediate power removal, Category 1 = controlled stop then power removal,
        Category 2 = controlled stop with power maintained. Critical for understanding hazard mitigation.

    # =====================================================================
    # ALIGNMENT ISSUES
    # =====================================================================

    - audit_id: "signal-processing.filtering.adaptive-filter"
      file: "/mnt/walnut-drive/dev/audits/audits/40-signal-processing-data-acquisition/filtering/adaptive-filter.yaml"
      dimension: "alignment"
      severity: "medium"
      issue: "ID prefix 'signal-processing' doesn't match category 'signal-processing-data-acquisition'"
      recommendation: |
        The audit ID uses 'signal-processing.filtering.adaptive-filter' but the category is
        'signal-processing-data-acquisition'. Update the ID prefix to match the full category
        name for consistency: 'signal-processing-data-acquisition.filtering.adaptive-filter'.

    - audit_id: "signal-processing.adc-dac.adc-linearity"
      file: "/mnt/walnut-drive/dev/audits/audits/40-signal-processing-data-acquisition/adc-dac/adc-linearity.yaml"
      dimension: "alignment"
      severity: "medium"
      issue: "ID prefix 'signal-processing' should be 'signal-processing-data-acquisition'"
      recommendation: |
        Update audit ID from 'signal-processing.adc-dac.adc-linearity' to
        'signal-processing-data-acquisition.adc-dac.adc-linearity' to match category naming.

    - audit_id: "signal-processing.spectral-analysis.fft-implementation"
      file: "/mnt/walnut-drive/dev/audits/audits/40-signal-processing-data-acquisition/spectral-analysis/fft-implementation.yaml"
      dimension: "alignment"
      severity: "medium"
      issue: "ID prefix inconsistent with category naming convention"
      recommendation: |
        The ID uses shortened 'signal-processing' but category is 'signal-processing-data-acquisition'.
        Align IDs with full category name for cross-category consistency.

    - audit_id: "blockchain.smart-contract-security.reentrancy-vulnerability"
      file: "/mnt/walnut-drive/dev/audits/audits/41-blockchain-distributed-ledger/smart-contract-security/reentrancy-vulnerability.yaml"
      dimension: "alignment"
      severity: "medium"
      issue: "ID prefix 'blockchain' doesn't match category 'blockchain-distributed-ledger'"
      recommendation: |
        Update audit ID from 'blockchain.smart-contract-security.reentrancy-vulnerability' to
        'blockchain-distributed-ledger.smart-contract-security.reentrancy-vulnerability'.

    - audit_id: "blockchain.governance.timelock"
      file: "/mnt/walnut-drive/dev/audits/audits/41-blockchain-distributed-ledger/governance/timelock.yaml"
      dimension: "alignment"
      severity: "medium"
      issue: "ID prefix uses shortened form inconsistent with category"
      recommendation: |
        The category is 'blockchain-distributed-ledger' but ID uses 'blockchain.governance.timelock'.
        Update to 'blockchain-distributed-ledger.governance.timelock' for consistency.

    - audit_id: "blockchain.smart-contract-security.oracle-manipulation"
      file: "/mnt/walnut-drive/dev/audits/audits/41-blockchain-distributed-ledger/smart-contract-security/oracle-manipulation.yaml"
      dimension: "alignment"
      severity: "medium"
      issue: "ID prefix mismatch with category naming"
      recommendation: |
        Standardize ID to 'blockchain-distributed-ledger.smart-contract-security.oracle-manipulation'.

    - audit_id: "sensors-physical-systems.data-acquisition.adc-resolution-accuracy"
      file: "/mnt/walnut-drive/dev/audits/audits/38-sensors-physical-systems/data-acquisition/adc-resolution-accuracy.yaml"
      dimension: "alignment"
      severity: "low"
      issue: "ADC content overlaps with category 40 signal-processing-data-acquisition"
      recommendation: |
        There are ADC-related audits in both category 38 (adc-resolution-accuracy) and category 40
        (adc-linearity, adc-resolution-adequacy). Consider cross-referencing or clarifying the
        distinction: cat-38 focuses on physical hardware, cat-40 on signal processing aspects.

    - audit_id: "quantum-computing.error-handling.error-correction-code"
      file: "/mnt/walnut-drive/dev/audits/audits/42-quantum-computing/error-handling/error-correction-code.yaml"
      dimension: "alignment"
      severity: "low"
      issue: "Tier 'phd' is appropriate but should be noted as exceptional"
      recommendation: |
        This audit correctly uses 'phd' tier - one of the few audits at this level. The complexity
        of QEC genuinely requires PhD-level expertise. Consider adding an explanation of why this
        tier is necessary in the audit description.

    # =====================================================================
    # AGENT-READINESS ISSUES
    # =====================================================================

    - audit_id: "sensors-physical-systems.safety-systems.emergency-stop-coverage"
      file: "/mnt/walnut-drive/dev/audits/audits/38-sensors-physical-systems/safety-systems/emergency-stop-coverage.yaml"
      dimension: "agent-readiness"
      severity: "critical"
      issue: "Audit requires physical access and manual safety testing an LLM cannot perform"
      recommendation: |
        The procedure includes 'Test Each E-stop' - functionally testing physical safety devices.
        An LLM agent cannot physically press E-stop buttons or verify circuit functionality.
        Mark this audit as 'automatable: none' or add a hybrid workflow indicator specifying
        which steps require human/physical intervention.

    - audit_id: "sensors-physical-systems.actuator-control.motor-control"
      file: "/mnt/walnut-drive/dev/audits/audits/38-sensors-physical-systems/actuator-control/motor-control.yaml"
      dimension: "agent-readiness"
      severity: "critical"
      issue: "Physical motor inspection and VFD parameter access requires human presence"
      recommendation: |
        Steps like 'Check VFD Configuration' require direct access to Variable Frequency Drive
        interfaces, often through proprietary software or physical HMI panels. An LLM cannot
        access these systems. Add explicit markers for physical-access-required steps.

    - audit_id: "sensors-physical-systems.data-acquisition.adc-resolution-accuracy"
      file: "/mnt/walnut-drive/dev/audits/audits/38-sensors-physical-systems/data-acquisition/adc-resolution-accuracy.yaml"
      dimension: "agent-readiness"
      severity: "high"
      issue: "ADC characterization requires lab equipment not accessible to LLM"
      recommendation: |
        Tooling lists 'precision-source', 'spectrum-analyzer', 'histogram-analyzer',
        'temperature-chamber' - all physical lab equipment. The code review portions are
        LLM-executable but measurements are not. Split procedure into code-audit (LLM) and
        hardware-characterization (human) phases.

    - audit_id: "real-time-embedded.interrupt-handling.isr-latency-analysis"
      file: "/mnt/walnut-drive/dev/audits/audits/39-real-time-embedded/isr-latency-analysis.yaml"
      dimension: "agent-readiness"
      severity: "high"
      issue: "Latency measurement requires oscilloscope/logic analyzer access"
      recommendation: |
        The audit requires 'Hardware timing measurement capability', 'Logic analyzer or oscilloscope'.
        An LLM can analyze code for potential latency issues but cannot capture actual measurements.
        Distinguish between static analysis (LLM-capable) and dynamic measurement (human-required).

    - audit_id: "metaverse-immersive.comfort-safety.motion-sickness-prevention"
      file: "/mnt/walnut-drive/dev/audits/audits/43-metaverse-immersive/comfort-safety/motion-sickness-prevention.yaml"
      dimension: "agent-readiness"
      severity: "critical"
      issue: "VR comfort testing requires human testers experiencing the application"
      recommendation: |
        Procedure step 'User Testing - Test with sensitive users' explicitly requires human
        participants. Motion sickness is a physiological response an LLM cannot evaluate.
        The code analysis portions are automatable; user testing is fundamentally not.
        Add 'requires_human_testing: true' metadata.

    - audit_id: "metaverse-immersive.spatial-computing.spatial-anchor"
      file: "/mnt/walnut-drive/dev/audits/audits/43-metaverse-immersive/spatial-computing/spatial-anchor.yaml"
      dimension: "agent-readiness"
      severity: "high"
      issue: "AR anchor testing requires physical device and multiple sessions"
      recommendation: |
        Testing anchor persistence 'across sessions' and 'relocation accuracy' requires a physical
        AR device in a real environment. An LLM can review code patterns but cannot verify actual
        anchor drift measurements. Indicate physical device requirements explicitly.

    - audit_id: "metaverse-immersive.rendering-performance.latency-motion-to-photon"
      file: "/mnt/walnut-drive/dev/audits/audits/43-metaverse-immersive/rendering-performance/latency-motion-to-photon.yaml"
      dimension: "agent-readiness"
      severity: "high"
      issue: "End-to-end latency measurement requires specialized hardware"
      recommendation: |
        The audit requires 'high-speed-camera' and 'latency-tester' hardware. While code patterns
        can be analyzed, actual motion-to-photon measurements require physical testing apparatus.
        The 20ms threshold verification cannot be done by code analysis alone.

    - audit_id: "quantum-computing.error-handling.error-correction-code"
      file: "/mnt/walnut-drive/dev/audits/audits/42-quantum-computing/error-handling/error-correction-code.yaml"
      dimension: "agent-readiness"
      severity: "medium"
      issue: "Requires access to quantum hardware or accurate simulators"
      recommendation: |
        While code review is possible, 'Measure Logical Error Rate' and 'Assess Threshold Behavior'
        require either quantum hardware access or computationally expensive simulation. Clarify
        whether simulation tools like Stim are sufficient or if real hardware is needed.

    - audit_id: "machine-learning-ai.llm-operations.hallucination-detection"
      file: "/mnt/walnut-drive/dev/audits/audits/37-machine-learning-ai/llm-operations/hallucination-detection.yaml"
      dimension: "agent-readiness"
      severity: "medium"
      issue: "Evaluating hallucination detection requires runtime LLM access and ground truth"
      recommendation: |
        Testing hallucination detection accuracy requires running the LLM system and comparing
        outputs against ground truth. An auditor LLM can review code and architecture but cannot
        execute and evaluate another system's live outputs without integration. Clarify access
        requirements for evaluation data and live system.

    - audit_id: "machine-learning-ai.responsible-ai.bias-detection"
      file: "/mnt/walnut-drive/dev/audits/audits/37-machine-learning-ai/responsible-ai/bias-detection.yaml"
      dimension: "agent-readiness"
      severity: "medium"
      issue: "Bias analysis requires model predictions and protected attribute data"
      recommendation: |
        Computing fairness metrics requires running the model on evaluation data with demographic
        labels. An LLM agent can review bias detection code but cannot execute the actual bias
        analysis without model access and protected data. Add data access prerequisites.

    # =====================================================================
    # ACTIONABILITY ISSUES
    # =====================================================================

    - audit_id: "internationalization-localization.performance-optimization.runtime-performance"
      file: "/mnt/walnut-drive/dev/audits/audits/36-internationalization-localization/performance-optimization/runtime-performance.yaml"
      dimension: "actionability"
      severity: "medium"
      issue: "File patterns too generic to find i18n-specific performance issues"
      recommendation: |
        The file pattern '**/*.{js,ts,tsx}' matches all source files. More specific patterns would
        help: '**/useTranslation*.{ts,tsx}', '**/Intl.*.{js,ts}', '**/formatMessage*.{js,ts}'.
        Add framework-specific patterns (react-intl, i18next, vue-i18n).

    - audit_id: "internationalization-localization.text-handling.pluralization-gender"
      file: "/mnt/walnut-drive/dev/audits/audits/36-internationalization-localization/text-handling/pluralization-gender.yaml"
      dimension: "actionability"
      severity: "low"
      issue: "Code pattern for detecting conditional pluralization could miss variations"
      recommendation: |
        The pattern 'count.*===.*1.*\?' only catches ternary-based pluralization. Also check for:
        - 'if.*count.*===.*1' (if-else style)
        - 'plural:' (i18next inline)
        - 'n === 1' (different variable name)
        Expand patterns to catch more pluralization anti-patterns.

    - audit_id: "real-time-embedded.firmware-quality.misra-compliance"
      file: "/mnt/walnut-drive/dev/audits/audits/39-real-time-embedded/misra-compliance.yaml"
      dimension: "actionability"
      severity: "medium"
      issue: "Tool commands need more specific MISRA rule configuration examples"
      recommendation: |
        The procedure mentions configuring static analysis but doesn't provide example configurations.
        Add sample PC-Lint or cppcheck MISRA configuration snippets. Show which specific rules map
        to mandatory vs required categories. Make configuration actionable, not just conceptual.

    - audit_id: "blockchain.smart-contract-security.reentrancy-vulnerability"
      file: "/mnt/walnut-drive/dev/audits/audits/41-blockchain-distributed-ledger/smart-contract-security/reentrancy-vulnerability.yaml"
      dimension: "actionability"
      severity: "low"
      issue: "Code patterns could be more comprehensive for detecting reentrancy"
      recommendation: |
        Current patterns focus on '.call{' and 'transfer'. Also check for:
        - 'safeTransfer' (token transfers)
        - 'flashLoan' (potential callback)
        - 'onERC*Received' (token callbacks)
        - 'fallback()' and 'receive()' definitions

    - audit_id: "quantum-computing.quantum-algorithm.circuit-depth"
      file: "/mnt/walnut-drive/dev/audits/audits/42-quantum-computing/quantum-algorithm/circuit-depth.yaml"
      dimension: "actionability"
      severity: "medium"
      issue: "Procedure command assumes qiskit and specific file naming"
      recommendation: |
        The command 'QuantumCircuit.from_qasm_file(\"circuit.qasm\")' assumes a specific setup.
        Add alternative commands for Cirq, Q#, and Pennylane. Show how to find circuit files
        if not named 'circuit.qasm'. Make discovery more robust.

    - audit_id: "machine-learning-ai.model-monitoring.drift-detection-monitoring"
      file: "/mnt/walnut-drive/dev/audits/audits/37-machine-learning-ai/model-monitoring/drift-detection-monitoring.yaml"
      dimension: "actionability"
      severity: "low"
      issue: "File patterns assume specific directory structures"
      recommendation: |
        Patterns like '**/drift/**/*.py' and '**/evidently/**' assume specific naming conventions.
        Also search for drift detection in: '**/monitoring/**/*drift*', '**/data_quality/**',
        '**/feature_store/**'. Many teams organize differently.

    - audit_id: "signal-processing.spectral-analysis.fft-implementation"
      file: "/mnt/walnut-drive/dev/audits/audits/40-signal-processing-data-acquisition/spectral-analysis/fft-implementation.yaml"
      dimension: "actionability"
      severity: "low"
      issue: "Verification commands assume Python/numpy environment"
      recommendation: |
        The procedure assumes Python with numpy. Add verification approaches for:
        - C/C++ FFTW implementations (test harness examples)
        - MATLAB/Octave environments
        - Embedded DSP libraries (CMSIS-DSP validation)
        Make verification language-agnostic or provide multiple options.

    - audit_id: "sensors-physical-systems.safety-systems.emergency-stop-coverage"
      file: "/mnt/walnut-drive/dev/audits/audits/38-sensors-physical-systems/safety-systems/emergency-stop-coverage.yaml"
      dimension: "actionability"
      severity: "medium"
      issue: "File patterns for safety code are too generic"
      recommendation: |
        Patterns like '**/*estop*.c' and '**/*safety*.c' may miss implementations using
        different naming. Add patterns for: '**/e_stop*.c', '**/emergency*.c', '**/EStop*.c',
        and framework-specific patterns for PLCopen Safety, SafeMotion blocks, etc.

    # =====================================================================
    # CROSS-CUTTING OBSERVATIONS
    # =====================================================================

    - audit_id: "CROSS-CAT-40-41"
      file: "N/A"
      dimension: "alignment"
      severity: "high"
      issue: "Categories 40 and 41 have systematic ID prefix misalignment"
      recommendation: |
        All audits in category 40 use 'signal-processing' prefix instead of 'signal-processing-data-acquisition'.
        All audits in category 41 use 'blockchain' prefix instead of 'blockchain-distributed-ledger'.
        This affects cross-referencing and consistency. Recommend bulk updating these prefixes.

    - audit_id: "CROSS-CAT-38-39"
      file: "N/A"
      dimension: "agent-readiness"
      severity: "high"
      issue: "Categories 38-39 heavily require physical hardware access"
      recommendation: |
        Sensors/Physical Systems (38) and Real-Time/Embedded (39) categories have many audits
        requiring physical equipment, oscilloscopes, logic analyzers, motor access, etc.
        Consider adding a 'physical_access_required: true' field to help automation orchestrators
        route these appropriately. Code review portions could be separated into standalone sub-audits.

    - audit_id: "CROSS-CAT-42"
      file: "N/A"
      dimension: "clarity"
      severity: "medium"
      issue: "Quantum computing category assumes high domain expertise throughout"
      recommendation: |
        Category 42 audits consistently assume familiarity with quantum computing concepts
        (qubits, gates, decoherence, error correction). Consider adding a category-level
        glossary or linking to educational resources for auditors new to quantum.

    - audit_id: "CROSS-CAT-43"
      file: "N/A"
      dimension: "agent-readiness"
      severity: "medium"
      issue: "XR/Metaverse category requires human perception testing"
      recommendation: |
        Many Category 43 audits involve human perceptual evaluation (motion sickness, comfort,
        spatial perception). These fundamentally cannot be automated. Consider marking these
        with 'requires_human_evaluation: true' to set appropriate expectations.

  summary:
    total_issues: 34
    by_dimension:
      clarity: 7
      alignment: 10
      agent_readiness: 12
      actionability: 8
    by_severity:
      critical: 4
      high: 13
      medium: 13
      low: 4

  key_insights:
    - |
      ID PREFIX MISALIGNMENT: Categories 40 and 41 systematically use shortened ID prefixes
      ('signal-processing' and 'blockchain') instead of full category names. This affects 10+
      audits and should be bulk-fixed for consistency.

    - |
      PHYSICAL SYSTEMS REQUIRE HUMAN INTERVENTION: Categories 38-39 (Sensors/Embedded) and 43
      (Metaverse) have many audits requiring physical hardware, lab equipment, or human perception
      testing. These cannot be fully automated by LLM agents. Consider adding explicit
      'physical_access_required' or 'human_testing_required' metadata fields.

    - |
      DOMAIN EXPERTISE ASSUMPTION: Specialized categories (Quantum, Signal Processing, Blockchain,
      Real-Time) assume significant domain expertise. While appropriate for the 'expert' tier,
      key terminology should be briefly defined to help auditors from adjacent domains.

    - |
      CODE PATTERNS COULD BE MORE COMPREHENSIVE: Several audits have file/code patterns that
      might miss variations in naming conventions or alternative implementations. Expanding
      pattern sets would improve detection coverage.

    - |
      PROCEDURE STEPS MIX AUTOMATABLE AND MANUAL: Many procedures don't clearly distinguish
      which steps can be automated (code review, pattern matching) vs which require human
      action (physical testing, user studies). This clarity would help automation orchestration.

  recommendations:
    priority_1_critical:
      - "Bulk update ID prefixes in categories 40 and 41 to match full category names"
      - "Add 'requires_physical_access: true' field to hardware-dependent audits"
      - "Mark audits requiring human perception testing with 'requires_human_evaluation: true'"

    priority_2_high:
      - "Add glossary sections to specialized domain audits (quantum, signal processing)"
      - "Expand code patterns to catch naming variations and framework-specific implementations"
      - "Split hybrid audits into code-review (automatable) and measurement (manual) sub-procedures"

    priority_3_medium:
      - "Add specific tool configuration examples (not just tool names)"
      - "Provide multi-language/framework alternatives for verification commands"
      - "Cross-reference related audits across categories (e.g., ADC in cat-38 vs cat-40)"
