# Category 21: Responsible Design

**Cluster:** Human & Experience
**Slug:** `responsible-design`

## Overview

Audits covering harm prevention, dark pattern avoidance, addiction/manipulation prevention,
algorithmic fairness, consent transparency, and environmental impact of digital products.

This category was renamed from "ethical-societal" to better distinguish it from Category 18
(Ethical & Societal) which focuses on broader societal impact and AI ethics.

## Subcategories

- **addiction-manipulation**: Audits for engagement ethics, notification manipulation, FOMO exploitation
- **algorithmic-fairness**: Bias detection, disparate impact, fairness metrics
- **consent-transparency**: Informed consent, data usage transparency, opt-in/opt-out defaults
- **content-harm**: Harmful content moderation, misinformation, radicalization vectors
- **dark-pattern-avoidance**: Misdirection, bait-and-switch, confirmshaming, roach motel patterns
- **economic-fairness**: Dynamic pricing transparency, predatory pricing, accessibility pricing
- **environmental-impact**: Energy efficiency, carbon footprint, green hosting, compute optimization

## Audit Patterns

This category primarily uses:
- **Code review pattern** for detecting dark patterns in UI code
- **Configuration audit pattern** for consent and transparency settings
- **Documentation pattern** for policy compliance verification

## Related Categories

- **Category 18 (Ethical & Societal)**: Broader ethics including AI safety, privacy by design, societal impact
- **Category 22 (Gamification & Behavioral)**: Engagement mechanics with ethical considerations
- **Category 37 (Machine Learning & AI)**: Responsible AI and bias detection

## Key Standards & Frameworks

- EU Digital Services Act (DSA)
- UK Online Safety Act
- California Consumer Privacy Act (CCPA)
- FTC guidelines on dark patterns
- ACM Code of Ethics
