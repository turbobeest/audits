audit:
  id: observability-instrumentation.observability-operations.observability-tool-sprawl
  name: Observability Tool Sprawl Audit
  version: 1.0.0
  last_updated: '2026-01-18'
  status: active
  category: observability-instrumentation
  category_number: 5
  subcategory: observability-operations
  tier: phd
  estimated_duration: 3-4 hours  # median: 3h
  completeness: complete
  requires_runtime: false
  destructive: false
execution:
  automatable: partial
  severity: medium
  scope: organizational
  default_profiles:
  - full
  blocks_phase: false
  parallelizable: true
description:
  what: |
    Inventories and evaluates the breadth of observability tooling across the
    organization. Identifies overlapping tools, redundant capabilities, unused
    features, and fragmentation of observability data. Assesses the cognitive
    load on operators and the cost of maintaining multiple tool ecosystems.
  why_it_matters: |
    Tool sprawl increases costs, fragments institutional knowledge, and creates
    context-switching overhead during incidents. Engineers struggle to know which
    tool has the data they need. Overlapping tools often have inconsistent data,
    making debugging harder. Consolidation improves both cost efficiency and
    operator effectiveness.
  when_to_run:
  - During annual tooling reviews
  - Before major observability platform migrations
  - When onboarding indicates tool confusion
  - After acquisitions or team mergers
  - When evaluating new observability vendors
prerequisites:
  required_artifacts:
  - type: tool_inventory
    description: List of all observability tools in use across the organization
  - type: vendor_contracts
    description: Contracts and licensing information for observability tools
  - type: team_roster
    description: Teams using each tool and their use cases
  access_requirements:
  - Survey access to engineering teams
  - Access to procurement/vendor management system
  - Read access to tool configurations across teams
  - Access to usage analytics for each tool
discovery:
  interviews:
  - role: On-call engineers
    questions:
    - What observability tools do you use during incidents?
    - Do you ever struggle to find the right tool for a task?
    - Are there tools you've been trained on but rarely use?
    purpose: Understand actual tool usage patterns during incidents
  - role: Team leads
    questions:
    - What observability tools does your team rely on?
    - Are there tools you're paying for but not fully utilizing?
    - What overlaps exist between your tools?
    purpose: Identify team-specific tool adoption and gaps
  - role: Platform/SRE team
    questions:
    - What is the full inventory of observability tools supported?
    - Which tools have overlapping capabilities?
    - What is the maintenance burden for each tool?
    purpose: Get infrastructure perspective on tool landscape
  documents_to_review:
  - type: Vendor contracts
    purpose: Understand licensing costs and feature entitlements
  - type: Architecture diagrams
    purpose: Map data flow between observability tools
  - type: Onboarding materials
    purpose: Assess which tools are taught to new engineers
  code_patterns:
  - pattern: datadog|newrelic|splunk|elastic|grafana|prometheus
    type: keyword
    scope: config
    purpose: Identify tool-specific configurations across codebase
knowledge_sources:
  guides:
  - id: observability-consolidation
    name: Observability Platform Consolidation Guide
    url: https://www.cncf.io/blog/2023/06/19/the-cloud-native-observability-landscape/
    offline_cache: true
  learning_resources:
  - id: tool-rationalization
    title: Technology Rationalization Frameworks
    type: article
    reference: Enterprise architecture best practices for tool consolidation
tooling:
  assessment_tools:
  - tool: Survey platform
    purpose: Gather team tool usage data at scale
  - tool: Spreadsheet/database
    purpose: Consolidate tool inventory and cost analysis
  scripts:
  - id: tool-usage-scanner
    language: bash
    purpose: Scan codebase for observability tool references
    source: inline
    code: |
      #!/bin/bash
      # Scan for common observability tool patterns
      TOOLS="datadog newrelic splunk elastic grafana prometheus jaeger zipkin honeycomb lightstep"

      for tool in $TOOLS; do
        count=$(grep -ri "$tool" --include="*.yaml" --include="*.yml" --include="*.json" . 2>/dev/null | wc -l)
        if [ "$count" -gt 0 ]; then
          echo "$tool: $count references"
        fi
      done
signals:
  critical:
  - id: SPRAWL-CRIT-001
    signal: More than 5 overlapping tools for same observability function
    evidence_indicators:
    - Multiple APM tools in use
    - Multiple log aggregation platforms
    - Multiple metrics systems without clear delineation
    explanation: |
      Extreme fragmentation makes it impossible for engineers to know
      where to look. Incident response suffers as responders check
      multiple tools searching for relevant data.
    remediation: Develop consolidation roadmap with clear migration timeline
  high:
  - id: SPRAWL-HIGH-001
    signal: Teams using different tools for same use case without integration
    explanation: Cross-team debugging requires learning multiple tools
    remediation: Standardize on primary tools; implement integrations
  - id: SPRAWL-HIGH-002
    signal: Paying for overlapping vendor capabilities
    explanation: Duplicate costs for equivalent features across tools
    remediation: Audit feature usage; consolidate to fewer vendors
  - id: SPRAWL-HIGH-003
    signal: No unified observability strategy or standards
    explanation: Organic growth leads to continued sprawl
    remediation: Establish observability platform team and standards
  medium:
  - id: SPRAWL-MED-001
    signal: Tools adopted without formal evaluation process
    remediation: Implement tool adoption governance and evaluation criteria
  - id: SPRAWL-MED-002
    signal: Legacy tools still running with minimal usage
    remediation: Inventory usage; plan decommissioning or migration
  low:
  - id: SPRAWL-LOW-001
    signal: No centralized documentation of tool landscape
  positive:
  - id: SPRAWL-POS-001
    signal: Clear primary tools with documented use cases
  - id: SPRAWL-POS-002
    signal: Tool adoption governance in place
  - id: SPRAWL-POS-003
    signal: Successful recent consolidation efforts
procedure:
  context:
    cognitive_mode: evaluative
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Create comprehensive tool inventory
    description: |
      Catalog all observability tools in use across the organization.
      Include vendor tools, open source tools, and custom solutions.
    duration_estimate: 60 min
    questions:
    - What tools are used for metrics collection and visualization?
    - What tools are used for log aggregation and analysis?
    - What tools are used for distributed tracing?
    - What tools are used for APM and profiling?
    - What tools are used for alerting and incident management?
    expected_findings:
    - Complete inventory of observability tools
    - Categorization by observability function
  - id: '2'
    name: Map tool usage by team
    description: |
      Document which teams use which tools and for what purposes.
      Identify patterns of tool adoption and team preferences.
    duration_estimate: 45 min
    questions:
    - Which teams use each tool?
    - What are the primary use cases for each tool per team?
    - Are there tools that only one team uses?
    expected_findings:
    - Team-by-tool usage matrix
    - Identification of isolated tool adoption
  - id: '3'
    name: Identify overlapping capabilities
    description: |
      Analyze the feature overlap between tools. Identify redundant
      capabilities and opportunities for consolidation.
    duration_estimate: 45 min
    questions:
    - Which tools have overlapping metrics capabilities?
    - Which tools have overlapping logging capabilities?
    - Which tools have overlapping tracing capabilities?
    expected_findings:
    - Capability overlap matrix
    - Redundancy identification
  - id: '4'
    name: Analyze costs and licensing
    description: |
      Compile cost information for all tools. Identify the total
      observability spend and cost of redundancy.
    duration_estimate: 30 min
    questions:
    - What is the annual cost of each tool?
    - What is the total observability tool spend?
    - Which tools have unused paid features?
    expected_findings:
    - Total cost of observability tooling
    - Cost of redundant capabilities
  - id: '5'
    name: Develop consolidation recommendations
    description: |
      Based on analysis, recommend which tools to standardize on,
      which to decommission, and a migration roadmap.
    duration_estimate: 30 min
    expected_findings:
    - Primary tool recommendations by function
    - Decommissioning candidates
    - Migration complexity assessment
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: tool_inventory
    format: structured
    sections:
    - Complete Tool List
    - Usage by Team
    - Capability Matrix
    - Cost Analysis
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Current State Assessment
    - Key Findings
    - Consolidation Recommendations
    - Migration Roadmap
  confidence_guidance:
    high: Verified through team interviews and usage data
    medium: Based on configuration analysis and partial team input
    low: Inferred from documentation or limited sampling
offline:
  capability: full
  cache_manifest:
    knowledge:
    - source_id: observability-consolidation
      priority: recommended
  offline_notes: |
    This audit is primarily document and interview-based.
    Can be completed offline once initial data is gathered.
profiles:
  membership:
    quick:
      included: false
      reason: Requires comprehensive organizational review
    full:
      included: true
      priority: 3
closeout_checklist:
- id: observability-tool-sprawl-001
  item: Complete tool inventory created
  level: CRITICAL
  verification: manual
  verification_notes: All observability tools across the organization are cataloged
  expected: Confirmed by reviewer
- id: observability-tool-sprawl-002
  item: Capability overlap analysis completed
  level: BLOCKING
  verification: manual
  verification_notes: Tools with overlapping capabilities are identified
  expected: Confirmed by reviewer
- id: observability-tool-sprawl-003
  item: Cost analysis documented
  level: BLOCKING
  verification: manual
  verification_notes: Annual costs for each tool and total spend documented
  expected: Confirmed by reviewer
- id: observability-tool-sprawl-004
  item: Consolidation recommendations provided
  level: WARNING
  verification: manual
  verification_notes: Clear recommendations for primary tools and decommissioning
  expected: Confirmed by reviewer
governance:
  applicable_to:
    archetypes:
    - all
  compliance_frameworks:
  - framework: FinOps
    controls:
    - Cost Optimization
    - Vendor Management
relationships:
  commonly_combined:
  - observability-instrumentation.observability-operations.observability-cost
  - observability-instrumentation.observability-operations.opentelemetry-adoption
