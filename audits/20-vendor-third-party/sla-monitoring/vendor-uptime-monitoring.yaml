# ============================================================
# AUDIT: Vendor Uptime Monitoring Audit
# ============================================================
# Evaluates monitoring of vendor service availability
# and uptime commitments.
# ============================================================

audit:
  id: "vendor-third-party.sla-monitoring.vendor-uptime-monitoring"

  name: "Vendor Uptime Monitoring Audit"

  version: "1.0.0"
  last_updated: "2026-01-19"
  status: "active"

  category: "vendor-third-party"
  category_number: 20
  subcategory: "sla-monitoring"

  tier: "expert"
  estimated_duration: "3-5 hours"  # median: 4h

  completeness: "requires_discovery"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "infrastructure"

  default_profiles:
    - "full"
    - "production"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Evaluates vendor uptime monitoring including:
    - Availability monitoring systems
    - Endpoint health checks
    - Service status page monitoring
    - Incident detection timeliness
    - Downtime tracking accuracy
    - Availability calculation methods
    - Historical uptime analysis
    - Independent vs. vendor-reported metrics
    - Multi-region monitoring coverage

  why_it_matters: |
    Uptime monitoring verifies vendor availability commitments.
    Inadequate uptime monitoring results in:
    - Undetected service degradation
    - Disputed availability calculations
    - Lost service credits
    - Inability to correlate vendor outages with impact
    - Reactive incident response
    - Unreliable availability reporting
    - Poor capacity planning decisions
    Independent monitoring ensures vendor accountability.

  when_to_run:
    - "Quarterly availability reviews"
    - "After vendor outages"
    - "During SLA negotiations"
    - "When deploying new vendor dependencies"
    - "Annual vendor performance reviews"

prerequisites:
  required_artifacts:
    - type: "monitoring_systems"
      description: "Uptime monitoring tools and configurations"
    - type: "uptime_reports"
      description: "Historical availability data"
    - type: "sla_definitions"
      description: "Vendor availability SLAs"

  access_requirements:
    - "Monitoring systems"
    - "Vendor status pages"
    - "Historical uptime data"
    - "IT Operations team"

discovery:
  file_patterns:
    - glob: "**/monitoring/**uptime**"
      purpose: "Find uptime monitoring configs"
    - glob: "**/availability/**"
      purpose: "Locate availability tracking"

  metrics_queries:
    - system: "Uptime Monitoring"
      query: "availability_percentage by vendor"
      purpose: "Retrieve availability metrics"
      threshold: "Per SLA (typically 99.9%+)"

  documents_to_review:
    - type: "Monitoring configuration"
      purpose: "Review monitoring setup"
    - type: "Availability reports"
      purpose: "Assess tracking accuracy"
    - type: "Incident logs"
      purpose: "Correlate with monitoring"

  interviews:
    - role: "IT Operations"
      questions:
        - "How is vendor uptime monitored?"
        - "What tools are used?"
        - "How is downtime calculated?"
      purpose: "Understand monitoring approach"
    - role: "Vendor Management"
      questions:
        - "How are availability disputes resolved?"
        - "Do measurements match vendor reports?"
        - "What SLA credits have been claimed?"
      purpose: "Assess monitoring effectiveness"

knowledge_sources:
  specifications:
    - id: "sre-slo"
      name: "Site Reliability Engineering - SLOs"
      url: "https://sre.google/sre-book/service-level-objectives/"
      offline_cache: true
      priority: "required"

  guides:
    - id: "availability-monitoring"
      name: "Availability Monitoring Best Practices"
      url: "https://www.pagerduty.com/"
      offline_cache: true

tooling:
  monitoring_queries:
    - system: "Uptime Monitor"
      query: "uptime_check_status{vendor=~'.*'}"
      purpose: "Check vendor availability status"

  infrastructure_tools:
    - tool: "Synthetic Monitoring"
      purpose: "Verify vendor endpoint availability"
      command: "curl -w '%{http_code}' -o /dev/null -s https://vendor-api.example.com/health"

signals:
  critical:
    - id: "VUM-CRIT-001"
      signal: "Critical vendor not monitored for uptime"
      evidence_indicators:
        - "No availability monitoring in place"
        - "Relying solely on vendor status pages"
        - "Downtime discovered only when users report"
      explanation: |
        Critical vendor availability must be independently monitored.
        Without monitoring, outages go undetected and untracked.
      remediation: "Implement independent uptime monitoring for all critical vendors"

    - id: "VUM-CRIT-002"
      signal: "Monitoring coverage incomplete"
      evidence_indicators:
        - "Key endpoints not monitored"
        - "Partial service monitoring only"
        - "Dependencies between services not tracked"
      explanation: |
        Incomplete monitoring may miss outages affecting
        critical functionality.
      remediation: "Ensure comprehensive coverage of all critical endpoints"

    - id: "VUM-CRIT-003"
      signal: "Significant discrepancy with vendor-reported uptime"
      evidence_indicators:
        - "Organization measures differ from vendor"
        - "Vendor claims higher availability"
        - "Methodology differences unresolved"
      explanation: |
        Measurement discrepancies prevent effective SLA
        enforcement and service credit claims.
      remediation: "Align measurement methodology or document independent metrics"

  high:
    - id: "VUM-HIGH-001"
      signal: "No alerting for availability issues"
      explanation: "Real-time alerts enable rapid incident response"
      remediation: "Implement availability alerting with appropriate thresholds"

    - id: "VUM-HIGH-002"
      signal: "Single-point monitoring creates blind spots"
      explanation: "Multi-region monitoring provides comprehensive coverage"
      remediation: "Implement monitoring from multiple locations"

    - id: "VUM-HIGH-003"
      signal: "Historical data not retained"
      explanation: "Historical data supports SLA tracking and trend analysis"
      remediation: "Retain availability data per SLA measurement periods"

  medium:
    - id: "VUM-MED-001"
      signal: "Check frequency insufficient"
      remediation: "Increase monitoring frequency for critical services"

    - id: "VUM-MED-002"
      signal: "Status page integration missing"
      remediation: "Integrate vendor status page monitoring"

    - id: "VUM-MED-003"
      signal: "Downtime categorization not tracked"
      remediation: "Track planned vs. unplanned downtime"

  low:
    - id: "VUM-LOW-001"
      signal: "Monitoring dashboard could be improved"

  positive:
    - id: "VUM-POS-001"
      signal: "Comprehensive multi-region availability monitoring"
    - id: "VUM-POS-002"
      signal: "Automated alerting with rapid detection"
    - id: "VUM-POS-003"
      signal: "Accurate historical tracking supporting SLA enforcement"

procedure:
  context:
    cognitive_mode: "critical"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Monitoring Inventory"
      description: |
        Identify all uptime monitoring systems and their
        coverage of vendor services.
      duration_estimate: "30 min"

      questions:
        - "What monitoring systems exist?"
        - "Which vendors are monitored?"
        - "What endpoints are checked?"

      expected_findings:
        - "Monitoring inventory"
        - "Coverage assessment"

    - id: "2"
      name: "Configuration Review"
      description: |
        Assess monitoring configuration including check
        frequency, locations, and alerting.
      duration_estimate: "45 min"

      commands:
        - purpose: "List monitoring check configurations"
          command: "ls -la /etc/monitoring/*.yaml 2>/dev/null || echo 'Check monitoring configs manually'"

      expected_findings:
        - "Configuration assessment"
        - "Gap identification"

    - id: "3"
      name: "Data Accuracy Validation"
      description: |
        Verify monitoring data accuracy against known
        incidents and vendor reports.
      duration_estimate: "45 min"

      questions:
        - "Does data match known incidents?"
        - "Are calculations accurate?"
        - "Do results align with vendor?"

      expected_findings:
        - "Accuracy assessment"
        - "Discrepancy identification"

    - id: "4"
      name: "Alerting Assessment"
      description: |
        Evaluate alerting configuration and incident
        detection timeliness.
      duration_estimate: "30 min"

      expected_findings:
        - "Alert effectiveness"
        - "Detection timeliness"

    - id: "5"
      name: "Historical Analysis"
      description: |
        Review historical uptime data and trend analysis
        capabilities.
      duration_estimate: "30 min"

      expected_findings:
        - "Data availability"
        - "Trend analysis capability"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "uptime_assessment"
      format: "structured"
      sections:
        - "Monitoring Inventory"
        - "Configuration Review"
        - "Data Validation"
        - "Alerting Assessment"
        - "Historical Analysis"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Key Findings"
        - "Recommendations"

  confidence_guidance:
    high: "Full monitoring review with data validation"
    medium: "Key systems reviewed"
    low: "Documentation review only"

offline:
  capability: "partial"

profiles:
  membership:
    quick:
      included: false
      reason: "Requires detailed monitoring assessment"
    full:
      included: true
      priority: 1
    production:
      included: true
      priority: 1

closeout_checklist:
  - id: "vum-001"
    item: "Monitoring coverage assessed"
    level: "CRITICAL"
    verification: "manual"
    verification_notes: "Confirm all critical vendors monitored"
    expected: "Confirmed by reviewer"

  - id: "vum-002"
    item: "Data accuracy validated"
    level: "CRITICAL"
    verification: "manual"
    verification_notes: "Verify measurement accuracy verified"
    expected: "Confirmed by reviewer"

  - id: "vum-003"
    item: "Alerting reviewed"
    level: "BLOCKING"
    verification: "manual"
    verification_notes: "Confirm alerting configuration assessed"
    expected: "Confirmed by reviewer"

  - id: "vum-004"
    item: "Recommendations documented"
    level: "BLOCKING"
    verification: "manual"
    verification_notes: "Verify improvement recommendations provided"
    expected: "Confirmed by reviewer"

governance:
  applicable_to:
    archetypes: ["all"]

  compliance_frameworks:
    - framework: "ISO 27001"
      controls: ["A.15.2.1"]
    - framework: "NIST CSF"
      controls: ["DE.CM-7"]
    - framework: "SOC 2"
      controls: ["CC9.2", "A1.1"]

relationships:
  commonly_combined:
    - "vendor-third-party.sla-monitoring.sla-performance-tracking"
    - "vendor-third-party.sla-monitoring.sla-breach-handling"
    - "vendor-third-party.vendor-lifecycle.vendor-performance-evaluation"
