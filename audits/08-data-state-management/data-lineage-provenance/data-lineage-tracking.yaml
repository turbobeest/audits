audit:
  id: data-state-management.data-lineage-provenance.data-lineage-tracking
  name: Data Lineage Tracking Audit
  version: 1.0.0
  last_updated: '2026-01-18'
  status: active
  category: data-state-management
  category_number: 8
  subcategory: data-lineage-provenance
  tier: phd
  estimated_duration: 120 minutes
  completeness: requires_discovery
  requires_runtime: false
  destructive: false
execution:
  automatable: partial
  severity: high
  scope: data
  default_profiles:
  - full
  - compliance
  blocks_phase: false
  parallelizable: true
description:
  what: |
    Evaluates the ability to trace data from its origin through all
    transformations to its final destination. Analyzes whether data flows
    are documented, transformations are tracked, and the provenance of
    any data point can be determined. Covers both technical lineage
    (ETL pipelines) and business lineage (semantic meaning).
  why_it_matters: |
    Data lineage is essential for regulatory compliance (GDPR right to
    explanation), debugging data quality issues, impact analysis for changes,
    and building trust in analytics. Without lineage, data pipelines become
    black boxes where issues cannot be diagnosed and changes cannot be
    safely made.
  when_to_run:
  - Data governance audits
  - Compliance assessments
  - Before major pipeline changes
  - Data quality investigations
prerequisites:
  required_artifacts:
  - type: source_code
    description: Data pipeline and ETL code
  - type: data_catalog
    description: Data catalog or documentation
  - type: architecture_docs
    description: Data flow diagrams
  access_requirements:
  - Read access to data pipeline code
  - Access to data catalog
  - Understanding of data flows
discovery:
  code_patterns:
  - pattern: lineage|provenance|origin|source.*data
    type: regex
    scope: source
    purpose: Detect lineage tracking
  - pattern: transform|ETL|extract|load|pipeline
    type: regex
    scope: source
    purpose: Detect transformation code
  - pattern: data.*catalog|metadata|schema.*registry
    type: regex
    scope: source
    purpose: Detect metadata management
  file_patterns:
  - glob: '**/pipelines/**'
    purpose: Data pipelines
  - glob: '**/etl/**'
    purpose: ETL code
  - glob: '**/lineage/**'
    purpose: Lineage tracking
  - glob: '**/catalog/**'
    purpose: Data catalog
knowledge_sources:
  guides:
  - id: openlineage
    name: OpenLineage Specification
    url: https://openlineage.io/
    offline_cache: true
  - id: data-lineage-patterns
    name: Data Lineage Patterns
    url: https://www.datadoghq.com/blog/data-lineage/
    offline_cache: true
  learning_resources:
  - id: data-management
    title: 'DAMA-DMBOK: Data Management Body of Knowledge'
    type: book
    reference: 'DAMA International, ISBN: 978-1634622349'
tooling:
  static_analysis:
  - tool: openlineage
    purpose: Standard lineage tracking
    offline_capable: true
  - tool: atlas
    purpose: Apache Atlas for metadata and lineage
    offline_capable: true
  - tool: datahub
    purpose: DataHub for metadata management
    offline_capable: true
  scripts:
  - id: lineage-scan
    language: bash
    purpose: Analyze data lineage implementation
    source: inline
    code: |
      echo "=== Data Lineage Analysis ==="
      echo "--- Lineage tracking code ---"
      grep -rn "lineage\|provenance\|source.*=\|origin" \
        --include="*.py" --include="*.scala" --include="*.ts" . 2>/dev/null | \
        grep -v node_modules | head -30

      echo "--- Data pipeline definitions ---"
      grep -rn "pipeline\|DAG\|flow\|job" \
        --include="*.py" --include="*.yaml" --include="*.ts" . 2>/dev/null | \
        grep -v node_modules | head -30

      echo "--- Transformation tracking ---"
      grep -rn "transform\|map\|aggregate\|join" \
        --include="*.py" --include="*.scala" . 2>/dev/null | \
        grep -v node_modules | head -20
signals:
  critical:
  - id: DLT-CRIT-001
    signal: No data lineage tracking whatsoever
    evidence_pattern: Data pipelines without lineage metadata
    explanation: |
      Without lineage tracking, you cannot trace data back to its source,
      understand how it was transformed, or comply with data subject
      rights requests. This is a governance and compliance failure.
    remediation: Implement lineage tracking using OpenLineage or similar
  - id: DLT-CRIT-002
    signal: Unable to trace PII data flow
    evidence_pattern: Personal data moved without documented lineage
    explanation: |
      GDPR and similar regulations require ability to trace personal data.
      Unable to answer "where did this data come from and where did it go"
      is a compliance violation.
    remediation: Document all PII data flows with automated tracking
  high:
  - id: DLT-HIGH-001
    signal: Manual lineage documentation only
    evidence_pattern: Lineage in wiki/docs but not automated
    explanation: |
      Manual documentation becomes stale as pipelines change. Automated
      lineage extraction ensures documentation stays current with
      actual data flows.
    remediation: Implement automated lineage extraction
  - id: DLT-HIGH-002
    signal: Transformations not tracked
    evidence_pattern: Data moves between systems but transformations undocumented
    explanation: |
      Understanding how data is transformed is as important as knowing
      where it came from. Missing transformation logic makes debugging
      and validation impossible.
    remediation: Track transformation logic in lineage metadata
  - id: DLT-HIGH-003
    signal: No column-level lineage
    evidence_pattern: Only table-level lineage tracked
    explanation: |
      Table-level lineage shows data flow but not how individual fields
      are derived. Column-level lineage is needed for precise impact
      analysis and debugging.
    remediation: Implement column-level lineage tracking
  medium:
  - id: DLT-MED-001
    signal: Lineage not integrated with data catalog
    evidence_pattern: Lineage tracked separately from metadata
    remediation: Integrate lineage with data catalog for unified view
  - id: DLT-MED-002
    signal: No lineage for real-time data streams
    evidence_pattern: Batch lineage only, streaming untracked
    remediation: Extend lineage tracking to streaming pipelines
  - id: DLT-MED-003
    signal: Lineage visualization not available
    evidence_pattern: Lineage data exists but no way to view it
    remediation: Implement lineage visualization tools
  low:
  - id: DLT-LOW-001
    signal: Lineage not versioned
    evidence_pattern: Cannot see historical lineage
    remediation: Version lineage metadata for historical analysis
  - id: DLT-LOW-002
    signal: No business lineage (semantic level)
    evidence_pattern: Only technical lineage, no business context
    remediation: Add business glossary terms to lineage
  positive:
  - id: DLT-POS-001
    signal: Automated lineage extraction
    evidence_pattern: Lineage captured automatically from pipeline execution
  - id: DLT-POS-002
    signal: Column-level lineage tracked
    evidence_pattern: Field-level derivation documented
  - id: DLT-POS-003
    signal: Lineage integrated with data catalog
    evidence_pattern: Unified metadata and lineage platform
procedure:
  context:
    cognitive_mode: evaluative
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Identify Data Pipelines
    description: |
      Catalog all data pipelines and flows.
    duration_estimate: 25 min
    commands:
    - purpose: Find pipeline definitions
      command: |
        find . -type f \( -name "*pipeline*" -o -name "*dag*" -o -name "*etl*" \) \
          -not -path "*/node_modules/*" 2>/dev/null
    - purpose: Find data flow code
      command: |
        grep -rn "extract\|transform\|load\|pipeline\|DAG" \
          --include="*.py" --include="*.scala" --include="*.yaml" . 2>/dev/null | \
          grep -v node_modules | head -40
    expected_findings:
    - Pipeline inventory
    - Data flow patterns
  - id: '2'
    name: Review Lineage Implementation
    description: |
      Examine how lineage is tracked.
    duration_estimate: 30 min
    commands:
    - purpose: Find lineage tracking
      command: |
        grep -rn "lineage\|provenance\|OpenLineage\|atlas\|datahub" \
          --include="*.py" --include="*.scala" --include="*.yaml" . 2>/dev/null | head -30
    - purpose: Find metadata tracking
      command: |
        grep -rn "metadata\|catalog\|registry" \
          --include="*.py" --include="*.yaml" . 2>/dev/null | head -30
    expected_findings:
    - Lineage tracking method
    - Metadata management
  - id: '3'
    name: Assess Lineage Coverage
    description: |
      Determine completeness of lineage tracking.
    duration_estimate: 25 min
    questions:
    - Are all major data pipelines tracked?
    - Is column-level lineage available?
    - Can PII data flows be traced?
    expected_findings:
    - Coverage assessment
    - Gap identification
  - id: '4'
    name: Review Lineage Accessibility
    description: |
      Check how lineage is accessed and visualized.
    duration_estimate: 20 min
    commands:
    - purpose: Find lineage APIs
      command: |
        grep -rn "lineage.*api\|/lineage\|get.*lineage" \
          --include="*.py" --include="*.ts" --include="*.yaml" . 2>/dev/null | head -20
    expected_findings:
    - Access methods
    - Visualization capability
  - id: '5'
    name: Evaluate Compliance Support
    description: |
      Verify lineage supports compliance needs.
    duration_estimate: 20 min
    questions:
    - Can data subject requests be fulfilled using lineage?
    - Is lineage sufficient for audit purposes?
    - Can impact analysis be performed before changes?
    expected_findings:
    - Compliance support assessment
    - Audit readiness
output:
  deliverables:
  - type: finding_list
    format: structured
    content:
    - pipeline_inventory
    - lineage_coverage
    - compliance_gaps
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Pipeline Inventory
    - Lineage Coverage
    - Compliance Assessment
    - Recommendations
  confidence_guidance:
    high: Clear absence of lineage tracking
    medium: Lineage exists but incomplete
    low: Requires data flow analysis to confirm coverage
offline:
  capability: full
  cache_manifest:
    knowledge:
    - source_id: openlineage
      priority: required
    - source_id: data-management
      priority: recommended
profiles:
  membership:
    quick:
      included: false
      reason: Requires comprehensive pipeline analysis
    full:
      included: true
      priority: 1
    compliance:
      included: true
      priority: 1
closeout_checklist:
- id: dlt-001
  item: Data lineage tracking implemented
  level: CRITICAL
  verification: |
    grep -rn "lineage\|provenance\|openlineage" --include="*.py" --include="*.yaml" . 2>/dev/null | \
      wc -l | xargs -I {} test {} -gt 0 && echo "PASS" || echo "FAIL"
  expected: PASS
- id: dlt-002
  item: PII data flows can be traced
  level: CRITICAL
  verification: manual
  verification_notes: Verify ability to trace PII data from source to destination
  expected: Confirmed by reviewer
- id: dlt-003
  item: Lineage accessible for impact analysis
  level: BLOCKING
  verification: manual
  verification_notes: Verify lineage can be queried for change impact analysis
  expected: Confirmed by reviewer
governance:
  applicable_to:
    archetypes:
    - data-intensive
    - enterprise
    - regulated
  compliance_frameworks:
  - framework: GDPR
    controls:
    - Article 30
    - Article 15
  - framework: SOX
    controls:
    - Data Lineage Requirements
  - framework: BCBS 239
    controls:
    - Data Lineage
relationships:
  commonly_combined:
  - data-state-management.data-lineage-provenance.audit-trail
  - data-state-management.data-validation.data-quality-check
  - data-state-management.data-lineage-provenance.data-source-documentation
