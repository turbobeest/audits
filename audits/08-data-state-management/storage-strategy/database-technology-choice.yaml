# ============================================================
# AUDIT: Database Technology Choice
# ============================================================

audit:
  id: "data-state-management.storage-strategy.database-technology-choice"
  name: "Database Technology Choice Audit"
  version: "1.0.0"
  last_updated: "2026-01-18"
  status: "active"

  category: "data-state-management"
  category_number: 8
  subcategory: "storage-strategy"

  tier: "phd"
  estimated_duration: "150 minutes"

  completeness: "requires_discovery"
  requires_runtime: false
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "architecture"

  default_profiles:
    - "full"
    - "architecture"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Evaluates the appropriateness of database technology choices for the
    application's data characteristics, query patterns, scalability needs,
    and consistency requirements. Analyzes whether SQL, NoSQL, NewSQL, or
    specialized databases (time-series, graph, vector) are correctly matched
    to use cases.

  why_it_matters: |
    Database choice is one of the most consequential architectural decisions.
    Wrong choices lead to performance problems, operational complexity, and
    costly migrations. Using a relational database for graph traversals or
    a document store for complex joins creates perpetual friction.

  when_to_run:
    - "Architecture planning"
    - "Technology stack reviews"
    - "Before major scale-ups"
    - "Performance issue investigations"

prerequisites:
  required_artifacts:
    - type: "source_code"
      description: "Application code showing data access patterns"
    - type: "architecture_docs"
      description: "System architecture documentation"
    - type: "data_model"
      description: "Database schema or data model documentation"

  access_requirements:
    - "Read access to application source code"
    - "Access to database configuration"
    - "Understanding of data requirements"

discovery:
  code_patterns:
    - pattern: "pg|postgres|mysql|mariadb|mssql|oracle"
      type: "regex"
      scope: "config"
      purpose: "Detect relational databases"

    - pattern: "mongodb|mongoose|dynamodb|couchdb|cassandra"
      type: "regex"
      scope: "config"
      purpose: "Detect NoSQL databases"

    - pattern: "redis|memcached|elasticache"
      type: "regex"
      scope: "config"
      purpose: "Detect cache/key-value stores"

    - pattern: "elasticsearch|opensearch|solr|meilisearch"
      type: "regex"
      scope: "config"
      purpose: "Detect search engines"

    - pattern: "neo4j|janusgraph|dgraph|neptune"
      type: "regex"
      scope: "config"
      purpose: "Detect graph databases"

    - pattern: "influxdb|timescale|questdb|prometheus"
      type: "regex"
      scope: "config"
      purpose: "Detect time-series databases"

  file_patterns:
    - glob: "**/docker-compose*.yaml"
      purpose: "Database service definitions"
    - glob: "**/*.env*"
      purpose: "Database connection strings"
    - glob: "**/config/**database*"
      purpose: "Database configuration"

knowledge_sources:
  guides:
    - id: "cap-theorem"
      name: "CAP Theorem and Database Selection"
      url: "https://www.ibm.com/cloud/learn/cap-theorem"
      offline_cache: true

    - id: "database-selection"
      name: "Choosing the Right Database"
      url: "https://aws.amazon.com/products/databases/"
      offline_cache: true

  learning_resources:
    - id: "ddia"
      title: "Designing Data-Intensive Applications"
      type: "book"
      reference: "Martin Kleppmann, ISBN: 978-1449373320"

    - id: "seven-databases"
      title: "Seven Databases in Seven Weeks"
      type: "book"
      reference: "Eric Redmond, ISBN: 978-1680502534"

tooling:
  static_analysis:
    - tool: "dependency-analyzer"
      purpose: "Detect database drivers in dependencies"
      offline_capable: true

  scripts:
    - id: "database-tech-scan"
      language: "bash"
      purpose: "Identify database technologies in use"
      source: "inline"
      code: |
        echo "=== Database Technology Analysis ==="
        echo "--- Database packages ---"
        grep -rn "pg\|mysql\|mongodb\|redis\|cassandra\|elasticsearch" \
          --include="package.json" --include="requirements.txt" --include="pom.xml" --include="*.gradle" . 2>/dev/null | head -30

        echo "--- Connection strings ---"
        grep -rn "DATABASE_URL\|MONGODB_URI\|REDIS_URL\|postgres://\|mysql://" \
          --include="*.env*" --include="*.yaml" --include="*.json" . 2>/dev/null | head -20

        echo "--- Database service definitions ---"
        grep -rn "image:.*postgres\|image:.*mysql\|image:.*mongo\|image:.*redis" \
          --include="docker-compose*.yaml" --include="docker-compose*.yml" . 2>/dev/null | head -20

signals:
  critical:
    - id: "DTC-CRIT-001"
      signal: "Relational database used for graph traversals"
      evidence_pattern: "Multiple self-joins or recursive CTEs for relationship queries"
      explanation: |
        Graph queries in relational databases require expensive recursive
        queries or application-level traversal. A graph database can
        execute these queries orders of magnitude faster.
      remediation: "Consider graph database (Neo4j, JanusGraph) for relationship-heavy data"

    - id: "DTC-CRIT-002"
      signal: "Document store used for complex analytical queries"
      evidence_pattern: "Aggregation pipelines with multiple joins/lookups"
      explanation: |
        Document databases excel at document retrieval but struggle with
        complex joins and analytics. Forcing analytical workloads onto
        document stores leads to performance problems and complex code.
      remediation: "Use analytical database or data warehouse for complex analytics"

  high:
    - id: "DTC-HIGH-001"
      signal: "Single database for all workloads"
      evidence_pattern: "OLTP and OLAP queries on same database instance"
      explanation: |
        Mixing transactional and analytical workloads on the same database
        causes resource contention. Analytics queries can block transactions
        and vice versa.
      remediation: "Separate OLTP and OLAP with data replication"

    - id: "DTC-HIGH-002"
      signal: "Strong consistency required but using eventual consistency store"
      evidence_pattern: "DynamoDB/Cassandra for financial transactions without careful design"
      explanation: |
        Eventual consistency databases require careful application design
        for financial or inventory operations. Missing this leads to
        overselling, double-spending, or data loss.
      remediation: "Use strongly consistent database or implement careful consistency patterns"

    - id: "DTC-HIGH-003"
      signal: "Time-series data in general-purpose database"
      evidence_pattern: "Sensor/metrics data in PostgreSQL without TimescaleDB"
      explanation: |
        General-purpose databases lack optimizations for time-series data
        like compression, downsampling, and time-based partitioning,
        leading to storage bloat and slow queries.
      remediation: "Use time-series database (TimescaleDB, InfluxDB, QuestDB)"

  medium:
    - id: "DTC-MED-001"
      signal: "Search functionality built on primary database"
      evidence_pattern: "LIKE queries or full-text search on PostgreSQL"
      remediation: "Consider dedicated search engine for complex search requirements"

    - id: "DTC-MED-002"
      signal: "Session storage in primary database"
      evidence_pattern: "Sessions table in main PostgreSQL database"
      remediation: "Use Redis or similar for ephemeral session data"

    - id: "DTC-MED-003"
      signal: "Vector embeddings in general-purpose database"
      evidence_pattern: "Storing embeddings without pgvector or similar"
      remediation: "Use vector database or extension for similarity search"

  low:
    - id: "DTC-LOW-001"
      signal: "Database choice not documented"
      evidence_pattern: "No ADR explaining database selection rationale"
      remediation: "Document database selection decisions in ADRs"

    - id: "DTC-LOW-002"
      signal: "Local development uses different database than production"
      evidence_pattern: "SQLite local, PostgreSQL production"
      remediation: "Match database technologies across environments"

  positive:
    - id: "DTC-POS-001"
      signal: "Database choice matched to data model"
      evidence_pattern: "Document store for document data, relational for relational"

    - id: "DTC-POS-002"
      signal: "Specialized databases for specialized workloads"
      evidence_pattern: "Redis for cache, Elasticsearch for search, PostgreSQL for transactions"

    - id: "DTC-POS-003"
      signal: "Database selection documented with rationale"
      evidence_pattern: "ADRs explain why specific databases were chosen"

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Inventory Database Technologies"
      description: |
        Identify all database technologies in use.
      duration_estimate: "20 min"
      commands:
        - purpose: "Find database dependencies"
          command: |
            grep -rn "postgres\|mysql\|mongodb\|redis\|elasticsearch\|cassandra" \
              --include="package.json" --include="requirements.txt" --include="pom.xml" . 2>/dev/null | head -30
        - purpose: "Find database services"
          command: |
            grep -rn "image:.*db\|postgres\|mysql\|mongo\|redis" \
              --include="docker-compose*.y*ml" . 2>/dev/null | head -20

      expected_findings:
        - "Database technology inventory"
        - "Deployment configuration"

    - id: "2"
      name: "Analyze Data Access Patterns"
      description: |
        Understand how data is accessed and queried.
      duration_estimate: "35 min"
      commands:
        - purpose: "Find query patterns"
          command: |
            grep -rn "SELECT.*JOIN\|aggregate(\|lookup(\|MATCH.*RETURN" \
              --include="*.js" --include="*.ts" --include="*.java" --include="*.py" . 2>/dev/null | \
              grep -v node_modules | head -40
        - purpose: "Find time-series patterns"
          command: |
            grep -rn "timestamp\|created_at\|recorded_at\|GROUP BY.*date\|time_bucket" \
              --include="*.sql" --include="*.js" --include="*.ts" --include="*.py" . 2>/dev/null | head -30

      expected_findings:
        - "Query pattern analysis"
        - "Workload characteristics"

    - id: "3"
      name: "Assess Consistency Requirements"
      description: |
        Determine consistency and durability needs.
      duration_estimate: "25 min"
      commands:
        - purpose: "Find transaction patterns"
          command: |
            grep -rn "transaction\|BEGIN\|COMMIT\|ROLLBACK\|atomic" \
              --include="*.js" --include="*.ts" --include="*.java" --include="*.py" . 2>/dev/null | \
              grep -v node_modules | head -30
        - purpose: "Find consistency configuration"
          command: |
            grep -rn "read_concern\|write_concern\|consistency_level" \
              --include="*.js" --include="*.ts" --include="*.yaml" . 2>/dev/null | head -20

      expected_findings:
        - "Consistency requirements"
        - "Transaction usage"

    - id: "4"
      name: "Review Scalability Approach"
      description: |
        Analyze how databases are scaled.
      duration_estimate: "25 min"
      commands:
        - purpose: "Find sharding/partitioning"
          command: |
            grep -rn "shard\|partition\|replica\|cluster" \
              --include="*.yaml" --include="*.json" --include="*.conf" . 2>/dev/null | head -30

      expected_findings:
        - "Scaling strategy"
        - "Replication setup"

    - id: "5"
      name: "Evaluate Technology Fit"
      description: |
        Compare chosen technologies against requirements.
      duration_estimate: "45 min"
      questions:
        - "Does the data model fit the database paradigm?"
        - "Are query patterns optimized for the chosen database?"
        - "Can the database scale to projected data volumes?"
        - "Are consistency requirements met?"
      expected_findings:
        - "Technology fit assessment"
        - "Mismatch identification"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"
      content:
        - "database_inventory"
        - "pattern_analysis"
        - "fit_assessment"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Technology Inventory"
        - "Pattern Analysis"
        - "Fit Assessment"
        - "Recommendations"

  confidence_guidance:
    high: "Clear mismatch between data characteristics and database choice"
    medium: "Database choice workable but not optimal"
    low: "Requires performance testing to confirm issues"

offline:
  capability: "full"

  cache_manifest:
    knowledge:
      - source_id: "ddia"
        priority: "required"
      - source_id: "cap-theorem"
        priority: "required"

profiles:
  membership:
    quick:
      included: false
      reason: "Requires deep architectural analysis"
    full:
      included: true
      priority: 1
    architecture:
      included: true
      priority: 1

closeout_checklist:
  - id: "dtc-001"
    item: "Database technologies identified and inventoried"
    level: "CRITICAL"
    verification: |
      grep -rn "DATABASE\|MONGO\|REDIS\|postgres" --include="*.env*" . 2>/dev/null | \
        wc -l | xargs -I {} test {} -gt 0 && echo "PASS" || echo "FAIL"
    expected: "PASS"

  - id: "dtc-002"
    item: "Database choice matches data model requirements"
    level: "CRITICAL"
    verification: "manual"
    verification_notes: "Review data model against chosen database paradigm"
    expected: "Confirmed by reviewer"

  - id: "dtc-003"
    item: "Consistency requirements documented and met"
    level: "BLOCKING"
    verification: "manual"
    verification_notes: "Verify consistency level appropriate for use cases"
    expected: "Confirmed by reviewer"

governance:
  applicable_to:
    archetypes: ["all"]

  compliance_frameworks:
    - framework: "ISO 27001"
      controls: ["A.14.1.1"]

relationships:
  commonly_combined:
    - "data-state-management.storage-strategy.polyglot-persistence"
    - "data-state-management.data-access-patterns.query-pattern"
    - "scalability-capacity.scaling-patterns.database-scaling"
