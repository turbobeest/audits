# ============================================================
# AUDIT: Archival Strategy
# ============================================================
# Evaluates data archival strategies including cold storage,
# retrieval capabilities, and cost optimization.
# ============================================================

audit:
  id: "data-state-management.data-lifecycle.archival-strategy"

  name: "Archival Strategy"

  version: "1.0.0"
  last_updated: "2026-01-18"
  status: "active"

  category: "data-state-management"
  category_number: 8
  subcategory: "data-lifecycle"

  tier: "expert"
  estimated_duration: "2 hours"

  completeness: "complete"
  requires_runtime: false
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "data"

  default_profiles:
    - "full"
    - "production"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    This audit evaluates data archival strategies for moving inactive data
    to cost-effective storage while maintaining accessibility. It examines
    archival triggers, storage tier selection, retrieval mechanisms, and
    data integrity during archival. The audit identifies archival gaps
    and retrieval capability issues.

  why_it_matters: |
    Proper archival strategies balance storage costs with data accessibility.
    Without archival, storage costs grow unbounded as inactive data accumulates.
    Poor archival makes historical data inaccessible when needed for compliance,
    analytics, or disputes. Well-designed archival reduces costs while
    maintaining data value.

  when_to_run:
    - "When storage costs are increasing"
    - "During capacity planning"
    - "When defining data lifecycle policies"
    - "Before compliance audits requiring historical data"

prerequisites:
  required_artifacts:
    - type: "archival-policy"
      description: "Data archival policy documentation"
    - type: "storage-config"
      description: "Storage tier configuration"

  access_requirements:
    - "Access to storage configuration"
    - "Access to archival job definitions"
    - "Storage cost data (recommended)"

discovery:
  code_patterns:
    - pattern: "archive|cold.*storage|glacier|infrequent.*access"
      type: "regex"
      scope: "source"
      purpose: "Identify archival-related code"
    - pattern: "S3.*GLACIER|STANDARD_IA|DEEP_ARCHIVE"
      type: "regex"
      scope: "source"
      purpose: "Identify AWS storage class references"
    - pattern: "lifecycle|transition|tier"
      type: "regex"
      scope: "source"
      purpose: "Identify storage lifecycle rules"

  file_patterns:
    - glob: "**/archive/**/*"
      purpose: "Archive-related code"
    - glob: "**/*.tf"
      purpose: "Terraform storage configuration"
    - glob: "**/s3/**/*"
      purpose: "S3 lifecycle configuration"

knowledge_sources:
  guides:
    - id: "aws-storage-classes"
      name: "AWS S3 Storage Classes"
      url: "https://aws.amazon.com/s3/storage-classes/"
      offline_cache: true

    - id: "data-archival-best-practices"
      name: "Data Archival Best Practices"
      url: "https://cloud.google.com/architecture/data-lifecycle-management"
      offline_cache: true

tooling:
  infrastructure_tools:
    - tool: "aws s3api"
      purpose: "Inspect S3 lifecycle configuration"
      command: "aws s3api get-bucket-lifecycle-configuration --bucket BUCKET_NAME"
    - tool: "aws glacier"
      purpose: "Inspect Glacier vaults"
      command: "aws glacier list-vaults --account-id -"

signals:
  critical:
    - id: "ARCH-CRIT-001"
      signal: "No archival strategy for growing historical data"
      evidence_pattern: "Large tables without archival, no lifecycle policies"
      explanation: |
        Without archival, storage costs grow linearly with data age.
        Databases become slower as tables grow. Eventually, storage
        limits or costs force emergency archival under pressure.
      remediation: "Define archival criteria and implement automated archival to cold storage"

    - id: "ARCH-CRIT-002"
      signal: "Archived data not retrievable or corrupted"
      evidence_pattern: "Archives without tested retrieval, missing integrity checks"
      explanation: |
        Archives that can't be retrieved are worthless. Corruption during
        archival, missing metadata, or incompatible formats make historical
        data inaccessible when needed for compliance or disputes.
      remediation: "Test archive retrieval regularly; implement integrity verification; document retrieval procedures"

  high:
    - id: "ARCH-HIGH-001"
      signal: "Archival without metadata preservation"
      evidence_pattern: "Archived data without schema, timestamps, or context"
      explanation: |
        Archives without metadata become increasingly difficult to use
        over time. Schema changes make old data unreadable. Missing
        timestamps prevent proper reconstruction of historical state.
      remediation: "Archive schema and metadata alongside data; include data lineage information"

    - id: "ARCH-HIGH-002"
      signal: "No automated archival triggers"
      evidence_pattern: "Manual archival process requiring intervention"
      explanation: |
        Manual archival is inconsistent and often delayed. Storage costs
        accumulate while waiting for someone to archive. Critical data
        may be missed or archived incorrectly.
      remediation: "Implement automated archival based on age, access patterns, or size thresholds"

  medium:
    - id: "ARCH-MED-001"
      signal: "Archival without retrieval SLA or time estimates"
      evidence_pattern: "Archives on Glacier Deep without documented retrieval times"
      remediation: "Document retrieval SLAs; choose storage class based on access requirements"

    - id: "ARCH-MED-002"
      signal: "Archives not included in backup strategy"
      evidence_pattern: "Archives stored without redundancy or backup"
      remediation: "Include archives in backup strategy with appropriate redundancy"

  low:
    - id: "ARCH-LOW-001"
      signal: "Suboptimal storage class selection"

  positive:
    - id: "ARCH-POS-001"
      signal: "Comprehensive archival with tested retrieval"
    - id: "ARCH-POS-002"
      signal: "Cost-optimized storage tiering based on access patterns"

procedure:
  context:
    cognitive_mode: "critical"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Archival Strategy Discovery"
      description: |
        Identify existing archival strategies including policies,
        storage tiers, and automation.
      duration_estimate: "25 min"

      commands:
        - purpose: "Find archival configuration"
          command: "grep -riE 'archive|glacier|cold.?storage|infrequent' --include='*.yml' --include='*.yaml' --include='*.tf' --include='*.json' . 2>/dev/null | head -40"
        - purpose: "Find lifecycle rules"
          command: "grep -riE 'lifecycle|transition|storage.?class' --include='*.tf' --include='*.yml' --include='*.yaml' . 2>/dev/null | head -30"
        - purpose: "Find archival jobs"
          command: "grep -riE 'archive|moveToArchive|archival' --include='*.ts' --include='*.py' --include='*.java' . 2>/dev/null | head -30"

      expected_findings:
        - "Archival configuration"
        - "Storage tier strategy"

    - id: "2"
      name: "Archival Criteria Analysis"
      description: |
        Evaluate criteria used to determine when data should
        be archived.
      duration_estimate: "25 min"

      commands:
        - purpose: "Find age-based archival"
          command: "grep -riE 'days?.*old|older.*than|created.*before|archive.*after' --include='*.ts' --include='*.py' --include='*.sql' . 2>/dev/null | head -30"
        - purpose: "Find access-pattern archival"
          command: "grep -riE 'last.*access|not.*accessed|inactive' --include='*.ts' --include='*.py' . 2>/dev/null | head -20"

      expected_findings:
        - "Archival trigger criteria"
        - "Age or access thresholds"

    - id: "3"
      name: "Retrieval Capability Analysis"
      description: |
        Verify archived data can be retrieved and used when needed.
      duration_estimate: "25 min"

      commands:
        - purpose: "Find retrieval procedures"
          command: "grep -riE 'restore|retrieve|unarchive|thaw' --include='*.ts' --include='*.py' --include='*.sh' --include='*.md' . 2>/dev/null | head -30"
        - purpose: "Find retrieval documentation"
          command: "find . -name '*.md' -exec grep -l -iE 'archive.*retriev|restore.*archive' {} \\; 2>/dev/null | head -10"

      expected_findings:
        - "Retrieval mechanisms"
        - "Retrieval documentation"

    - id: "4"
      name: "Data Integrity Analysis"
      description: |
        Verify archival maintains data integrity with checksums
        and metadata.
      duration_estimate: "25 min"

      commands:
        - purpose: "Find checksum/integrity verification"
          command: "grep -riE 'checksum|md5|sha256|integrity|verify' --include='*.ts' --include='*.py' -path '*archive*' . 2>/dev/null | head -20"
        - purpose: "Find metadata preservation"
          command: "grep -riE 'metadata|schema.*version|archive.*context' --include='*.ts' --include='*.py' . 2>/dev/null | head -20"

      expected_findings:
        - "Integrity verification mechanisms"
        - "Metadata preservation"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Archival Strategy Assessment"
        - "Retrieval Capability"
        - "Data Integrity"
        - "Cost Optimization Opportunities"

  confidence_guidance:
    high: "Clear evidence of missing archival or unretrievable archives"
    medium: "Archival exists but retrieval testing uncertain"
    low: "Archival appears adequate but comprehensive testing needed"

offline:
  capability: "full"

  cache_manifest:
    knowledge:
      - source_id: "aws-storage-classes"
        priority: "recommended"

profiles:
  membership:
    quick:
      included: false
      reason: "Requires comprehensive archival analysis"
    full:
      included: true
      priority: 1

closeout_checklist:
  - id: "arch-001"
    item: "Archival strategy defined for large/growing data"
    level: "CRITICAL"
    verification: "grep -riE 'archive|lifecycle|glacier' --include='*.tf' --include='*.yml' . 2>/dev/null | wc -l | xargs -I{} test {} -gt 0 && echo PASS || echo FAIL"
    expected: "PASS"

  - id: "arch-002"
    item: "Retrieval procedures documented and tested"
    level: "BLOCKING"
    verification: "manual"
    verification_notes: "Reviewer should verify retrieval procedures exist and have been tested"
    expected: "Confirmed by reviewer"

  - id: "arch-003"
    item: "Archive integrity verification in place"
    level: "WARNING"
    verification: "manual"
    verification_notes: "Reviewer should verify checksums or integrity checks for archives"
    expected: "Confirmed by reviewer"

governance:
  applicable_to:
    archetypes: ["all"]

  compliance_frameworks:
    - framework: "Data Governance"
      controls: ["DG-001", "DG-002"]

relationships:
  commonly_combined:
    - "data-state-management.data-lifecycle.data-retention-policy"
    - "data-state-management.data-lifecycle.data-aging"
