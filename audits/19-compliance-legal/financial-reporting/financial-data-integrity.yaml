audit:
  id: compliance-legal.financial-reporting.financial-data-integrity
  name: Financial Data Integrity Audit
  version: 1.0.0
  last_updated: '2026-01-19'
  status: active
  category: compliance-legal
  category_number: 19
  subcategory: financial-reporting
  tier: phd
  estimated_duration: 5-8 hours  # median: 6h
  completeness: requires_discovery
  requires_runtime: true
  destructive: false
execution:
  automatable: partial
  severity: critical
  scope: data
  default_profiles:
  - full
  - security
  blocks_phase: false
  parallelizable: true
description:
  what: |
    Evaluates controls ensuring financial data integrity including:
    - Input validation and data quality controls
    - Processing integrity controls
    - Output reconciliation procedures
    - Data completeness verification
    - Interface and integration controls
    - Error handling and correction processes
    - Data transformation accuracy
    - Master data management controls
  why_it_matters: |
    Financial data integrity is fundamental to reliable financial
    reporting. Data integrity failures can result in:
    - Material misstatements in financial reports
    - Regulatory enforcement and restatements
    - Audit qualifications and increased scrutiny
    - Investor lawsuits and loss of confidence
    - Operational decisions based on incorrect data
    - SOX material weaknesses
    - Fraud facilitation through undetected manipulation
  when_to_run:
  - During annual SOX assessment
  - When implementing new financial integrations
  - After data quality incidents
  - During system migrations
prerequisites:
  required_artifacts:
  - type: data_flow_diagrams
    description: Financial data flows and transformations
  - type: reconciliation_procedures
    description: Data reconciliation documentation
  - type: input_validation_rules
    description: Data validation specifications
  access_requirements:
  - Financial database read access
  - Integration and ETL documentation
  - Reconciliation reports
  - Data quality metrics
discovery:
  code_patterns:
  - pattern: (validat|sanitiz|check|verify).*input
    type: regex
    scope: source
    purpose: Find input validation code
  - pattern: (reconcil|balance|match|compare)
    type: regex
    scope: source
    purpose: Locate reconciliation logic
  - pattern: (checksum|hash|integrity|digest)
    type: regex
    scope: source
    purpose: Find integrity verification code
  file_patterns:
  - glob: '**/validation/**'
    purpose: Validation module code
  - glob: '**/reconciliation/**'
    purpose: Reconciliation implementations
  - glob: '**/etl/**'
    purpose: Data transformation code
  documents_to_review:
  - type: Data flow documentation
    purpose: Understand data movement
  - type: Reconciliation procedures
    purpose: Review balance verification
  - type: Data quality reports
    purpose: Assess current quality metrics
  interviews:
  - role: Data Engineering
    questions:
    - How is data validated at input?
    - What transformation controls exist?
    - How are data quality issues detected?
    purpose: Understand technical controls
  - role: Finance Operations
    questions:
    - What reconciliations are performed?
    - How are discrepancies investigated?
    - What are common data issues?
    purpose: Assess operational controls
knowledge_sources:
  specifications:
  - id: sox-data
    name: SOX Data Integrity Requirements
    url: https://www.sec.gov/
    offline_cache: true
    priority: required
  - id: gaap-controls
    name: GAAP Internal Control Requirements
    url: https://fasb.org/
    offline_cache: true
    priority: required
  guides:
  - id: data-quality
    name: DAMA Data Quality Framework
    url: https://www.dama.org/
    offline_cache: true
tooling:
  assessment_tools:
  - tool: Data Integrity Assessment Checklist
    purpose: Structured evaluation of data controls
  - tool: Reconciliation Testing Template
    purpose: Document reconciliation assessments
  scripts:
  - id: find-validation
    language: bash
    purpose: Locate data validation implementations
    source: inline
    code: |
      #!/bin/bash
      echo "=== Input Validation ==="
      grep -r -E "(validate|sanitize|check).*input" \
        --include="*.py" --include="*.java" --include="*.ts" . 2>/dev/null

      echo "=== Data Integrity Checks ==="
      grep -r -E "(checksum|hash|verify.*integrity)" \
        --include="*.py" --include="*.java" . 2>/dev/null
signals:
  critical:
  - id: FDI-CRIT-001
    signal: No input validation for financial data entry
    evidence_indicators:
    - Direct database inserts without validation
    - User input accepted without sanity checks
    - Invalid data types accepted
    explanation: |
      Input validation is the first line of defense for data integrity.
      Unvalidated input can corrupt financial records and reports.
    remediation: Implement comprehensive input validation at all entry points
  - id: FDI-CRIT-002
    signal: No reconciliation between systems
    evidence_indicators:
    - Financial totals not balanced between systems
    - No verification of data completeness after transfers
    - Interface discrepancies undetected
    explanation: |
      Reconciliation controls detect data loss or corruption during
      processing. Missing reconciliation allows errors to compound.
    remediation: Implement automated reconciliation with exception alerting
  - id: FDI-CRIT-003
    signal: Manual data manipulation without controls
    evidence_indicators:
    - Direct database updates in production
    - Spreadsheet-based financial adjustments
    - No approval for data corrections
    explanation: |
      Manual data manipulation bypasses application controls and
      creates opportunity for error and fraud.
    remediation: Implement controlled correction processes with approval workflow
  high:
  - id: FDI-HIGH-001
    signal: Data transformation logic undocumented
    explanation: Undocumented transformations cannot be verified for accuracy
    remediation: Document all data transformations with business rules
  - id: FDI-HIGH-002
    signal: Error handling allows partial updates
    explanation: Partial updates can create data inconsistencies
    remediation: Implement transaction controls ensuring atomicity
  - id: FDI-HIGH-003
    signal: No data completeness verification
    explanation: Missing records may not be detected without completeness checks
    remediation: Implement record count and hash-total reconciliation
  medium:
  - id: FDI-MED-001
    signal: Data quality metrics not monitored
    remediation: Implement data quality dashboards and alerting
  - id: FDI-MED-002
    signal: Duplicate detection not implemented
    remediation: Add duplicate prevention and detection controls
  low:
  - id: FDI-LOW-001
    signal: Data quality documentation outdated
  positive:
  - id: FDI-POS-001
    signal: Automated reconciliation with exception workflow
  - id: FDI-POS-002
    signal: Comprehensive input validation framework
procedure:
  context:
    cognitive_mode: critical
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Map Financial Data Flows
    description: |
      Document how financial data flows through systems from
      input to reporting, identifying all transformation points.
    duration_estimate: 60 min
    questions:
    - What are the sources of financial data?
    - How does data flow between systems?
    - Where are transformations applied?
    expected_findings:
    - Complete data flow mapping
    - Transformation inventory
    - Integration point identification
  - id: '2'
    name: Input Validation Assessment
    description: |
      Evaluate input validation controls at all financial
      data entry points including interfaces.
    duration_estimate: 75 min
    commands:
    - purpose: Find validation implementations
      command: grep -r -E '(validate|check|verify)' --include='*.py' --include='*.java' --include='*.ts'
        . | head -30
    expected_findings:
    - Input validation coverage
    - Validation rule completeness
    - Gap identification
  - id: '3'
    name: Processing Controls Review
    description: |
      Assess controls over data processing including
      transformation accuracy and error handling.
    duration_estimate: 60 min
    questions:
    - How are transformations tested and verified?
    - What error handling exists?
    - Are transactions atomic?
    expected_findings:
    - Processing control adequacy
    - Error handling assessment
    - Transaction integrity
  - id: '4'
    name: Reconciliation Assessment
    description: |
      Evaluate reconciliation controls between systems
      and to authoritative sources.
    duration_estimate: 60 min
    questions:
    - What reconciliations are performed?
    - How frequently are they executed?
    - How are exceptions investigated?
    expected_findings:
    - Reconciliation coverage
    - Exception handling adequacy
    - Timeliness assessment
  - id: '5'
    name: Data Quality Monitoring
    description: |
      Review data quality monitoring capabilities and
      historical quality metrics.
    duration_estimate: 45 min
    expected_findings:
    - Quality monitoring capabilities
    - Historical quality trends
    - Issue detection timeliness
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: data_integrity_assessment
    format: structured
    sections:
    - Data Flow Analysis
    - Input Control Assessment
    - Processing Control Assessment
    - Reconciliation Assessment
    - Quality Monitoring Review
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Key Findings
    - Recommendations
  confidence_guidance:
    high: Complete data flow tracing with control testing
    medium: Control review with sample testing
    low: Documentation review only
offline:
  capability: partial
  cache_manifest:
    knowledge:
    - source_id: sox-data
      priority: required
profiles:
  membership:
    quick:
      included: false
      reason: Requires comprehensive data flow analysis
    full:
      included: true
      priority: 1
closeout_checklist:
- id: fdi-001
  item: Data flows documented
  level: CRITICAL
  verification: manual
  verification_notes: Confirm complete data flow mapping exists
  expected: Confirmed by reviewer
- id: fdi-002
  item: Input validation assessed
  level: CRITICAL
  verification: manual
  verification_notes: Verify input control evaluation complete
  expected: Confirmed by reviewer
- id: fdi-003
  item: Reconciliation controls evaluated
  level: CRITICAL
  verification: manual
  verification_notes: Confirm reconciliation assessment complete
  expected: Confirmed by reviewer
- id: fdi-004
  item: Processing integrity verified
  level: BLOCKING
  verification: manual
  verification_notes: Verify transaction and transformation controls assessed
  expected: Confirmed by reviewer
governance:
  applicable_to:
    archetypes:
    - public-company
    - financial-services
    - enterprise
  compliance_frameworks:
  - framework: SOX
    controls:
    - Section 404
    - ITGC
  - framework: GAAP
    controls:
    - Internal Control Standards
relationships:
  commonly_combined:
  - compliance-legal.financial-reporting.sox-compliance
  - compliance-legal.financial-reporting.financial-reporting-accuracy
  - compliance-legal.risk-control.control-effectiveness
