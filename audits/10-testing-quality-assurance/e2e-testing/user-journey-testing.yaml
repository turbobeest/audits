# ============================================================
# AUDIT: User Journey Testing
# ============================================================
# Evaluates E2E tests for coverage of complete user journeys
# and realistic user workflows.
# ============================================================

audit:
  id: "testing-quality-assurance.e2e-testing.user-journey-testing"
  name: "User Journey Testing"
  version: "1.0.0"
  last_updated: "2026-01-19"
  status: "active"

  category: "testing-quality-assurance"
  category_number: 10
  subcategory: "e2e-testing"

  tier: "expert"
  estimated_duration: "2 hours"

  completeness: "complete"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "testing"

  default_profiles:
    - "full"
    - "quality"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Assesses whether E2E tests represent realistic user journeys from start
    to finish rather than isolated feature tests. Evaluates whether tests
    cover the complete flow users take to accomplish goals including
    navigation, form completion, error recovery, and success confirmation.

  why_it_matters: |
    Isolated feature tests may pass while complete user journeys fail due
    to navigation issues, state problems, or missing steps. Testing complete
    journeys ensures users can actually accomplish their goals in the
    real application.

  when_to_run:
    - "Before major releases"
    - "After navigation changes"
    - "UX review processes"
    - "Onboarding flow updates"

prerequisites:
  required_artifacts:
    - type: "e2e_tests"
      description: "End-to-end test files"
    - type: "user_journeys"
      description: "Documented user journey maps"

  access_requirements:
    - "Source code repository access"
    - "User journey documentation"
    - "Product requirements"

discovery:
  file_patterns:
    - glob: "**/e2e/**/*.{spec,test}.{js,ts}"
      purpose: "E2E test files"
    - glob: "**/cypress/**/*.{spec,cy}.{js,ts}"
      purpose: "Cypress tests"
    - glob: "**/*journey*"
      purpose: "Journey-specific tests"

  code_patterns:
    - pattern: "visit|navigate|goto"
      type: "keyword"
      scope: "source"
      purpose: "Identify navigation in tests"
    - pattern: "click|type|fill|select"
      type: "keyword"
      scope: "source"
      purpose: "Identify user interactions"
    - pattern: "should|expect|assert"
      type: "keyword"
      scope: "source"
      purpose: "Identify verification points"

knowledge_sources:
  guides:
    - id: "user-journey-testing"
      name: "Testing User Journeys"
      url: "https://www.nngroup.com/articles/journey-mapping-101/"
      offline_cache: true
    - id: "cypress-testing"
      name: "Cypress Best Practices"
      url: "https://docs.cypress.io/guides/references/best-practices"
      offline_cache: true

  learning_resources:
    - id: "ux-testing"
      title: "UX Research and Design"
      type: "book"
      reference: "ISBN 978-0321934116"

tooling:
  static_analysis:
    - tool: "cypress"
      purpose: "E2E journey testing"
      offline_capable: true
    - tool: "playwright"
      purpose: "Multi-page journey testing"
      offline_capable: true

  scripts:
    - id: "journey-analyzer"
      language: "bash"
      purpose: "Analyze user journey test coverage"
      source: "inline"
      code: |
        #!/bin/bash
        echo "=== User Journey Testing Analysis ==="
        echo "Journey-focused tests:"
        grep -r -l 'journey\|flow\|workflow\|scenario' --include='*.spec.*' --include='*.cy.*' . 2>/dev/null | head -10
        echo ""
        echo "Multi-page navigation tests:"
        grep -r -c 'visit\|navigate\|goto' --include='*.spec.*' --include='*.cy.*' . 2>/dev/null | awk -F: '$2 > 2 {print}' | head -15
        echo ""
        echo "User action sequences:"
        grep -r -c 'click\|type\|fill' --include='*.spec.*' --include='*.cy.*' . 2>/dev/null | awk -F: '$2 > 5 {print}' | head -15

signals:
  critical:
    - id: "JOURNEY-CRIT-001"
      signal: "No complete user journey tests exist"
      evidence_pattern: "All E2E tests are single-page feature tests"
      explanation: |
        Feature tests that don't follow complete journeys miss navigation
        issues and state problems that occur during real user flows.
      remediation: "Create E2E tests that follow complete user journeys"

    - id: "JOURNEY-CRIT-002"
      signal: "Critical conversion flows not tested end-to-end"
      evidence_pattern: "Signup-to-purchase flow not tested completely"
      explanation: |
        Conversion flows directly impact revenue. Breaks in these flows
        may not be caught by isolated tests.
      remediation: "Add complete journey tests for conversion flows"

  high:
    - id: "JOURNEY-HIGH-001"
      signal: "Journey tests skip important steps"
      evidence_pattern: "Tests use shortcuts not available to users"
      explanation: |
        Using API shortcuts or direct state manipulation hides issues
        users would encounter navigating normally.
      remediation: "Ensure journey tests use realistic user paths"

    - id: "JOURNEY-HIGH-002"
      signal: "No error recovery journey tests"
      evidence_pattern: "All journeys assume happy path"
      explanation: |
        Users make mistakes and encounter errors. Journey tests should
        verify users can recover and complete their goals.
      remediation: "Add journey tests with error recovery scenarios"

  medium:
    - id: "JOURNEY-MED-001"
      signal: "Journeys don't test realistic data entry"
      evidence_pattern: "Trivial test data used (single character, etc.)"
      remediation: "Use realistic data in journey tests"

    - id: "JOURNEY-MED-002"
      signal: "Journey tests don't verify completion confirmation"
      evidence_pattern: "No assertions on success messages or next steps"
      remediation: "Add verification of journey completion"

  low:
    - id: "JOURNEY-LOW-001"
      signal: "Journey tests have unclear descriptions"
      evidence_pattern: "Test names don't describe the journey"

  positive:
    - id: "JOURNEY-POS-001"
      signal: "Complete user journeys tested from start to finish"
      evidence_pattern: "Multi-step flows with realistic navigation"
    - id: "JOURNEY-POS-002"
      signal: "Journey tests map to documented user stories"
      evidence_pattern: "Clear traceability between tests and requirements"

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Identify journey tests"
      description: |
        Locate E2E tests that appear to test complete user journeys
        rather than isolated features.
      duration_estimate: "20 min"
      commands:
        - purpose: "Find multi-step tests"
          command: "grep -r -B2 -A20 'describe(' --include='*.spec.*' --include='*.cy.*' . 2>/dev/null | grep -A20 'it(' | head -60"
        - purpose: "Find navigation-heavy tests"
          command: "grep -r -c 'visit\\|navigate' --include='*.spec.*' --include='*.cy.*' . 2>/dev/null | awk -F: '$2 > 2 {print}' | head -15"
      expected_findings:
        - "Journey test candidates"
        - "Multi-step test patterns"

    - id: "2"
      name: "Analyze journey completeness"
      description: |
        Review identified journey tests to verify they test
        complete flows from start to finish.
      duration_estimate: "30 min"
      commands:
        - purpose: "Sample journey test content"
          command: "find . -path '*e2e*' -name '*.spec.*' 2>/dev/null | head -3 | xargs head -80 2>/dev/null"
      questions:
        - "Do tests start from realistic entry points?"
        - "Do tests follow user navigation patterns?"
        - "Do tests verify journey completion?"
      expected_findings:
        - "Journey completeness assessment"
        - "Missing journey steps"

    - id: "3"
      name: "Check journey coverage"
      description: |
        Map journeys to documented user stories and identify
        coverage gaps.
      duration_estimate: "25 min"
      commands:
        - purpose: "Find critical journey keywords"
          command: "grep -r 'signup\\|register\\|login\\|checkout\\|purchase\\|submit' --include='*.spec.*' --include='*.cy.*' . 2>/dev/null | head -20"
      expected_findings:
        - "Critical journey coverage"
        - "Coverage gaps"

    - id: "4"
      name: "Evaluate journey realism"
      description: |
        Assess whether journey tests represent realistic user
        behavior or use unrealistic shortcuts.
      duration_estimate: "15 min"
      commands:
        - purpose: "Find potential shortcuts"
          command: "grep -r 'localStorage\\|setCookie\\|request(' --include='*.spec.*' --include='*.cy.*' . 2>/dev/null | head -10"
      expected_findings:
        - "Shortcut usage"
        - "Realism assessment"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "journey_map"
      format: "table"
      sections:
        - "Journey Inventory"
        - "Completeness Assessment"
        - "Coverage Analysis"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "User Journey Testing Assessment"
        - "Recommendations"

  confidence_guidance:
    high: "Journey tests executed and mapped to requirements"
    medium: "Test content reviewed without execution"
    low: "Based on file patterns only"

offline:
  capability: "partial"

  cache_manifest:
    knowledge:
      - source_id: "user-journey-testing"
        priority: "required"

profiles:
  membership:
    quick:
      included: false
      reason: "Journey analysis requires thorough review"
    full:
      included: true
      priority: 2

closeout_checklist:
  - id: "journey-001"
    item: "Journey tests identified"
    level: "CRITICAL"
    verification: "manual"
    verification_notes: "List tests that cover complete user journeys"
    expected: "Confirmed by reviewer"

  - id: "journey-002"
    item: "Journey completeness assessed"
    level: "BLOCKING"
    verification: "manual"
    verification_notes: "Verify journeys test start to finish"
    expected: "Confirmed by reviewer"

  - id: "journey-003"
    item: "Critical journeys covered"
    level: "BLOCKING"
    verification: "grep -r 'login\\|checkout' --include='*.spec.*' . | wc -l"
    expected: "PASS (count > 0)"

governance:
  applicable_to:
    archetypes: ["all"]

  compliance_frameworks:
    - framework: "ISO 25010"
      controls: ["Usability", "Functional Suitability"]

relationships:
  commonly_combined:
    - "testing-quality-assurance.e2e-testing.e2e-coverage"
    - "testing-quality-assurance.e2e-testing.e2e-test-stability"
    - "testing-quality-assurance.e2e-testing.cross-browser-testing"
