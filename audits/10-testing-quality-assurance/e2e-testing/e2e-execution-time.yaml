# ============================================================
# AUDIT: E2E Execution Time
# ============================================================
# Evaluates the execution time of E2E tests and strategies for
# maintaining acceptable pipeline feedback times.
# ============================================================

audit:
  id: "testing-quality-assurance.e2e-testing.e2e-execution-time"
  name: "E2E Execution Time"
  version: "1.0.0"
  last_updated: "2026-01-19"
  status: "active"

  category: "testing-quality-assurance"
  category_number: 10
  subcategory: "e2e-testing"

  tier: "expert"
  estimated_duration: "1.5 hours"

  completeness: "complete"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "medium"
  scope: "testing"

  default_profiles:
    - "full"
    - "quality"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Assesses E2E test execution time including total suite duration,
    individual test times, parallelization strategy, and optimization
    opportunities. Evaluates whether execution time enables fast
    feedback or creates deployment bottlenecks.

  why_it_matters: |
    Slow E2E suites delay feedback, increase developer wait time, and
    reduce deployment frequency. Long feedback loops lead to larger,
    riskier deployments and reduced developer productivity. Fast suites
    enable continuous deployment and rapid iteration.

  when_to_run:
    - "CI pipeline optimization"
    - "When adding new E2E tests"
    - "Developer experience reviews"
    - "Deployment frequency improvement initiatives"

prerequisites:
  required_artifacts:
    - type: "e2e_tests"
      description: "End-to-end test files"
    - type: "ci_config"
      description: "CI/CD pipeline configuration"

  access_requirements:
    - "Source code repository access"
    - "CI/CD configuration and metrics"
    - "Test execution reports"

discovery:
  file_patterns:
    - glob: "**/e2e/**/*.{spec,test}.{js,ts}"
      purpose: "E2E test files"
    - glob: "**/.github/workflows/*.yml"
      purpose: "CI workflow files"
    - glob: "**/cypress.config.{js,ts}"
      purpose: "Cypress configuration"

  code_patterns:
    - pattern: "parallel|shard|workers"
      type: "keyword"
      scope: "config"
      purpose: "Identify parallelization config"
    - pattern: "timeout|defaultCommandTimeout"
      type: "keyword"
      scope: "config"
      purpose: "Identify timeout settings"
    - pattern: "matrix|strategy"
      type: "keyword"
      scope: "config"
      purpose: "Identify CI matrix strategy"

knowledge_sources:
  guides:
    - id: "test-parallelization"
      name: "Parallelizing Cypress Tests"
      url: "https://docs.cypress.io/guides/guides/parallelization"
      offline_cache: true
    - id: "playwright-parallel"
      name: "Playwright Parallelism"
      url: "https://playwright.dev/docs/test-parallel"
      offline_cache: true

  learning_resources:
    - id: "accelerate"
      title: "Accelerate: Building High Performing Technology Organizations"
      type: "book"
      reference: "ISBN 978-1942788331"

tooling:
  static_analysis:
    - tool: "test-analyzer"
      purpose: "Analyze test execution patterns"
      offline_capable: true

  infrastructure_tools:
    - tool: "cypress-dashboard"
      purpose: "Test analytics and parallelization"
      command: "cypress run --record --parallel"
    - tool: "playwright"
      purpose: "Built-in parallelization"
      command: "npx playwright test --workers=4"

  scripts:
    - id: "execution-time-analyzer"
      language: "bash"
      purpose: "Analyze E2E execution time patterns"
      source: "inline"
      code: |
        #!/bin/bash
        echo "=== E2E Execution Time Analysis ==="
        echo "Test file count:"
        find . \( -path '*e2e*' -o -path '*cypress*' \) -name '*.spec.*' 2>/dev/null | wc -l
        echo ""
        echo "Parallelization config:"
        grep -r 'parallel\|workers\|shard' --include='*.config.*' --include='*.yml' . 2>/dev/null | head -15
        echo ""
        echo "Timeout configuration:"
        grep -r 'timeout\|defaultCommandTimeout' --include='*.config.*' . 2>/dev/null | head -10

signals:
  critical:
    - id: "TIME-CRIT-001"
      signal: "E2E suite takes >30 minutes"
      evidence_pattern: "Total execution time exceeds 30 minutes"
      explanation: |
        30+ minute suites severely impact feedback loops and deployment
        frequency. Developers avoid running tests or wait excessively.
      remediation: "Parallelize, optimize, or split the test suite"

    - id: "TIME-CRIT-002"
      signal: "No parallelization despite large test count"
      evidence_pattern: ">50 tests running sequentially"
      explanation: |
        Sequential execution of many tests wastes time. Parallelization
        can dramatically reduce total execution time.
      remediation: "Implement parallel test execution"

  high:
    - id: "TIME-HIGH-001"
      signal: "E2E tests block deployment for >15 minutes"
      evidence_pattern: "E2E stage takes >15 minutes in pipeline"
      explanation: |
        Long E2E stages create deployment bottlenecks and reduce
        developer willingness to deploy frequently.
      remediation: "Optimize E2E execution or run asynchronously"

    - id: "TIME-HIGH-002"
      signal: "Individual tests take >2 minutes"
      evidence_pattern: "Single test execution >2 minutes"
      explanation: |
        Long individual tests are often doing too much. They're
        harder to debug and slow the entire suite.
      remediation: "Split long tests or optimize test steps"

  medium:
    - id: "TIME-MED-001"
      signal: "Test suite not sharded across CI jobs"
      evidence_pattern: "Single CI job runs all E2E tests"
      remediation: "Implement test sharding across multiple CI jobs"

    - id: "TIME-MED-002"
      signal: "Slow selectors or inefficient waits"
      evidence_pattern: "Long waits or complex CSS selectors"
      remediation: "Optimize selectors and wait strategies"

  low:
    - id: "TIME-LOW-001"
      signal: "No test execution metrics tracked"
      evidence_pattern: "No performance tracking for tests"

  positive:
    - id: "TIME-POS-001"
      signal: "Effective parallelization in place"
      evidence_pattern: "Tests sharded across multiple workers"
    - id: "TIME-POS-002"
      signal: "E2E suite completes in <10 minutes"
      evidence_pattern: "Fast feedback from E2E tests"

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Assess current execution time"
      description: |
        Determine the current E2E suite execution time from
        CI metrics or local execution.
      duration_estimate: "20 min"
      commands:
        - purpose: "Count test files"
          command: "find . \\( -path '*e2e*' -o -path '*cypress*' \\) -name '*.spec.*' 2>/dev/null | wc -l"
        - purpose: "Count test cases"
          command: "grep -r 'it(\\|test(' --include='*.spec.*' --include='*.cy.*' . 2>/dev/null | wc -l"
      questions:
        - "What is the total suite execution time?"
        - "What is the average test execution time?"
      expected_findings:
        - "Current execution time"
        - "Test count"

    - id: "2"
      name: "Review parallelization"
      description: |
        Examine parallelization configuration and usage.
      duration_estimate: "20 min"
      commands:
        - purpose: "Check parallelization config"
          command: "grep -r 'parallel\\|workers\\|shard' --include='*.config.*' --include='*.yml' . 2>/dev/null | head -20"
        - purpose: "Check CI matrix"
          command: "grep -A10 'matrix\\|strategy' .github/workflows/*.yml 2>/dev/null | head -30"
      expected_findings:
        - "Parallelization strategy"
        - "Worker/shard count"

    - id: "3"
      name: "Identify slow tests"
      description: |
        Find tests that take disproportionately long to execute.
      duration_estimate: "20 min"
      commands:
        - purpose: "Find long timeout settings"
          command: "grep -r 'timeout.*[0-9]\\{5,\\}' --include='*.spec.*' --include='*.cy.*' . 2>/dev/null | head -15"
      questions:
        - "Which tests take longest?"
        - "Are there tests with excessive waits?"
      expected_findings:
        - "Slow test identification"
        - "Timeout patterns"

    - id: "4"
      name: "Evaluate optimization opportunities"
      description: |
        Identify opportunities to reduce execution time.
      duration_estimate: "15 min"
      questions:
        - "Can more tests run in parallel?"
        - "Can tests be split or optimized?"
        - "Are there unnecessary waits?"
      expected_findings:
        - "Optimization opportunities"
        - "Specific recommendations"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "execution_report"
      format: "table"
      sections:
        - "Execution Time Metrics"
        - "Parallelization Assessment"
        - "Optimization Opportunities"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Execution Time Assessment"
        - "Recommendations"

  confidence_guidance:
    high: "Execution metrics from CI/CD system"
    medium: "Configuration review with estimates"
    low: "Based on test count only"

offline:
  capability: "partial"

  cache_manifest:
    knowledge:
      - source_id: "test-parallelization"
        priority: "required"

profiles:
  membership:
    quick:
      included: true
      reason: "Quick check for parallelization"
    full:
      included: true
      priority: 2

closeout_checklist:
  - id: "time-001"
    item: "Execution time documented"
    level: "CRITICAL"
    verification: "manual"
    verification_notes: "Document current E2E suite execution time"
    expected: "Confirmed by reviewer"

  - id: "time-002"
    item: "Parallelization assessed"
    level: "BLOCKING"
    verification: "grep -r 'parallel\\|workers' --include='*.config.*' . | wc -l"
    expected: "PASS (strategy documented)"

  - id: "time-003"
    item: "Optimization opportunities identified"
    level: "WARNING"
    verification: "manual"
    verification_notes: "List specific optimization recommendations"
    expected: "Confirmed by reviewer"

governance:
  applicable_to:
    archetypes: ["all"]

  compliance_frameworks:
    - framework: "DORA Metrics"
      controls: ["Lead Time for Changes"]

relationships:
  commonly_combined:
    - "testing-quality-assurance.e2e-testing.e2e-test-stability"
    - "testing-quality-assurance.e2e-testing.e2e-coverage"
    - "testing-quality-assurance.test-strategy.test-pyramid-balance"
