# ============================================================
# AUDIT: Performance Baseline
# ============================================================
# Evaluates establishment and maintenance of performance baselines
# for measuring and detecting performance changes.
# ============================================================

audit:
  id: "testing-quality-assurance.performance-testing.performance-baseline"
  name: "Performance Baseline"
  version: "1.0.0"
  last_updated: "2026-01-19"
  status: "active"

  category: "testing-quality-assurance"
  category_number: 10
  subcategory: "performance-testing"

  tier: "expert"
  estimated_duration: "3 hours"

  completeness: "complete"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "testing"

  default_profiles:
    - "full"
    - "production"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Examines performance baseline establishment, documentation, and maintenance
    practices. Reviews baseline metrics definition, measurement methodology,
    storage and versioning of baselines, and processes for updating baselines
    as the system evolves. Evaluates whether baselines enable meaningful
    performance regression detection.

  why_it_matters: |
    Without established baselines, there is no reference point for detecting
    performance changes. Teams cannot identify regressions, validate optimizations,
    or set realistic performance goals. Baselines provide the foundation for
    all performance analysis and capacity planning decisions.

  when_to_run:
    - "Initial project setup"
    - "After major releases"
    - "When performance requirements change"
    - "Quarterly baseline validation"

prerequisites:
  required_artifacts:
    - type: "performance-metrics"
      description: "Defined performance metrics and KPIs"
    - type: "monitoring-setup"
      description: "Monitoring and metrics collection infrastructure"

  access_requirements:
    - "Performance monitoring dashboards"
    - "Historical metrics data"
    - "Baseline documentation repository"

discovery:
  file_patterns:
    - glob: "**/baseline/**"
      purpose: "Baseline configuration directories"
    - glob: "**/*baseline*.{json,yaml,yml}"
      purpose: "Baseline definition files"
    - glob: "**/performance/**/*.json"
      purpose: "Performance data files"

  code_patterns:
    - pattern: "baseline|reference|target"
      type: "keyword"
      scope: "config"
      purpose: "Baseline configuration"
    - pattern: "p50|p95|p99|percentile"
      type: "keyword"
      scope: "config"
      purpose: "Latency percentile definitions"
    - pattern: "throughput|latency|response.*time"
      type: "regex"
      scope: "config"
      purpose: "Performance metric definitions"

  metrics_queries:
    - system: "Prometheus"
      query: "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))"
      purpose: "Current P95 latency for baseline comparison"
      threshold: "Should match or beat documented baseline"
    - system: "Prometheus"
      query: "rate(http_requests_total[5m])"
      purpose: "Current throughput for baseline comparison"
      threshold: "Should meet documented baseline capacity"

knowledge_sources:
  guides:
    - id: "google-sre"
      name: "Google SRE Book - Service Level Objectives"
      url: "https://sre.google/sre-book/service-level-objectives/"
      offline_cache: true

  learning_resources:
    - id: "perf-eng"
      title: "The Art of Capacity Planning"
      type: "book"
      reference: "John Allspaw, O'Reilly"

tooling:
  monitoring_queries:
    - system: "Prometheus"
      query: "http_request_duration_seconds{quantile='0.95'}"
      purpose: "P95 latency baseline measurement"
    - system: "Prometheus"
      query: "sum(rate(http_requests_total[5m]))"
      purpose: "Throughput baseline measurement"

  infrastructure_tools:
    - tool: "performance-metrics-collector"
      purpose: "Collect and store baseline metrics"
      command: "collect-baselines --output baseline.json"

signals:
  critical:
    - id: "BASELINE-CRIT-001"
      signal: "No performance baselines established"
      evidence_pattern: "Absence of baseline definitions or historical performance data"
      explanation: |
        Without baselines, there is no reference for performance comparison.
        Regressions go undetected, optimizations cannot be validated, and
        capacity planning is pure guesswork.
      remediation: "Establish documented baselines for all critical performance metrics"

    - id: "BASELINE-CRIT-002"
      signal: "Baselines not tied to specific system versions"
      evidence_pattern: "Baseline data without version or commit references"
      explanation: |
        Unversioned baselines cannot be correlated with code changes.
        When performance changes, there's no way to identify which change
        caused the regression or improvement.
      remediation: "Version baselines with git commits or release tags"

  high:
    - id: "BASELINE-HIGH-001"
      signal: "Baselines outdated by more than 3 months"
      evidence_pattern: "Baseline timestamps older than current quarter"
      explanation: |
        Stale baselines become irrelevant as systems evolve. Comparing against
        obsolete baselines provides misleading signals and false confidence.
      remediation: "Update baselines quarterly or after significant changes"

    - id: "BASELINE-HIGH-002"
      signal: "Baseline metrics don't match production monitoring"
      evidence_pattern: "Different metrics in baselines vs production dashboards"
      explanation: |
        Misaligned metrics prevent meaningful comparison between baseline
        and production performance. Teams may optimize the wrong metrics.
      remediation: "Align baseline metrics with production monitoring definitions"

  medium:
    - id: "BASELINE-MED-001"
      signal: "Baselines lack confidence intervals"
      evidence_pattern: "Single-value baselines without variance information"
      remediation: "Include variance and confidence intervals in baseline definitions"

    - id: "BASELINE-MED-002"
      signal: "No process for baseline updates"
      evidence_pattern: "Missing documentation for baseline refresh procedures"
      remediation: "Document baseline update triggers and procedures"

  low:
    - id: "BASELINE-LOW-001"
      signal: "Baseline history not preserved"
      remediation: "Maintain historical baseline versions for trend analysis"

  positive:
    - id: "BASELINE-POS-001"
      signal: "Comprehensive versioned baselines with regular updates"
    - id: "BASELINE-POS-002"
      signal: "Baselines integrated with regression detection"

procedure:
  context:
    cognitive_mode: "critical"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Identify baseline definitions"
      description: |
        Search for baseline configuration files, performance documentation,
        and historical performance data.
      duration_estimate: "25 min"
      commands:
        - purpose: "Find baseline configuration files"
          command: "find . -type f -name '*baseline*' 2>/dev/null"
        - purpose: "Search for performance targets in docs"
          command: "grep -r 'baseline\\|target.*latency\\|target.*throughput' docs/ 2>/dev/null | head -20"
      expected_findings:
        - "Baseline definition files"
        - "Performance target documentation"

    - id: "2"
      name: "Review baseline metrics"
      description: |
        Examine what metrics are included in baselines and whether they
        cover critical performance dimensions.
      duration_estimate: "30 min"
      commands:
        - purpose: "Check for latency metrics"
          command: "grep -r 'p50\\|p95\\|p99\\|latency' --include='*.json' --include='*.yaml' 2>/dev/null | head -20"
        - purpose: "Check for throughput metrics"
          command: "grep -r 'throughput\\|rps\\|requests.*second' --include='*.json' --include='*.yaml' 2>/dev/null"
      expected_findings:
        - "Latency percentile definitions"
        - "Throughput targets"

    - id: "3"
      name: "Verify baseline versioning"
      description: |
        Check that baselines are versioned and tied to specific system
        versions or commits.
      duration_estimate: "25 min"
      commands:
        - purpose: "Check for version information in baselines"
          command: "grep -r 'version\\|commit\\|tag\\|release' --include='*baseline*' 2>/dev/null"
      expected_findings:
        - "Version references in baseline files"
        - "Commit or tag associations"

    - id: "4"
      name: "Check baseline freshness"
      description: |
        Verify baselines are current and have been updated within
        acceptable timeframes.
      duration_estimate: "20 min"
      commands:
        - purpose: "Check baseline file timestamps"
          command: "find . -name '*baseline*' -type f -exec stat --format='%n: %y' {} \\; 2>/dev/null"
      expected_findings:
        - "Recent baseline update dates"
        - "Update frequency patterns"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"
    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Baseline Coverage Analysis"
        - "Freshness Assessment"
        - "Recommendations"

  confidence_guidance:
    high: "Baselines documented, versioned, and regularly updated"
    medium: "Baselines exist but versioning or freshness unclear"
    low: "Limited visibility into baseline practices"

offline:
  capability: "full"
  cache_manifest:
    knowledge:
      - source_id: "google-sre"
        priority: "recommended"

profiles:
  membership:
    quick:
      included: false
      reason: "Requires historical analysis"
    full:
      included: true
      priority: 2
    production:
      included: true
      priority: 1

closeout_checklist:
  - id: "performance-baseline-001"
    item: "Performance baselines are defined"
    level: "CRITICAL"
    verification: "find . -type f -name '*baseline*' 2>/dev/null | head -1 | grep -q . && echo PASS || echo FAIL"
    expected: "PASS"

  - id: "performance-baseline-002"
    item: "Baselines include version information"
    level: "BLOCKING"
    verification: "grep -r 'version\\|commit' --include='*baseline*' 2>/dev/null | grep -q . && echo PASS || echo FAIL"
    expected: "PASS"

  - id: "performance-baseline-003"
    item: "Baselines updated within last quarter"
    level: "WARNING"
    verification: "manual"
    verification_notes: "Reviewer confirms baseline files updated within 90 days"
    expected: "Confirmed by reviewer"

governance:
  applicable_to:
    archetypes: ["web-application", "api-service", "microservices"]

  compliance_frameworks:
    - framework: "SOC2"
      controls: ["CC7.1"]

relationships:
  commonly_combined:
    - "testing-quality-assurance.performance-testing.performance-regression"
    - "testing-quality-assurance.performance-testing.benchmark-testing"
    - "testing-quality-assurance.performance-testing.load-testing"
