# ============================================================
# AUDIT: Data Masking
# ============================================================
# Evaluates data masking and anonymization practices for test
# environments to protect sensitive information.
# ============================================================

audit:
  id: "testing-quality-assurance.test-data-management.data-masking"
  name: "Data Masking"
  version: "1.0.0"
  last_updated: "2026-01-19"
  status: "active"

  category: "testing-quality-assurance"
  category_number: 10
  subcategory: "test-data-management"

  tier: "expert"
  estimated_duration: "4 hours"

  completeness: "complete"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "critical"
  scope: "security"

  default_profiles:
    - "full"
    - "security"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Examines data masking and anonymization practices to ensure sensitive
    information is protected when used in test environments. Reviews
    masking techniques, coverage of sensitive fields, referential
    integrity preservation, and compliance with data protection regulations.

  why_it_matters: |
    Unmasked production data in test environments creates privacy and
    compliance risks. PII, financial data, and health information must
    be protected everywhere it exists. Data breaches from test environments
    carry the same regulatory and reputational consequences as production.

  when_to_run:
    - "Before using production-derived data"
    - "During compliance audits"
    - "After data model changes affecting PII"
    - "When provisioning new test environments"

prerequisites:
  required_artifacts:
    - type: "data-classification"
      description: "Inventory of sensitive data fields"
    - type: "masking-configuration"
      description: "Data masking rules and configurations"

  access_requirements:
    - "Data masking tool access"
    - "Test database access"
    - "Data classification documentation"

discovery:
  file_patterns:
    - glob: "**/masking/**"
      purpose: "Data masking configurations"
    - glob: "**/anonymize*/**"
      purpose: "Anonymization scripts"
    - glob: "**/*mask*.{sql,py,js}"
      purpose: "Masking scripts"

  code_patterns:
    - pattern: "mask|anonymize|redact|obfuscate"
      type: "keyword"
      scope: "source"
      purpose: "Masking function usage"
    - pattern: "PII|ssn|email|phone|address"
      type: "keyword"
      scope: "config"
      purpose: "Sensitive field identification"
    - pattern: "encrypt|hash|token"
      type: "keyword"
      scope: "source"
      purpose: "Data protection methods"

knowledge_sources:
  specifications:
    - id: "gdpr"
      name: "GDPR Article 89 - Safeguards for Research"
      url: "https://gdpr-info.eu/art-89-gdpr/"
      offline_cache: true
      priority: "required"
    - id: "hipaa-deident"
      name: "HIPAA De-identification Standard"
      url: "https://www.hhs.gov/hipaa/for-professionals/privacy/special-topics/de-identification/index.html"
      offline_cache: true
      priority: "recommended"

  guides:
    - id: "data-masking-guide"
      name: "Data Masking Best Practices"
      url: "https://www.nist.gov/privacy-framework"
      offline_cache: true

tooling:
  infrastructure_tools:
    - tool: "Delphix"
      purpose: "Enterprise data masking"
      command: "Built-in masking engine"
    - tool: "AWS DMS"
      purpose: "Database migration with masking"
      command: "dms-cli create-replication-task --table-mappings"
    - tool: "Tonic"
      purpose: "Synthetic test data generation"
      command: "tonic generate"

  scripts:
    - id: "mask-data"
      language: "python"
      purpose: "Basic data masking example"
      source: "inline"
      code: |
        import hashlib
        import re

        def mask_email(email):
            """Mask email while preserving format"""
            local, domain = email.split('@')
            masked_local = local[0] + '*' * (len(local) - 2) + local[-1]
            return f"{masked_local}@{domain}"

        def mask_ssn(ssn):
            """Mask SSN keeping last 4"""
            return f"XXX-XX-{ssn[-4:]}"

        def mask_name(name):
            """Replace with consistent fake"""
            return hashlib.md5(name.encode()).hexdigest()[:8]

signals:
  critical:
    - id: "MASK-CRIT-001"
      signal: "Unmasked PII in test environments"
      evidence_pattern: "Real SSNs, emails, or addresses in test data"
      explanation: |
        Unmasked PII in test environments violates privacy regulations
        and creates breach risk. Test environments often have weaker
        security controls, making exposure more likely.
      remediation: "Implement comprehensive data masking before data reaches test environments"

    - id: "MASK-CRIT-002"
      signal: "No data masking process exists"
      evidence_pattern: "Production data copied directly to test without transformation"
      explanation: |
        Without masking processes, every use of production data in testing
        creates compliance violations. This is a systematic gap that
        affects all test data operations.
      remediation: "Establish automated data masking pipeline for all production-derived data"

  high:
    - id: "MASK-HIGH-001"
      signal: "Incomplete masking coverage"
      evidence_pattern: "Some sensitive fields masked but others missed"
      explanation: |
        Partial masking provides false assurance. Attackers can often
        reconstruct masked data from unmasked related fields. All PII
        must be consistently protected.
      remediation: "Audit all fields for sensitivity and ensure complete masking coverage"

    - id: "MASK-HIGH-002"
      signal: "Masking breaks referential integrity"
      evidence_pattern: "Masked data inconsistent across related tables"
      explanation: |
        Inconsistent masking makes data unusable for testing and may
        expose relationships that reveal original values. Masking must
        preserve referential integrity.
      remediation: "Use consistent masking that maintains referential integrity"

  medium:
    - id: "MASK-MED-001"
      signal: "Masking not automated"
      evidence_pattern: "Manual masking processes"
      remediation: "Automate data masking in data provisioning pipeline"

    - id: "MASK-MED-002"
      signal: "Masking reversible without proper controls"
      evidence_pattern: "Simple substitution or deterministic encryption without key management"
      remediation: "Use one-way masking or properly managed encryption keys"

  low:
    - id: "MASK-LOW-001"
      signal: "Masking rules not documented"
      remediation: "Document masking rules and sensitive field inventory"

  positive:
    - id: "MASK-POS-001"
      signal: "Comprehensive automated data masking"
    - id: "MASK-POS-002"
      signal: "Referential integrity preserved with consistent masking"

procedure:
  context:
    cognitive_mode: "critical"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Identify masking infrastructure"
      description: |
        Search for data masking tools, configurations, and scripts.
      duration_estimate: "30 min"
      commands:
        - purpose: "Find masking configurations"
          command: "find . -type f \\( -name '*mask*' -o -name '*anonymize*' \\) 2>/dev/null"
        - purpose: "Check for masking functions"
          command: "grep -r 'mask\\|anonymize\\|redact' . --include='*.py' --include='*.sql' --include='*.js' 2>/dev/null | head -20"
      expected_findings:
        - "Masking configurations"
        - "Masking implementations"

    - id: "2"
      name: "Review sensitive field coverage"
      description: |
        Verify that all sensitive fields are identified and masked.
      duration_estimate: "45 min"
      commands:
        - purpose: "Find PII field references"
          command: "grep -r 'email\\|phone\\|ssn\\|address\\|birth.*date' . --include='*.sql' --include='*.yaml' 2>/dev/null | head -30"
        - purpose: "Check masking rules"
          command: "grep -r 'mask.*config\\|masking.*rule' . --include='*.yaml' --include='*.json' 2>/dev/null"
      expected_findings:
        - "Sensitive field inventory"
        - "Masking rule coverage"

    - id: "3"
      name: "Verify masking consistency"
      description: |
        Check that masking preserves referential integrity across
        related tables.
      duration_estimate: "35 min"
      questions:
        - "Is the same value masked consistently across tables?"
        - "Are foreign key relationships preserved?"
        - "Can masked data be used for testing?"
      expected_findings:
        - "Referential integrity preservation"
        - "Masking consistency"

    - id: "4"
      name: "Test for unmasked data"
      description: |
        Sample test data to verify masking effectiveness.
      duration_estimate: "30 min"
      commands:
        - purpose: "Check test data for patterns"
          command: "find . -path '*/test*' -name '*.json' -exec grep -l '@.*\\.com\\|\\d{3}-\\d{2}-\\d{4}' {} \\; 2>/dev/null | head -10"
      expected_findings:
        - "Masking validation"
        - "Exposure identification"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"
    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Masking Coverage Analysis"
        - "Compliance Assessment"
        - "Recommendations"

  confidence_guidance:
    high: "Masking verified, coverage confirmed, test data validated"
    medium: "Configuration reviewed but data not validated"
    low: "Limited visibility into masking practices"

offline:
  capability: "partial"
  cache_manifest:
    knowledge:
      - source_id: "gdpr"
        priority: "required"

profiles:
  membership:
    quick:
      included: false
      reason: "Requires detailed compliance analysis"
    full:
      included: true
      priority: 1
    security:
      included: true
      priority: 1

closeout_checklist:
  - id: "data-masking-001"
    item: "Data masking process exists"
    level: "CRITICAL"
    verification: "find . -type f \\( -name '*mask*' -o -name '*anonymize*' \\) 2>/dev/null | head -1 | grep -q . && echo PASS || echo FAIL"
    expected: "PASS"

  - id: "data-masking-002"
    item: "All PII fields identified and masked"
    level: "BLOCKING"
    verification: "manual"
    verification_notes: "Reviewer confirms sensitive field inventory and masking coverage"
    expected: "Confirmed by reviewer"

  - id: "data-masking-003"
    item: "No unmasked PII in test data"
    level: "WARNING"
    verification: "manual"
    verification_notes: "Reviewer samples test data for unmasked PII"
    expected: "Confirmed by reviewer"

governance:
  applicable_to:
    archetypes: ["web-application", "api-service", "data-platform"]

  compliance_frameworks:
    - framework: "GDPR"
      controls: ["Art. 5", "Art. 25", "Art. 89"]
    - framework: "HIPAA"
      controls: ["164.514"]
    - framework: "PCI-DSS"
      controls: ["3.3", "3.4"]

relationships:
  commonly_combined:
    - "testing-quality-assurance.test-data-management.test-data-generation"
    - "testing-quality-assurance.test-data-management.database-seeding"
