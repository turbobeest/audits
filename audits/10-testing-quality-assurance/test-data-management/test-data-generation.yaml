# ============================================================
# AUDIT: Test Data Generation
# ============================================================
# Evaluates practices for generating realistic and comprehensive
# test data for automated testing.
# ============================================================

audit:
  id: "testing-quality-assurance.test-data-management.test-data-generation"
  name: "Test Data Generation"
  version: "1.0.0"
  last_updated: "2026-01-19"
  status: "active"

  category: "testing-quality-assurance"
  category_number: 10
  subcategory: "test-data-management"

  tier: "expert"
  estimated_duration: "3 hours"

  completeness: "complete"
  requires_runtime: false
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "testing"

  default_profiles:
    - "full"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Examines test data generation practices including synthetic data
    creation, faker libraries usage, edge case coverage, and data
    variety strategies. Reviews how test data represents realistic
    production scenarios while remaining reproducible.

  why_it_matters: |
    Tests are only as good as their data. Inadequate test data misses
    edge cases, internationalization issues, and real-world scenarios.
    Good test data generation ensures comprehensive coverage while
    maintaining reproducibility and avoiding production data exposure.

  when_to_run:
    - "Test suite development"
    - "After domain model changes"
    - "When test coverage gaps identified"
    - "During compliance reviews"

prerequisites:
  required_artifacts:
    - type: "data-generators"
      description: "Test data generation configurations and factories"
    - type: "domain-model"
      description: "Understanding of data requirements"

  access_requirements:
    - "Test code repository access"
    - "Data schema documentation"

discovery:
  file_patterns:
    - glob: "**/factories/**"
      purpose: "Factory pattern implementations"
    - glob: "**/fixtures/**"
      purpose: "Test fixture files"
    - glob: "**/*factory*.{js,py,rb,java}"
      purpose: "Factory files"
    - glob: "**/*faker*.{js,py,rb}"
      purpose: "Faker configurations"

  code_patterns:
    - pattern: "faker|Faker|fake|generate"
      type: "keyword"
      scope: "source"
      purpose: "Data generation libraries"
    - pattern: "factory|Factory|builder|Builder"
      type: "keyword"
      scope: "source"
      purpose: "Factory pattern usage"
    - pattern: "seed|random|uuid"
      type: "keyword"
      scope: "source"
      purpose: "Randomization and seeding"

knowledge_sources:
  guides:
    - id: "faker-docs"
      name: "Faker Library Documentation"
      url: "https://faker.readthedocs.io/"
      offline_cache: true
    - id: "factory-bot"
      name: "FactoryBot Documentation"
      url: "https://github.com/thoughtbot/factory_bot/wiki"
      offline_cache: true

  learning_resources:
    - id: "test-data-book"
      title: "Data-Driven Testing"
      type: "article"
      reference: "Martin Fowler articles"

tooling:
  static_analysis:
    - tool: "Faker"
      purpose: "Python fake data generation"
      offline_capable: true
    - tool: "faker.js"
      purpose: "JavaScript fake data generation"
      offline_capable: true
    - tool: "FactoryBot"
      purpose: "Ruby factory pattern"
      offline_capable: true
    - tool: "AutoFixture"
      purpose: ".NET test data generation"
      offline_capable: true

  scripts:
    - id: "generate-data"
      language: "python"
      purpose: "Generate test data"
      source: "inline"
      code: |
        from faker import Faker
        import json

        fake = Faker()
        Faker.seed(42)  # Reproducible

        users = [
            {
                'id': i,
                'name': fake.name(),
                'email': fake.email(),
                'created_at': fake.date_time().isoformat()
            }
            for i in range(100)
        ]

        print(json.dumps(users, indent=2))

signals:
  critical:
    - id: "DATAGEN-CRIT-001"
      signal: "Production data used in tests"
      evidence_pattern: "Database dumps or production exports in test data"
      explanation: |
        Using production data in tests risks exposing PII and violating
        privacy regulations. Production data may also cause tests to
        be non-reproducible and tied to specific data states.
      remediation: "Replace production data with synthetic data generation"

    - id: "DATAGEN-CRIT-002"
      signal: "No test data generation strategy"
      evidence_pattern: "Hardcoded literal values throughout tests"
      explanation: |
        Hardcoded test data is difficult to maintain and doesn't scale.
        Tests become brittle, changes require updates in many places,
        and edge cases are easily missed.
      remediation: "Implement test data generation using factories or fakers"

  high:
    - id: "DATAGEN-HIGH-001"
      signal: "Test data not reproducible"
      evidence_pattern: "Random data without seeding"
      explanation: |
        Non-reproducible test data makes debugging failures difficult.
        Tests that sometimes pass and sometimes fail due to data variations
        erode confidence in the test suite.
      remediation: "Seed random generators for reproducible test data"

    - id: "DATAGEN-HIGH-002"
      signal: "Edge cases not represented in test data"
      evidence_pattern: "Only happy path data, no boundary conditions"
      explanation: |
        Missing edge cases means missing bugs. Empty strings, null values,
        unicode characters, and boundary conditions often reveal bugs
        that normal data doesn't expose.
      remediation: "Include edge case data in generation strategies"

  medium:
    - id: "DATAGEN-MED-001"
      signal: "Test data lacks international variety"
      evidence_pattern: "Only ASCII/English data in tests"
      remediation: "Include internationalized test data (unicode, RTL, locales)"

    - id: "DATAGEN-MED-002"
      signal: "Data factories not well organized"
      evidence_pattern: "Scattered data generation without central factories"
      remediation: "Centralize data generation in organized factory modules"

  low:
    - id: "DATAGEN-LOW-001"
      signal: "Test data generation not documented"
      remediation: "Document data generation patterns and factories"

  positive:
    - id: "DATAGEN-POS-001"
      signal: "Comprehensive synthetic data generation with edge cases"
    - id: "DATAGEN-POS-002"
      signal: "Reproducible seeded data with international variety"

procedure:
  context:
    cognitive_mode: "critical"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Identify data generation tools"
      description: |
        Search for data generation libraries, factories, and configurations.
      duration_estimate: "25 min"
      commands:
        - purpose: "Find faker usage"
          command: "grep -r 'faker\\|Faker\\|fake' . --include='*.py' --include='*.js' --include='*.ts' 2>/dev/null | head -20"
        - purpose: "Find factory patterns"
          command: "find . -type f \\( -name '*factory*' -o -name '*Factory*' \\) -not -path '*/node_modules/*' 2>/dev/null"
      expected_findings:
        - "Data generation libraries"
        - "Factory implementations"

    - id: "2"
      name: "Review data reproducibility"
      description: |
        Check for seeding and reproducibility in data generation.
      duration_estimate: "25 min"
      commands:
        - purpose: "Check for seeding"
          command: "grep -r 'seed\\|Seed\\|random.seed' . --include='*.py' --include='*.js' 2>/dev/null | head -20"
      expected_findings:
        - "Seeding configuration"
        - "Reproducibility patterns"

    - id: "3"
      name: "Assess edge case coverage"
      description: |
        Review test data for edge cases, boundary conditions, and
        special characters.
      duration_estimate: "30 min"
      commands:
        - purpose: "Check for edge case data"
          command: "grep -r 'edge\\|boundary\\|null\\|empty\\|unicode' . --include='*test*' --include='*spec*' 2>/dev/null | head -20"
      expected_findings:
        - "Edge case test data"
        - "Boundary value testing"

    - id: "4"
      name: "Check for production data"
      description: |
        Verify that production data is not used in tests.
      duration_estimate: "20 min"
      commands:
        - purpose: "Check for production data indicators"
          command: "find . -path '*/test*' -type f \\( -name '*dump*' -o -name '*backup*' -o -name '*prod*' \\) 2>/dev/null"
      expected_findings:
        - "Absence of production data"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"
    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Data Generation Assessment"
        - "Edge Case Coverage Analysis"
        - "Recommendations"

  confidence_guidance:
    high: "Generation verified, reproducibility confirmed, edge cases validated"
    medium: "Tools identified but coverage not fully assessed"
    low: "Limited visibility into data generation practices"

offline:
  capability: "full"
  cache_manifest:
    knowledge:
      - source_id: "faker-docs"
        priority: "recommended"

profiles:
  membership:
    quick:
      included: false
      reason: "Requires detailed data analysis"
    full:
      included: true
      priority: 2

closeout_checklist:
  - id: "data-generation-001"
    item: "Synthetic data generation implemented"
    level: "CRITICAL"
    verification: "grep -r 'faker\\|Faker\\|Factory' . --include='*.py' --include='*.js' 2>/dev/null | grep -q . && echo PASS || echo FAIL"
    expected: "PASS"

  - id: "data-generation-002"
    item: "Data generation is reproducible"
    level: "BLOCKING"
    verification: "grep -r 'seed' . --include='*.py' --include='*.js' 2>/dev/null | grep -q . && echo PASS || echo FAIL"
    expected: "PASS"

  - id: "data-generation-003"
    item: "No production data in tests"
    level: "WARNING"
    verification: "! find . -path '*/test*' -name '*prod*.sql' 2>/dev/null | grep -q . && echo PASS || echo FAIL"
    expected: "PASS"

governance:
  applicable_to:
    archetypes: ["all"]

  compliance_frameworks:
    - framework: "GDPR"
      controls: ["Art. 5"]
    - framework: "HIPAA"
      controls: ["164.502"]

relationships:
  commonly_combined:
    - "testing-quality-assurance.test-data-management.data-masking"
    - "testing-quality-assurance.test-data-management.test-fixture-management"
