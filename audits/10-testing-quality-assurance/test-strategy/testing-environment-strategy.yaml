# ============================================================
# AUDIT: Testing Environment Strategy
# ============================================================
# Evaluates the organization's approach to managing test
# environments across development, staging, and production.
# ============================================================

audit:
  id: "testing-quality-assurance.test-strategy.testing-environment-strategy"
  name: "Testing Environment Strategy"
  version: "1.0.0"
  last_updated: "2026-01-19"
  status: "active"

  category: "testing-quality-assurance"
  category_number: 10
  subcategory: "test-strategy"

  tier: "expert"
  estimated_duration: "2 hours"

  completeness: "complete"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "testing"

  default_profiles:
    - "full"
    - "production"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Assesses the test environment strategy including environment parity
    with production, data management, environment provisioning, isolation
    between test runs, and the ability to reproduce production issues
    in test environments.

  why_it_matters: |
    Test environment issues are a leading cause of "works on my machine"
    problems and production incidents. Poor environment strategy leads to
    tests that pass locally but fail in CI, or pass in staging but fail
    in production. Proper environment management ensures test results
    are reliable and reproducible.

  when_to_run:
    - "CI/CD pipeline setup or migration"
    - "After environment-related incidents"
    - "New service deployment planning"
    - "Infrastructure modernization projects"

prerequisites:
  required_artifacts:
    - type: "infrastructure_config"
      description: "IaC configs for test environments (Terraform, Docker, etc.)"
    - type: "ci_configuration"
      description: "CI/CD pipeline configuration"

  access_requirements:
    - "Access to infrastructure configurations"
    - "CI/CD system access"
    - "Environment documentation"

discovery:
  file_patterns:
    - glob: "**/docker-compose*.yml"
      purpose: "Docker Compose configurations for test environments"
    - glob: "**/Dockerfile*"
      purpose: "Docker configurations"
    - glob: "**/*.tf"
      purpose: "Terraform infrastructure definitions"
    - glob: "**/k8s/**"
      purpose: "Kubernetes configurations"
    - glob: "**/.env.test*"
      purpose: "Test environment variables"
    - glob: "**/testcontainers*"
      purpose: "Testcontainers configuration"

  code_patterns:
    - pattern: "testcontainers|TestContainers"
      type: "keyword"
      scope: "source"
      purpose: "Identify testcontainers usage"
    - pattern: "docker-compose.*test"
      type: "regex"
      scope: "config"
      purpose: "Test-specific compose files"
    - pattern: "DATABASE_URL.*test|TEST_DATABASE"
      type: "regex"
      scope: "config"
      purpose: "Test database configuration"

knowledge_sources:
  guides:
    - id: "12-factor-dev-prod-parity"
      name: "The Twelve-Factor App - Dev/prod parity"
      url: "https://12factor.net/dev-prod-parity"
      offline_cache: true
    - id: "testcontainers"
      name: "Testcontainers Best Practices"
      url: "https://www.testcontainers.org/features/configuration/"
      offline_cache: true

  learning_resources:
    - id: "continuous-delivery"
      title: "Continuous Delivery"
      type: "book"
      reference: "ISBN 978-0321601919"

tooling:
  infrastructure_tools:
    - tool: "docker"
      purpose: "Container-based test environments"
      command: "docker-compose -f docker-compose.test.yml up"
    - tool: "testcontainers"
      purpose: "Programmatic container management for tests"
    - tool: "localstack"
      purpose: "Local AWS service emulation"

  scripts:
    - id: "env-parity-check"
      language: "bash"
      purpose: "Check environment configuration parity"
      source: "inline"
      code: |
        #!/bin/bash
        echo "=== Environment Configuration Analysis ==="
        echo "Docker Compose files:"
        find . -name "docker-compose*.yml" 2>/dev/null | head -10
        echo ""
        echo "Environment files:"
        find . -name ".env*" 2>/dev/null | head -10
        echo ""
        echo "Testcontainers usage:"
        grep -r "testcontainers" --include="*.java" --include="*.ts" --include="*.js" . 2>/dev/null | wc -l

signals:
  critical:
    - id: "ENV-CRIT-001"
      signal: "Tests run against production database or services"
      evidence_pattern: "Production connection strings in test configs"
      explanation: |
        Running tests against production can corrupt real data, cause
        outages, and create security incidents. Test environments must
        be completely isolated from production.
      remediation: "Implement isolated test databases and service mocks"

    - id: "ENV-CRIT-002"
      signal: "No isolated test environment exists"
      evidence_pattern: "Tests share environment with development"
      explanation: |
        Without isolation, test results become unreliable due to
        interference between concurrent test runs or development activity.
      remediation: "Create dedicated test environments with proper isolation"

  high:
    - id: "ENV-HIGH-001"
      signal: "Significant drift between test and production environments"
      evidence_pattern: "Different versions, configurations, or services"
      explanation: |
        Environment drift leads to tests passing in staging but failing
        in production. Parity is essential for reliable test results.
      remediation: "Use IaC to maintain environment parity"

    - id: "ENV-HIGH-002"
      signal: "Test data management strategy undefined"
      evidence_pattern: "No fixtures, factories, or data seeding approach"
      explanation: |
        Without proper test data strategy, tests become brittle and
        dependent on implicit data state that's hard to reproduce.
      remediation: "Implement test data factories and seeding strategies"

  medium:
    - id: "ENV-MED-001"
      signal: "Environment provisioning is manual"
      evidence_pattern: "No IaC or automation for test environments"
      remediation: "Automate environment provisioning with IaC"

    - id: "ENV-MED-002"
      signal: "Environment cleanup between tests is inconsistent"
      evidence_pattern: "Data persists across test runs"
      remediation: "Implement proper teardown and cleanup procedures"

  low:
    - id: "ENV-LOW-001"
      signal: "Environment documentation is outdated"
      evidence_pattern: "Docs don't match actual configuration"

  positive:
    - id: "ENV-POS-001"
      signal: "Testcontainers or similar used for database tests"
      evidence_pattern: "Testcontainers dependency and usage"
    - id: "ENV-POS-002"
      signal: "Environment parity maintained via IaC"
      evidence_pattern: "Terraform/Pulumi configs for all environments"

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Inventory test environments"
      description: |
        Identify all test environments in use and their purposes
        (unit tests, integration tests, E2E, staging, etc.).
      duration_estimate: "20 min"
      commands:
        - purpose: "Find environment configuration files"
          command: "find . -name '.env*' -o -name 'docker-compose*.yml' 2>/dev/null | grep -v node_modules | head -20"
        - purpose: "Check for environment-specific configs"
          command: "find . -type d \\( -name 'environments' -o -name 'envs' -o -name 'config' \\) 2>/dev/null | head -10"
      expected_findings:
        - "List of test environments"
        - "Environment configuration locations"

    - id: "2"
      name: "Assess environment parity"
      description: |
        Compare test environment configurations with production to
        identify drift in versions, services, or configurations.
      duration_estimate: "30 min"
      commands:
        - purpose: "Compare Docker base images"
          command: "grep -h 'FROM\\|image:' Dockerfile* docker-compose*.yml 2>/dev/null | sort -u | head -20"
      questions:
        - "Are service versions the same across environments?"
        - "Are configurations consistent?"
        - "What services are mocked vs real?"
      expected_findings:
        - "Parity assessment between environments"
        - "Documented differences and their justification"

    - id: "3"
      name: "Review data management"
      description: |
        Evaluate how test data is managed, including fixtures,
        factories, seeding, and cleanup procedures.
      duration_estimate: "25 min"
      commands:
        - purpose: "Find test fixtures and factories"
          command: "find . -path '*test*' \\( -name '*fixture*' -o -name '*factory*' -o -name '*seed*' \\) 2>/dev/null | head -20"
      expected_findings:
        - "Test data management approach"
        - "Data isolation mechanisms"

    - id: "4"
      name: "Evaluate environment isolation"
      description: |
        Assess whether test environments are properly isolated from
        each other and from production.
      duration_estimate: "20 min"
      commands:
        - purpose: "Check for production references in test config"
          command: "grep -r 'prod\\|production' --include='.env*' --include='*.yml' . 2>/dev/null | grep -v node_modules | head -10"
      expected_findings:
        - "Isolation verification"
        - "Any cross-environment dependencies"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "environment_inventory"
      format: "table"
      sections:
        - "Environment List"
        - "Parity Assessment"
        - "Data Management"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Environment Health Assessment"
        - "Recommendations"

  confidence_guidance:
    high: "Direct configuration inspection and verification"
    medium: "Configuration files reviewed without runtime verification"
    low: "Based on documentation only"

offline:
  capability: "partial"

  cache_manifest:
    knowledge:
      - source_id: "12-factor-dev-prod-parity"
        priority: "required"

profiles:
  membership:
    quick:
      included: false
      reason: "Environment assessment requires thorough review"
    full:
      included: true
      priority: 2

closeout_checklist:
  - id: "env-001"
    item: "Test environments inventoried"
    level: "CRITICAL"
    verification: "find . -name 'docker-compose*.yml' -o -name '.env.test*' | wc -l"
    expected: "PASS (count >= 0)"

  - id: "env-002"
    item: "Environment parity assessed"
    level: "BLOCKING"
    verification: "manual"
    verification_notes: "Document differences between test and production environments"
    expected: "Confirmed by reviewer"

  - id: "env-003"
    item: "No production data in test environments"
    level: "CRITICAL"
    verification: "grep -r 'prod' --include='.env.test*' . 2>/dev/null | wc -l"
    expected: "PASS (count = 0)"

governance:
  applicable_to:
    archetypes: ["all"]

  compliance_frameworks:
    - framework: "SOC 2"
      controls: ["Environment Segregation"]
    - framework: "GDPR"
      controls: ["Data Protection"]

relationships:
  commonly_combined:
    - "testing-quality-assurance.integration-testing.integration-test-isolation"
    - "testing-quality-assurance.e2e-testing.e2e-test-stability"
    - "reliability-resilience.disaster-recovery.environment-recovery"
