audit:
  id: responsible-design.content-harm.misinformation-amplification
  name: Misinformation Amplification Audit
  version: 1.0.0
  last_updated: '2025-01-19'
  status: active
  category: ethical-societal
  category_number: 21
  subcategory: content-harm
  tier: expert
  estimated_duration: 4-6 hours  # median: 5h
  completeness: requires_discovery
  requires_runtime: true
  destructive: false
execution:
  automatable: partial
  severity: critical
  scope: qualitative
  default_profiles:
  - full
  blocks_phase: false
  parallelizable: false
description:
  what: |
    Evaluates whether platform systems amplify misinformation through
    recommendation algorithms, engagement optimization, or content
    distribution. Assesses whether viral dynamics favor false content,
    whether fact-checking reduces amplification, and whether systems
    have misinformation safeguards.
  why_it_matters: |
    Misinformation amplification causes significant harm:

    - Health misinformation can cause death and disease
    - Election misinformation undermines democracy
    - Financial misinformation causes economic harm
    - EU DSA requires systemic risk assessment for misinformation
    - Platform liability increasing for amplification
    - Reputational damage from being misinformation vector
  when_to_run:
  - For platforms with user-generated content
  - When content recommendation systems exist
  - During EU DSA compliance
  - After misinformation incidents
prerequisites:
  required_artifacts:
  - type: recommendation_systems
    description: Documentation of content recommendation algorithms
  - type: moderation_policies
    description: Misinformation policies and enforcement
  access_requirements:
  - Algorithm documentation
  - Moderation system access
  - Interview access to trust & safety
discovery:
  interviews:
  - role: Trust & Safety Lead
    questions:
    - How do you identify misinformation?
    - What happens when misinformation is detected?
    - How does detection affect algorithmic distribution?
    - What metrics track misinformation spread?
    purpose: Understand misinformation response
    duration: 45 min
  - role: Recommendation System Lead
    questions:
    - How does engagement influence recommendations?
    - Are there safeguards against viral misinformation?
    - How does fact-checking affect distribution?
    - What friction exists for potentially false content?
    purpose: Understand algorithmic safeguards
    duration: 45 min
  documents_to_review:
  - type: Misinformation Policy
    purpose: Review policy and enforcement
    look_for:
    - Definition of misinformation
    - Enforcement actions
    - Amplification reduction measures
  - type: Recommendation Algorithm Documentation
    purpose: Review amplification dynamics
    look_for:
    - Engagement optimization
    - Quality signals
    - Misinformation downranking
  file_patterns:
  - glob: '**/ETHICS.md'
    purpose: Ethics documentation
  - glob: '**/PRIVACY*.md'
    purpose: Privacy documentation
  - glob: '**/terms*.md'
    purpose: Terms of service
  - glob: '**/policy*.md'
    purpose: Policy documentation
  code_patterns:
  - pattern: consent|privacy|gdpr|ccpa|cookie
    type: regex
    scope: all
    purpose: Privacy/consent references
signals:
  critical:
  - id: MISINFO-CRIT-001
    signal: Algorithms optimize for engagement regardless of accuracy
    evidence_indicators:
    - No content quality signals in recommendations
    - Viral content promoted without verification
    - Engagement-only optimization
    - False content spreads faster than corrections
    explanation: |
      When algorithms optimize purely for engagement, they may
      preferentially amplify false content that generates emotional
      responses, causing significant harm.
    remediation: |
      - Add content quality signals to recommendations
      - Implement verification friction for viral content
      - Downrank unverified claims
      - Measure and optimize for accuracy
  - id: MISINFO-CRIT-002
    signal: No misinformation detection or response
    evidence_indicators:
    - No fact-checking integration
    - No misinformation policies
    - Known false content circulates freely
    - No response to flagged misinformation
    explanation: |
      Platforms without misinformation response become vectors for
      false information, causing harm and facing increasing liability.
    remediation: |
      - Develop misinformation policies
      - Implement fact-checking integration
      - Create response workflow
      - Monitor misinformation spread
  high:
  - id: MISINFO-HIGH-001
    signal: Fact-checked content continues to spread
    evidence_indicators:
    - Fact-check labels don't reduce distribution
    - False content remains recommended
    - Corrections don't reach original audience
    - Repeat spreaders face no consequences
    explanation: |
      If fact-checking doesn't affect distribution, it fails to
      reduce harm from misinformation amplification.
    remediation: |
      - Reduce distribution of fact-checked false content
      - Ensure corrections reach original viewers
      - Add friction before sharing flagged content
      - Address repeat spreaders
  - id: MISINFO-HIGH-002
    signal: Recommendation systems create echo chambers
    evidence_indicators:
    - Users only see confirming content
    - No exposure to alternative perspectives
    - Algorithmic bubble formation
    - Extremism amplification
    explanation: |
      Echo chambers can amplify misinformation by removing exposure
      to corrections and alternative viewpoints.
    remediation: |
      - Consider viewpoint diversity in recommendations
      - Surface authoritative sources
      - Break filter bubbles for important topics
  medium:
  - id: MISINFO-MED-001
    signal: No metrics on misinformation spread
    evidence_indicators:
    - Misinformation velocity not tracked
    - No measurement of false content reach
    - Corrections not tracked
    remediation: |
      - Implement misinformation tracking
      - Measure spread of known false content
      - Track correction effectiveness
  positive:
  - id: MISINFO-POS-001
    signal: Comprehensive misinformation safeguards
    evidence_indicators:
    - Quality signals in recommendations
    - Fact-checking reduces distribution
    - Corrections reach original audience
    - Metrics track and reduce spread
procedure:
  context:
    cognitive_mode: evaluative
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Recommendation System Review
    description: Assess how recommendations affect misinformation.
    duration_estimate: 1.5 hours
    expected_findings:
    - Amplification dynamics
    - Quality signals presence
  - id: '2'
    name: Policy and Enforcement Review
    description: Review misinformation policies and enforcement.
    duration_estimate: 1 hour
    expected_findings:
    - Policy assessment
    - Enforcement effectiveness
  - id: '3'
    name: Stakeholder Interviews
    description: Interview trust & safety and recommendation teams.
    duration_estimate: 1.5 hours
    expected_findings:
    - Process understanding
    - Gap identification
  - id: '4'
    name: Synthesize Findings
    description: Compile findings and recommendations.
    duration_estimate: 30 min
    expected_findings:
    - Prioritized findings
    - Recommendations
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Amplification Analysis
    - Policy Review
    - Recommendations
  confidence_guidance:
    high: Algorithm reviewed, policies documented, metrics available
    medium: Partial visibility
    low: External assessment only
offline:
  capability: partial
profiles:
  membership:
    quick:
      included: false
      reason: Requires comprehensive analysis
    full:
      included: true
      priority: 85
closeout_checklist:
- id: misinfo-001
  item: Recommendation amplification assessed
  level: CRITICAL
  verification: manual
  verification_notes: Algorithm misinformation dynamics evaluated
  expected: Confirmed by reviewer
- id: misinfo-002
  item: Misinformation response reviewed
  level: CRITICAL
  verification: manual
  verification_notes: Detection and enforcement assessed
  expected: Confirmed by reviewer
governance:
  applicable_to:
    archetypes:
    - social
    - content
    - platform
    team_sizes:
    - medium
    - large
  compliance_frameworks:
  - framework: EU DSA
    controls:
    - Article 34 (Systemic risks)
    - Article 35 (Risk mitigation)
relationships:
  commonly_combined:
  - responsible-design.content-harm.harmful-content-moderation
  - responsible-design.content-harm.radicalization-vector
