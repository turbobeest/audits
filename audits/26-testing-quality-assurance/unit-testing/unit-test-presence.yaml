audit:
  id: testing-quality-assurance.unit-testing.unit-test-presence
  name: Unit Test Presence
  version: 1.0.0
  last_updated: '2026-01-22'
  status: active
  category: testing-quality-assurance
  category_number: 26
  subcategory: unit-testing
  tier: expert
  estimated_duration: 30-60 min
  completeness: complete
  requires_runtime: false
  destructive: false
execution:
  automatable: 'yes'
  severity: high
  scope: testing
  default_profiles:
  - full
  - quick
  - quality
  blocks_phase: false
  parallelizable: true
description:
  what: |
    Verifies that unit tests exist for the codebase, evaluates test-to-code
    ratio, identifies modules without tests, and assesses test file
    organization. Checks for test framework configuration and validates
    test file naming conventions are followed.
  why_it_matters: |
    Unit tests are the foundation of the testing pyramid and provide the
    fastest feedback loop for developers. Missing unit tests mean bugs are
    caught later in the development cycle where they're more expensive to
    fix. A codebase without unit tests cannot be safely refactored.
  when_to_run:
  - New project onboarding
  - Pre-release quality assessment
  - Code review process
  - Test suite maintenance
prerequisites:
  required_artifacts:
  - type: source_code
    description: Source code repository
  access_requirements:
  - Source code repository access
discovery:
  file_patterns:
  - glob: '**/*.test.{js,ts,jsx,tsx}'
    purpose: JavaScript/TypeScript test files
  - glob: '**/*.spec.{js,ts,jsx,tsx}'
    purpose: Spec-style test files
  - glob: '**/test_*.py'
    purpose: Python test files (pytest)
  - glob: '**/*_test.py'
    purpose: Python test files (alternative)
  - glob: '**/*_test.go'
    purpose: Go test files
  - glob: '**/*Test.java'
    purpose: Java JUnit test files
  - glob: '**/*Spec.scala'
    purpose: Scala spec files
  - glob: '**/*.test.rb'
    purpose: Ruby test files
  code_patterns:
  - pattern: describe\s*\(|it\s*\(|test\s*\(
    type: regex
    scope: test
    purpose: JavaScript test blocks
  - pattern: def test_|class Test|@pytest
    type: regex
    scope: test
    purpose: Python test declarations
  - pattern: '@Test|@ParameterizedTest'
    type: regex
    scope: test
    purpose: JUnit test annotations
knowledge_sources:
  guides:
  - id: unit-testing-guide
    name: Google Testing Blog - Unit Testing
    url: https://testing.googleblog.com/
    offline_cache: true
  - id: test-pyramid
    name: Martin Fowler - Test Pyramid
    url: https://martinfowler.com/articles/practical-test-pyramid.html
    offline_cache: true
  learning_resources:
  - id: unit-testing-book
    title: Unit Testing Principles, Practices, and Patterns
    type: book
    reference: ISBN 978-1617296277
tooling:
  static_analysis:
  - tool: jest
    purpose: JavaScript testing framework
    offline_capable: true
  - tool: pytest
    purpose: Python testing framework
    offline_capable: true
  - tool: junit
    purpose: Java testing framework
    offline_capable: true
  scripts:
  - id: test-presence-check
    language: bash
    purpose: Check for unit test presence
    source: inline
    code: |
      #!/bin/bash
      echo "=== Unit Test Presence Analysis ==="

      echo "Source files:"
      src_count=$(find . -name '*.{js,ts,py,java,go}' -not -path '*node_modules*' -not -path '*test*' 2>/dev/null | wc -l)
      echo "  Total: $src_count"

      echo ""
      echo "Test files:"
      test_count=$(find . \( -name '*.test.*' -o -name '*.spec.*' -o -name 'test_*' -o -name '*_test.*' -o -name '*Test.java' \) -not -path '*node_modules*' 2>/dev/null | wc -l)
      echo "  Total: $test_count"

      echo ""
      echo "Test/Source ratio: $(echo "scale=2; $test_count / $src_count" | bc 2>/dev/null || echo 'N/A')"
signals:
  critical:
  - id: UNITTEST-CRIT-001
    signal: No unit tests found in codebase
    evidence_pattern: Zero test files matching standard conventions
    explanation: |
      A codebase without unit tests has no safety net for changes.
      Refactoring is dangerous, bugs are discovered late, and there's
      no documentation of expected behavior through tests.
    remediation: |
      Establish unit testing foundation:
      1. Choose appropriate test framework for the stack
      2. Configure test runner and coverage tools
      3. Start with tests for new code (no new code without tests)
      4. Gradually add tests for existing critical paths
  - id: UNITTEST-CRIT-002
    signal: Critical modules have no unit tests
    evidence_pattern: Core business logic directories with no test files
    explanation: |
      Core business logic without tests represents highest risk. Any
      change to these modules could introduce regressions that won't
      be caught until production.
    remediation: |
      Prioritize test creation for critical modules:
      - Authentication/authorization
      - Payment/financial calculations
      - Core domain logic
      - Data validation
  high:
  - id: UNITTEST-HIGH-001
    signal: Test-to-source ratio below 0.5
    evidence_threshold: Fewer test files than half the source files
    explanation: |
      Low test-to-source ratio indicates inadequate test coverage.
      While not all files need dedicated tests, healthy projects
      typically have test counts approaching source file counts.
    remediation: |
      Increase test coverage by:
      - Adding tests for all new code
      - Creating tests before refactoring existing code
      - Establishing minimum test requirements per PR
  - id: UNITTEST-HIGH-002
    signal: Test framework not configured
    evidence_pattern: No test runner configuration in project
    explanation: |
      Without test framework configuration, developers cannot easily
      write or run tests. This creates friction that reduces testing.
    remediation: |
      Configure test framework:
      - npm: Add jest or mocha configuration
      - Python: Configure pytest in pyproject.toml
      - Java: Add JUnit dependencies and surefire plugin
  medium:
  - id: UNITTEST-MED-001
    signal: Inconsistent test file naming
    evidence_pattern: Mix of .test., .spec., test_, naming conventions
    remediation: Standardize on single test naming convention project-wide
  - id: UNITTEST-MED-002
    signal: Test files not co-located with source
    evidence_pattern: Tests in separate directory tree from source
    remediation: Consider co-location for easier test discovery and maintenance
  low:
  - id: UNITTEST-LOW-001
    signal: Test directory structure inconsistent
    evidence_pattern: Tests organized differently across modules
  positive:
  - id: UNITTEST-POS-001
    signal: Comprehensive test presence
    evidence_pattern: Test-to-source ratio >= 1.0
  - id: UNITTEST-POS-002
    signal: Consistent test organization
    evidence_pattern: Standardized naming and location conventions
procedure:
  context:
    cognitive_mode: evaluative
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Inventory source files
    description: |
      Count source files to establish baseline for test ratio.
    duration_estimate: 5 min
    commands:
    - purpose: Count source files
      command: find . -type f \( -name '*.js' -o -name '*.ts' -o -name '*.py' -o -name '*.java' -o -name
        '*.go' \) -not -path '*node_modules*' -not -path '*test*' -not -path '*.d.ts' 2>/dev/null | wc
        -l
    expected_findings:
    - Total source file count
  - id: '2'
    name: Inventory test files
    description: |
      Count test files using standard naming conventions.
    duration_estimate: 5 min
    commands:
    - purpose: Count test files
      command: find . \( -name '*.test.*' -o -name '*.spec.*' -o -name 'test_*' -o -name '*_test.*' -o
        -name '*Test.java' \) -not -path '*node_modules*' 2>/dev/null | wc -l
    expected_findings:
    - Total test file count
    - Test-to-source ratio
  - id: '3'
    name: Check test framework configuration
    description: |
      Verify test framework is properly configured.
    duration_estimate: 10 min
    commands:
    - purpose: Check for Jest config
      command: test -f jest.config.js -o -f jest.config.ts && echo 'Jest configured' || echo 'No Jest
        config'
    - purpose: Check for pytest config
      command: grep -E '\[tool.pytest|\[pytest\]' pyproject.toml setup.cfg 2>/dev/null || echo 'No pytest
        config'
    expected_findings:
    - Test framework configuration status
  - id: '4'
    name: Identify untested modules
    description: |
      Find source directories without corresponding tests.
    duration_estimate: 15 min
    commands:
    - purpose: List directories without tests
      command: 'for dir in $(find . -type d -name ''src'' -o -name ''lib'' | head -10); do test_count=$(find
        $dir -name ''*.test.*'' -o -name ''test_*'' 2>/dev/null | wc -l); echo "$dir: $test_count tests";
        done'
    expected_findings:
    - Modules without tests
    - Test distribution across codebase
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: inventory_report
    format: table
    sections:
    - Source File Count
    - Test File Count
    - Test-to-Source Ratio
    - Untested Modules
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Test Presence Analysis
    - Recommendations
  confidence_guidance:
    high: Automated file system analysis
    medium: Configuration inspection
    low: Estimated from partial scan
offline:
  capability: full
  cache_manifest:
    knowledge:
    - source_id: test-pyramid
      priority: required
profiles:
  membership:
    quick:
      included: true
      reason: Quick check provides immediate value
    full:
      included: true
      priority: 1
closeout_checklist:
- id: unittest-presence-001
  item: Test files identified
  level: CRITICAL
  verification: find . -name '*.test.*' -o -name 'test_*' 2>/dev/null | head -1 && echo PASS || echo FAIL
  expected: PASS
- id: unittest-presence-002
  item: Test-to-source ratio calculated
  level: BLOCKING
  verification: manual
  verification_notes: Document ratio of test files to source files
  expected: Confirmed by reviewer
- id: unittest-presence-003
  item: Test framework configured
  level: WARNING
  verification: test -f jest.config.js -o -f pyproject.toml && echo PASS || echo FAIL
  expected: PASS
governance:
  applicable_to:
    archetypes:
    - all
  compliance_frameworks:
  - framework: ISO 25010
    controls:
    - Maintainability
    - Testability
relationships:
  commonly_combined:
  - testing-quality-assurance.test-coverage.code-coverage
  - testing-quality-assurance.unit-testing.unit-test-isolation
  - testing-quality-assurance.unit-testing.unit-test-speed
