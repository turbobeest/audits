# ============================================================
# AUDIT: Mutation Testing Coverage
# ============================================================
# Evaluates test suite effectiveness through mutation testing
# to verify tests actually detect code changes.
# ============================================================

audit:
  id: "testing-quality-assurance.test-coverage.mutation-testing-coverage"
  name: "Mutation Testing Coverage"
  version: "1.0.0"
  last_updated: "2026-01-22"
  status: "active"

  category: "testing-quality-assurance"
  category_number: 26
  subcategory: "test-coverage"

  tier: "phd"
  estimated_duration: "2-4 hours"  # median: 3h

  completeness: "complete"
  requires_runtime: true
  destructive: false

execution:
  automatable: "yes"
  severity: "medium"
  scope: "testing"

  default_profiles:
    - "full"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Evaluates test suite quality through mutation testing - a technique
    that introduces small code changes (mutants) and verifies tests detect
    them. Measures mutation score (percentage of mutants killed by tests),
    identifies surviving mutants indicating weak test assertions, and
    assesses the fault-detection capability of the test suite.

  why_it_matters: |
    High code coverage doesn't guarantee tests will catch bugs. Tests may
    execute code without meaningful assertions (coverage without verification).
    Mutation testing proves tests actually verify behavior by demonstrating
    they fail when code is broken. Low mutation scores indicate tests that
    pass regardless of code correctness.

  when_to_run:
    - "Test suite quality assessment"
    - "Before removing test redundancy"
    - "Critical module test validation"
    - "CI pipeline quality gates (incremental)"

prerequisites:
  required_artifacts:
    - type: "source_code"
      description: "Source code with test suite"
    - type: "mutation_tooling"
      description: "Mutation testing framework installed"

  access_requirements:
    - "Source code repository access"
    - "Ability to run test suite repeatedly"
    - "Computational resources for mutation testing"

discovery:
  file_patterns:
    - glob: "**/mutation-report/**"
      purpose: "Mutation testing reports"
    - glob: "**/stryker.conf.*"
      purpose: "Stryker configuration"
    - glob: "**/mutmut_cache/**"
      purpose: "mutmut cache files"

  code_patterns:
    - pattern: "stryker|mutmut|pitest|mutant"
      type: "regex"
      scope: "config"
      purpose: "Mutation testing configuration"

  metrics_queries:
    - system: "Stryker Dashboard"
      query: "mutation-score"
      purpose: "Overall mutation score"
      threshold: ">= 80%"

knowledge_sources:
  specifications:
    - id: "mutation-testing-theory"
      name: "An Analysis and Survey of the Development of Mutation Testing"
      url: "https://ieeexplore.ieee.org/document/5487526"
      offline_cache: true
      priority: "recommended"

  guides:
    - id: "stryker-docs"
      name: "Stryker Mutation Testing"
      url: "https://stryker-mutator.io/docs/"
      offline_cache: true
    - id: "pitest-docs"
      name: "PIT Mutation Testing"
      url: "https://pitest.org/"
      offline_cache: true

  learning_resources:
    - id: "mutation-intro"
      title: "Introduction to Mutation Testing"
      type: "article"
      reference: "https://www.guru99.com/mutation-testing.html"

tooling:
  static_analysis:
    - tool: "Stryker"
      purpose: "JavaScript/TypeScript mutation testing"
      offline_capable: true
    - tool: "mutmut"
      purpose: "Python mutation testing"
      offline_capable: true
    - tool: "PIT (pitest)"
      purpose: "Java mutation testing"
      offline_capable: true
    - tool: "cargo-mutants"
      purpose: "Rust mutation testing"
      offline_capable: true
    - tool: "go-mutesting"
      purpose: "Go mutation testing"
      offline_capable: true

  scripts:
    - id: "mutation-analysis"
      language: "bash"
      purpose: "Run mutation testing analysis"
      source: "inline"
      code: |
        #!/bin/bash
        echo "=== Mutation Testing Analysis ==="

        # Check for JavaScript/Stryker
        if [ -f "stryker.conf.js" ] || [ -f "stryker.conf.json" ]; then
          echo "Stryker configured - run: npx stryker run"
        fi

        # Check for Python/mutmut
        if [ -f "pyproject.toml" ] || [ -f "setup.py" ]; then
          echo "Python project - run: mutmut run"
        fi

        # Check for Java/PIT
        if [ -f "pom.xml" ]; then
          echo "Maven project - run: mvn org.pitest:pitest-maven:mutationCoverage"
        fi

        # Check for existing reports
        if [ -d "reports/mutation" ]; then
          echo "Existing mutation reports found"
          ls -la reports/mutation/
        fi

signals:
  critical:
    - id: "MUTATION-CRIT-001"
      signal: "Mutation score below 50%"
      evidence_threshold: "Less than 50% of mutants killed"
      explanation: |
        Most code mutations survive without being caught by tests.
        Tests may execute code but lack meaningful assertions. The
        test suite provides little actual bug detection capability.
      remediation: |
        Improve test assertions to catch mutations:
        1. Add specific value assertions, not just execution checks
        2. Verify return values and state changes explicitly
        3. Test boundary conditions and edge cases
        4. Remove redundant tests that don't add detection value

    - id: "MUTATION-CRIT-002"
      signal: "Critical business logic has surviving mutants"
      evidence_pattern: "Payment/auth/validation code with surviving mutations"
      explanation: |
        Surviving mutants in critical code indicate tests wouldn't
        catch real bugs. Security or financial code with weak tests
        represents significant risk.
      remediation: |
        Achieve 100% mutation kill rate for critical modules.
        Each surviving mutant indicates a potential real bug the
        tests would miss.

  high:
    - id: "MUTATION-HIGH-001"
      signal: "Boundary condition mutations survive"
      evidence_pattern: "Relational operator mutations (< to <=) survive"
      explanation: |
        Off-by-one errors and boundary conditions are common bugs.
        If tests don't catch operator changes, they won't catch
        boundary bugs in production.
      remediation: |
        Add tests specifically targeting boundary conditions:
        - Test at exact boundary values
        - Test one above and below boundaries
        - Test empty/zero/null cases

    - id: "MUTATION-HIGH-002"
      signal: "Return value mutations survive"
      evidence_pattern: "Changed return values don't fail tests"
      explanation: |
        Tests that don't verify return values are execution tests,
        not verification tests. They confirm code runs but not
        that it produces correct results.
      remediation: |
        Add explicit assertions on all return values.
        Avoid tests that only check for no exceptions.

  medium:
    - id: "MUTATION-MED-001"
      signal: "Equivalent mutants not identified"
      evidence_pattern: "High surviving mutant count including equivalents"
      remediation: "Review surviving mutants to identify and exclude equivalents"

    - id: "MUTATION-MED-002"
      signal: "Mutation testing not in CI pipeline"
      evidence_pattern: "No automated mutation score tracking"
      remediation: "Add incremental mutation testing to CI for new code"

  low:
    - id: "MUTATION-LOW-001"
      signal: "Mutation testing timeout configuration"
      evidence_pattern: "Long-running mutation tests due to slow suite"

  positive:
    - id: "MUTATION-POS-001"
      signal: "Mutation score above 80%"
      evidence_threshold: "80%+ mutants killed"

    - id: "MUTATION-POS-002"
      signal: "Mutation score tracked and trending positively"
      evidence_threshold: "Mutation score dashboard active"

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Configure mutation testing"
      description: |
        Set up mutation testing framework appropriate for the codebase.
      duration_estimate: "20 min"
      commands:
        - purpose: "Install Stryker (JS)"
          command: "npm install --save-dev @stryker-mutator/core 2>/dev/null || echo 'Install manually'"
        - purpose: "Install mutmut (Python)"
          command: "pip install mutmut 2>/dev/null || echo 'Install manually'"
      expected_findings:
        - "Mutation framework availability"
        - "Configuration requirements"

    - id: "2"
      name: "Run mutation testing"
      description: |
        Execute mutation testing on target codebase (may take significant time).
      duration_estimate: "60-120 min"
      commands:
        - purpose: "Run Stryker"
          command: "npx stryker run 2>/dev/null || echo 'Configure and run manually'"
        - purpose: "Run mutmut"
          command: "mutmut run 2>/dev/null || echo 'Configure and run manually'"
      expected_findings:
        - "Mutation score"
        - "Killed vs survived mutant count"

    - id: "3"
      name: "Analyze surviving mutants"
      description: |
        Review surviving mutants to understand test weaknesses.
      duration_estimate: "30 min"
      commands:
        - purpose: "View surviving mutants"
          command: "mutmut results 2>/dev/null || cat reports/mutation/mutation.html"
      expected_findings:
        - "List of surviving mutants"
        - "Patterns in survival"

    - id: "4"
      name: "Prioritize improvements"
      description: |
        Determine which surviving mutants indicate highest risk.
      duration_estimate: "20 min"
      questions:
        - "Which surviving mutants affect critical code?"
        - "What mutation types survive most often?"
        - "Which tests need stronger assertions?"
      expected_findings:
        - "Priority improvement list"
        - "Test enhancement recommendations"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "mutation_report"
      format: "table"
      sections:
        - "Mutation Score Summary"
        - "Surviving Mutants"
        - "Kill Rate by Module"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Test Quality Assessment"
        - "Improvement Recommendations"

  confidence_guidance:
    high: "Full mutation testing run completed"
    medium: "Sampled mutation testing on critical paths"
    low: "Mutation testing not feasible, estimated from coverage"

offline:
  capability: "full"

  cache_manifest:
    knowledge:
      - source_id: "stryker-docs"
        priority: "required"

profiles:
  membership:
    quick:
      included: false
      reason: "Mutation testing is computationally expensive"
    full:
      included: true
      priority: 15

closeout_checklist:
  - id: "mutation-001"
    item: "Mutation testing executed"
    level: "CRITICAL"
    verification: "test -d reports/mutation && echo PASS || echo FAIL"
    expected: "PASS"

  - id: "mutation-002"
    item: "Mutation score documented"
    level: "BLOCKING"
    verification: "manual"
    verification_notes: "Record overall mutation score percentage"
    expected: "Confirmed by reviewer"

  - id: "mutation-003"
    item: "Surviving mutants analyzed"
    level: "WARNING"
    verification: "manual"
    verification_notes: "Document critical surviving mutants"
    expected: "Confirmed by reviewer"

governance:
  applicable_to:
    archetypes:
      - "safety-critical"
      - "security"
      - "financial"

  compliance_frameworks:
    - framework: "ISO 26262"
      controls: ["Test effectiveness validation"]

relationships:
  commonly_combined:
    - "testing-quality-assurance.test-coverage.code-coverage"
    - "testing-quality-assurance.test-effectiveness.defect-detection-rate"
    - "testing-quality-assurance.unit-testing.unit-test-presence"
