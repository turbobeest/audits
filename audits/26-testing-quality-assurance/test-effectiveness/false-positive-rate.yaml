audit:
  id: testing-quality-assurance.test-effectiveness.false-positive-rate
  name: False Positive Rate
  version: 1.0.0
  last_updated: '2026-01-22'
  status: active
  category: testing-quality-assurance
  category_number: 26
  subcategory: test-effectiveness
  tier: expert
  estimated_duration: 30-45 min
  completeness: requires_discovery
  requires_runtime: false
  destructive: false
execution:
  automatable: partial
  severity: high
  scope: quality
  default_profiles:
  - full
  - quality
  blocks_phase: false
  parallelizable: true
description:
  what: |
    Evaluates the false positive rate of the test suite - the percentage
    of test failures that don't indicate real code defects. Includes
    flaky tests, environment issues, test bugs, and other non-code
    causes of failure.
  why_it_matters: |
    False positives erode trust in the test suite. When failures frequently
    don't mean anything, developers ignore them. Real issues slip through
    because "the tests always fail." A test suite with high false positives
    provides negative value.
  when_to_run:
  - Test reliability assessment
  - CI/CD optimization
  - Developer productivity review
  - Quality improvement
prerequisites:
  required_artifacts:
  - type: test_results
    description: Historical test execution results
  - type: ci_logs
    description: CI pipeline logs
  access_requirements:
  - CI/CD execution history
  - Test failure logs
discovery:
  documents_to_review:
  - type: CI logs
    purpose: Analyze failure causes
  - type: Retry data
    purpose: Identify non-deterministic failures
  file_patterns:
  - glob: '**/*.md'
    purpose: Documentation files
  - glob: '**/*.yaml'
    purpose: Configuration files
  - glob: '**/*.json'
    purpose: JSON configuration
knowledge_sources:
  guides:
  - id: test-reliability
    name: Test Reliability Engineering
    url: https://testing.googleblog.com/2020/12/test-flakiness-one-of-main-challenges.html
    offline_cache: true
  learning_resources:
  - id: false-positives
    title: Reducing False Positives in Testing
    type: article
    reference: Testing Best Practices
tooling:
  assessment_tools:
  - tool: CI analytics
    purpose: Failure analysis
  - tool: Test reporting
    purpose: Pattern detection
  scripts:
  - id: fp-check
    language: bash
    purpose: Analyze false positive indicators
    source: inline
    code: |
      #!/bin/bash
      echo "=== False Positive Rate Analysis ==="

      echo "This audit requires CI/CD data analysis."
      echo ""
      echo "Key indicators to examine:"
      echo "  1. Failures that pass on retry"
      echo "  2. Failures without code changes"
      echo "  3. Environment-related failures"
      echo "  4. Timeout failures"

      echo ""
      echo "Test retry configurations:"
      grep -r 'retry\|retries\|rerun' --include='*.json' --include='*.yml' . 2>/dev/null | head -10

      echo ""
      echo "Timeout configurations:"
      grep -r 'timeout' --include='*.json' --include='*.yml' --include='*.test.*' . 2>/dev/null | head -10

      echo ""
      echo "Flaky test markers:"
      grep -r -n 'flaky\|unstable\|skip.*reason' --include='*.test.*' --include='*.spec.*' . 2>/dev/null | head -10
signals:
  critical:
  - id: FPR-CRIT-001
    signal: Very high false positive rate
    evidence_pattern: '> 30% of failures are false positives'
    explanation: |
      When nearly a third of failures are false positives, the test
      suite actively harms development. Time is wasted investigating
      non-issues, and real issues are dismissed as noise.
    remediation: |
      Urgent test suite cleanup:
      1. Identify all false positive sources
      2. Quarantine worst offenders
      3. Fix or remove flaky tests
      4. Improve environment stability
      5. Set FPR targets and track
  - id: FPR-CRIT-002
    signal: Team has stopped trusting tests
    evidence_pattern: Developers routinely ignore failures
    explanation: |
      When trust is lost, tests provide no value. Developers proceed
      despite failures, defeating the purpose of testing. Rebuilding
      trust requires eliminating false positives.
    remediation: |
      Rebuild trust:
      - Remove or fix all known flaky tests
      - Achieve streak of reliable runs
      - Communicate improvements
      - Respond quickly to new flakes
  high:
  - id: FPR-HIGH-001
    signal: High retry success rate
    evidence_pattern: Most failed tests pass on retry
    explanation: |
      If tests pass on retry, they're flaky, not failing. High retry
      success indicates non-deterministic tests that waste time and
      CI resources while hiding real issues.
    remediation: |
      Address retry-dependent tests:
      - Track which tests need retries
      - Fix root causes
      - Add retry reporting
      - Set retry reduction goals
  - id: FPR-HIGH-002
    signal: Infrastructure causes failures
    evidence_pattern: Test failures from resource exhaustion, timeouts
    explanation: |
      Infrastructure issues appearing as test failures are false
      positives. They don't indicate code problems but waste time
      investigating. Environment must be stable.
    remediation: |
      Stabilize infrastructure:
      - Monitor test environment health
      - Set appropriate resource limits
      - Add infrastructure failure detection
      - Separate infra failures from test failures
  medium:
  - id: FPR-MED-001
    signal: False positives not categorized
    evidence_pattern: All failures treated the same
    remediation: Categorize failures by cause (code, flaky, infra)
  - id: FPR-MED-002
    signal: No false positive tracking
    evidence_pattern: FPR not measured
    remediation: Implement FPR tracking and reporting
  low:
  - id: FPR-LOW-001
    signal: False positive causes not documented
    evidence_pattern: Unclear why false positives occur
  positive:
  - id: FPR-POS-001
    signal: Very low false positive rate
    evidence_pattern: < 5% of failures are false positives
  - id: FPR-POS-002
    signal: False positive tracking in place
    evidence_pattern: FPR measured and improving
procedure:
  context:
    cognitive_mode: analytical
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Gather failure data
    description: |
      Collect test failure history.
    duration_estimate: 10 min
    questions:
    - How many test failures in last 30 days?
    - How many were real code issues?
    - How many passed on retry?
    expected_findings:
    - Failure counts
    - Retry data
  - id: '2'
    name: Categorize failures
    description: |
      Classify failures by root cause.
    duration_estimate: 15 min
    questions:
    - What % were code issues?
    - What % were flaky tests?
    - What % were infrastructure?
    - What % were test bugs?
    expected_findings:
    - Failure categories
    - False positive sources
  - id: '3'
    name: Calculate FPR
    description: |
      Compute false positive rate.
    duration_estimate: 5 min
    questions:
    - FPR = (Non-code failures) / (Total failures) * 100
    - What is the current FPR?
    expected_findings:
    - FPR value
    - Trend if available
  - id: '4'
    name: Identify improvement opportunities
    description: |
      Find ways to reduce FPR.
    duration_estimate: 15 min
    questions:
    - Which tests contribute most to FPR?
    - What infrastructure issues cause failures?
    - Which flaky tests need fixing?
    expected_findings:
    - Top FPR contributors
    - Action items
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: fpr_report
    format: table
    sections:
    - Failure Analysis
    - FPR Calculation
    - Improvement Opportunities
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - FPR Analysis
    - Recommendations
  confidence_guidance:
    high: Full CI data with categorization
    medium: Sample analysis
    low: Interview-based estimate
offline:
  capability: partial
  cache_manifest:
    knowledge:
    - source_id: test-reliability
      priority: recommended
profiles:
  membership:
    quick:
      included: false
      reason: Requires failure analysis
    quality:
      included: true
      priority: 2
    full:
      included: true
      priority: 3
closeout_checklist:
- id: fpr-001
  item: Failure data gathered
  level: CRITICAL
  verification: manual
  verification_notes: Document total failures analyzed
  expected: Count documented
- id: fpr-002
  item: FPR calculated
  level: CRITICAL
  verification: manual
  verification_notes: Document FPR percentage
  expected: FPR documented
- id: fpr-003
  item: Top FPR contributors identified
  level: WARNING
  verification: manual
  verification_notes: List tests/causes with most false positives
  expected: List created
governance:
  applicable_to:
    archetypes:
    - all
  compliance_frameworks:
  - framework: ISO 25010
    controls:
    - Reliability
relationships:
  commonly_combined:
  - testing-quality-assurance.test-effectiveness.test-flakiness
  - testing-quality-assurance.test-effectiveness.test-signal-vs-noise
  - testing-quality-assurance.test-environment.environment-stability
