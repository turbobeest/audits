audit:
  id: testing-quality-assurance.test-effectiveness.defect-detection-rate
  name: Defect Detection Rate
  version: 1.0.0
  last_updated: '2026-01-22'
  status: active
  category: testing-quality-assurance
  category_number: 26
  subcategory: test-effectiveness
  tier: expert
  estimated_duration: 45-60 min
  completeness: requires_discovery
  requires_runtime: false
  destructive: false
execution:
  automatable: partial
  severity: high
  scope: quality
  default_profiles:
  - full
  - quality
  blocks_phase: false
  parallelizable: true
description:
  what: |
    Evaluates the defect detection rate - the percentage of defects
    caught by testing versus those found in production. Analyzes
    where defects escape to production and which test types are
    most effective at catching issues.
  why_it_matters: |
    Tests exist to find defects before users do. If most defects are
    found in production, testing is failing its primary purpose. High
    defect detection rates indicate effective testing; low rates signal
    coverage gaps or test quality issues.
  when_to_run:
  - Quality process assessment
  - Testing strategy review
  - Post-incident analysis
  - Quality metrics review
prerequisites:
  required_artifacts:
  - type: defect_data
    description: Defect tracking data
  - type: test_results
    description: Test execution history
  access_requirements:
  - Bug tracker access
  - Test execution data
discovery:
  documents_to_review:
  - type: Bug reports
    purpose: Where defects are found
  - type: Test results
    purpose: Defects caught in testing
  - type: Incident reports
    purpose: Production defects
  file_patterns:
  - glob: '**/*.md'
    purpose: Documentation files
  - glob: '**/*.yaml'
    purpose: Configuration files
  - glob: '**/*.json'
    purpose: JSON configuration
knowledge_sources:
  guides:
  - id: defect-metrics
    name: Software Defect Metrics
    url: https://www.guru99.com/defect-metrics.html
    offline_cache: true
  learning_resources:
  - id: testing-metrics
    title: Testing Metrics That Matter
    type: article
    reference: QA Best Practices
tooling:
  assessment_tools:
  - tool: Bug tracker
    purpose: Defect source analysis
  - tool: CI/CD reports
    purpose: Test detection tracking
  scripts:
  - id: defect-analysis
    language: bash
    purpose: Analyze defect patterns
    source: inline
    code: |
      #!/bin/bash
      echo "=== Defect Detection Analysis ==="

      echo "This audit requires access to:"
      echo "  - Bug tracking system data"
      echo "  - Test execution history"
      echo "  - Production incident logs"

      echo ""
      echo "Key metrics to calculate:"
      echo "  - Defect Detection Percentage (DDP)"
      echo "  - Defects found in testing vs production"
      echo "  - Defect distribution by test type"

      echo ""
      echo "Test result patterns:"
      find . -name '*test-results*' -o -name '*report*' 2>/dev/null | grep -E '\.(xml|json|html)$' | head -10
signals:
  critical:
  - id: DDR-CRIT-001
    signal: Most defects found in production
    evidence_pattern: DDP < 50%
    explanation: |
      When more than half of defects reach production, testing is
      fundamentally failing. Users are effectively doing QA. This
      indicates severe gaps in test coverage, environment parity,
      or test design.
    remediation: |
      Improve defect detection:
      1. Analyze escaped defects for patterns
      2. Add tests for missed scenarios
      3. Improve environment parity
      4. Enhance test types (add E2E, integration)
      5. Review test quality
  - id: DDR-CRIT-002
    signal: Critical defects escaping to production
    evidence_pattern: High-severity issues not caught by tests
    explanation: |
      Critical defects in production cause outages, data loss, and
      user harm. Testing should prioritize catching critical issues.
      Escaped critical defects indicate testing gaps in important areas.
    remediation: |
      Prioritize critical path testing:
      - Identify critical functionality
      - Ensure comprehensive coverage
      - Add negative test cases
      - Test failure scenarios
      - Include security testing
  high:
  - id: DDR-HIGH-001
    signal: Defect detection declining over time
    evidence_pattern: DDP trending downward
    explanation: |
      Declining detection rates suggest test suite degradation.
      As code evolves, tests may not keep pace. Regular monitoring
      catches this regression before it becomes severe.
    remediation: |
      Reverse the trend:
      - Analyze recent escaped defects
      - Update tests for new features
      - Remove obsolete tests
      - Improve test maintenance
      - Add regression tests for bugs
  - id: DDR-HIGH-002
    signal: Specific area with low detection
    evidence_pattern: One component has most escapes
    explanation: |
      Concentrated escapes indicate specific coverage gaps. Some
      components may be undertested due to complexity, legacy code,
      or ownership gaps.
    remediation: |
      Target low-detection areas:
      - Identify problem components
      - Analyze what tests exist
      - Add targeted tests
      - Consider specialized testing
      - Assign testing ownership
  medium:
  - id: DDR-MED-001
    signal: No defect source tracking
    evidence_pattern: Can't determine where defects found
    remediation: Tag defects with discovery phase (test, staging, prod)
  - id: DDR-MED-002
    signal: Test types not balanced
    evidence_pattern: All defects from one test type
    remediation: Diversify test types for broader detection
  low:
  - id: DDR-LOW-001
    signal: Detection metrics not monitored
    evidence_pattern: DDP not tracked over time
  positive:
  - id: DDR-POS-001
    signal: High defect detection rate
    evidence_pattern: DDP > 80%
  - id: DDR-POS-002
    signal: Improving detection trend
    evidence_pattern: DDP increasing over time
procedure:
  context:
    cognitive_mode: analytical
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Gather defect data
    description: |
      Collect defect information from all sources.
    duration_estimate: 15 min
    questions:
    - How many defects were found in testing?
    - How many defects were found in production?
    - What is the timeframe for analysis?
    expected_findings:
    - Defect counts
    - Source distribution
  - id: '2'
    name: Calculate detection rate
    description: |
      Compute defect detection percentage.
    duration_estimate: 10 min
    questions:
    - DDP = (Testing Defects) / (Total Defects) * 100
    - What is the current DDP?
    - How has it trended?
    expected_findings:
    - DDP value
    - Trend direction
  - id: '3'
    name: Analyze escaped defects
    description: |
      Examine defects that reached production.
    duration_estimate: 20 min
    questions:
    - What types of defects escape?
    - Which components have escapes?
    - Why weren't they caught?
    expected_findings:
    - Escape patterns
    - Coverage gaps
  - id: '4'
    name: Assess by test type
    description: |
      Evaluate which test types find defects.
    duration_estimate: 15 min
    questions:
    - How many defects found by unit tests?
    - How many by integration tests?
    - How many by E2E tests?
    expected_findings:
    - Test type effectiveness
    - Balance assessment
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: detection_report
    format: table
    sections:
    - Detection Rate
    - Escape Analysis
    - Test Type Effectiveness
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Detection Analysis
    - Improvement Recommendations
  confidence_guidance:
    high: Full defect data with historical trends
    medium: Sample defect analysis
    low: Interview-based assessment
offline:
  capability: partial
  cache_manifest:
    knowledge:
    - source_id: defect-metrics
      priority: recommended
profiles:
  membership:
    quick:
      included: false
      reason: Requires defect data analysis
    quality:
      included: true
      priority: 2
    full:
      included: true
      priority: 3
closeout_checklist:
- id: ddr-001
  item: Detection rate calculated
  level: CRITICAL
  verification: manual
  verification_notes: Document DDP percentage
  expected: DDP documented
- id: ddr-002
  item: Escaped defects analyzed
  level: BLOCKING
  verification: manual
  verification_notes: Document escape patterns
  expected: Patterns identified
- id: ddr-003
  item: Improvement opportunities identified
  level: WARNING
  verification: manual
  verification_notes: Document coverage gaps
  expected: Gaps documented
governance:
  applicable_to:
    archetypes:
    - all
  compliance_frameworks:
  - framework: ISO 25010
    controls:
    - Reliability
    - Functional Suitability
relationships:
  commonly_combined:
  - testing-quality-assurance.test-coverage.code-coverage
  - testing-quality-assurance.test-effectiveness.test-signal-vs-noise
  - testing-quality-assurance.test-coverage.critical-path-coverage
