# ============================================================
# AUDIT: Parallel Running Validation
# Category: 33 - Legacy & Migration
# Subcategory: compatibility-testing
# ============================================================

audit:
  id: "legacy-migration.compatibility-testing.parallel-running"
  name: "Parallel Running Validation Audit"
  version: "1.0.0"
  last_updated: "2025-01-22"
  status: "active"

  category: "legacy-migration"
  category_number: 33
  subcategory: "compatibility-testing"

  tier: "expert"
  estimated_duration: "6-10 hours"  # median: 8h

  completeness: "requires_discovery"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "system"

  default_profiles:
    - "full"
    - "quick"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Evaluates the implementation and effectiveness of parallel running between
    legacy and new systems, where both systems process the same inputs and
    outputs are compared. This audit assesses comparison mechanisms, difference
    handling, and the decision criteria for cutover based on parallel run results.

  why_it_matters: |
    Parallel running provides the highest confidence that new systems behave
    correctly by comparing actual production results. Effective parallel running
    catches issues that tests miss and builds confidence for cutover. Poor
    parallel running implementation can give false confidence or miss real issues.

  when_to_run:
    - "During parallel operation phase"
    - "Before production cutover"
    - "When validating migration correctness"
    - "After discrepancies are detected"

prerequisites:
  required_artifacts:
    - type: "parallel_infrastructure"
      description: "Both systems running in parallel"
    - type: "comparison_tools"
      description: "Output comparison mechanisms"
    - type: "discrepancy_logs"
      description: "Parallel run discrepancy records"

  access_requirements:
    - "Access to both systems"
    - "Comparison tool access"
    - "Discrepancy tracking system"
    - "Production traffic routing"

discovery:
  file_patterns:
    - glob: "**/parallel*"
      purpose: "Find parallel run configurations"
    - glob: "**/comparison*"
      purpose: "Find comparison logic"
    - glob: "**/shadow*"
      purpose: "Find shadow/dark launch code"

  interview_questions:
    - role: "Tech Lead"
      questions:
        - "How are parallel run results compared?"
        - "What discrepancies have been found?"
        - "What is the cutover decision criteria?"
    - role: "Operations Engineer"
      questions:
        - "How is parallel traffic routing managed?"
        - "What monitoring exists for parallel systems?"
        - "How are discrepancies investigated?"

knowledge_sources:
  guides:
    - id: "parallel-run"
      name: "Parallel Running in Migration"
      url: "https://martinfowler.com/bliki/ParallelRun.html"
    - id: "shadow-traffic"
      name: "Shadow Traffic Testing"
      url: "https://microsoft.github.io/code-with-engineering-playbook/automated-testing/shadow-testing/"

  standards:
    - id: "change-management"
      name: "ITIL Change Management"
      relevance: "Change verification practices"

tooling:
  analysis_tools:
    - tool: "Diffy"
      purpose: "Twitter's comparison proxy"
    - tool: "GoReplay"
      purpose: "Traffic capture and replay"
      command: "gor --input-raw :8080 --output-http http://new-system:8080"
    - tool: "Scientist"
      purpose: "GitHub's experiment framework"
    - tool: "Custom comparison scripts"
      purpose: "Application-specific comparison"

signals:
  critical:
    - id: "PRV-CRIT-001"
      signal: "Systematic discrepancies in parallel results"
      evidence_indicators:
        - "Consistent differences in outputs"
        - "Pattern of mismatches across cases"
        - "Business logic differences"
      explanation: |
        Systematic discrepancies indicate fundamental differences between
        systems that must be resolved before cutover.
      remediation: "Investigate and fix root cause before cutover"

    - id: "PRV-CRIT-002"
      signal: "Comparison coverage incomplete"
      evidence_indicators:
        - "Only subset of transactions compared"
        - "Some outputs not verified"
        - "Edge cases not covered"
      explanation: |
        Incomplete comparison may miss issues in uncompared functionality.
      remediation: "Expand comparison to cover all functionality"

  high:
    - id: "PRV-HIGH-001"
      signal: "Discrepancy investigation backlog growing"
      remediation: "Allocate resources to clear investigation backlog"

    - id: "PRV-HIGH-002"
      signal: "Comparison timing issues causing false differences"
      remediation: "Implement proper synchronization"

    - id: "PRV-HIGH-003"
      signal: "No automated comparison alerting"
      remediation: "Implement discrepancy alerting"

  medium:
    - id: "PRV-MED-001"
      signal: "Minor acceptable differences not documented"
      remediation: "Document expected differences"

    - id: "PRV-MED-002"
      signal: "Comparison performance impacting systems"
      remediation: "Optimize comparison process"

  low:
    - id: "PRV-LOW-001"
      signal: "Comparison reporting could be improved"
      remediation: "Enhance comparison dashboards"

    - id: "PRV-LOW-002"
      signal: "Historical comparison data not retained"
      remediation: "Implement comparison data archival"

  positive:
    - id: "PRV-POS-001"
      signal: "High match rate with explained differences"

    - id: "PRV-POS-002"
      signal: "Comprehensive comparison with trending"

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Review Parallel Architecture"
      description: "Understand parallel running setup"
      duration_estimate: "1 hour"

    - id: "2"
      name: "Assess Comparison Coverage"
      description: "Evaluate what is being compared"
      duration_estimate: "2 hours"

    - id: "3"
      name: "Analyze Discrepancy Patterns"
      description: "Review and categorize discrepancies"
      duration_estimate: "2 hours"

    - id: "4"
      name: "Evaluate Investigation Process"
      description: "Assess how discrepancies are handled"
      duration_estimate: "1 hour"

    - id: "5"
      name: "Review Cutover Criteria"
      description: "Assess decision criteria for cutover"
      duration_estimate: "1 hour"

    - id: "6"
      name: "Validate Results"
      description: "Confirm parallel run effectiveness"
      duration_estimate: "2 hours"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Parallel Architecture Review"
        - "Comparison Coverage"
        - "Discrepancy Analysis"
        - "Cutover Readiness"
        - "Recommendations"

closeout_checklist:
  - id: "prv-001"
    item: "Comparison coverage assessed"
    level: "WARNING"
    verification: "manual"
  - id: "prv-002"
    item: "Discrepancies analyzed"
    level: "WARNING"
    verification: "manual"
  - id: "prv-003"
    item: "Cutover readiness determined"
    level: "GATE"
    verification: "manual"

governance:
  applicable_to:
    archetypes: ["critical-migrations", "financial-systems", "high-risk-cutovers"]

  compliance_mappings:
    - framework: "SOX"
      control: "Change Management"
      description: "System change verification"
    - framework: "PCI DSS"
      control: "6.4.5"
      description: "Change control procedures"

relationships:
  commonly_combined:
    - "legacy-migration.data-migration.migration-verification"
    - "legacy-migration.compatibility-testing.regression-testing"
  depends_on:
    - "legacy-migration.migration-planning.incremental-migration-strategy"
  feeds_into:
    - "operations.production-cutover"
    - "legacy-migration.sunset-decommission.post-migration-cleanup"
