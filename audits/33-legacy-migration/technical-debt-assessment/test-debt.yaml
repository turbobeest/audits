audit:
  id: legacy-migration.technical-debt-assessment.test-debt
  name: Test Debt Assessment Audit
  version: 1.0.0
  last_updated: '2025-01-22'
  status: active
  category: legacy-migration
  category_number: 33
  subcategory: technical-debt-assessment
  tier: expert
  estimated_duration: 4-6 hours  # median: 5h
  completeness: requires_discovery
  requires_runtime: true
  destructive: false
execution:
  automatable: partial
  severity: medium
  scope: codebase
  default_profiles:
  - full
  - quick
  blocks_phase: false
  parallelizable: true
description:
  what: |
    Evaluates the quality and coverage of the test suite, identifying gaps,
    brittle tests, slow tests, and areas of the codebase with inadequate testing.
    This audit measures test coverage, analyzes test quality metrics, identifies
    flaky tests, and assesses the maintainability of the test code itself.
    It quantifies the effort needed to achieve reliable test coverage.
  why_it_matters: |
    Test debt makes refactoring dangerous and slows down development. Without
    adequate tests, teams cannot confidently make changes, leading to either
    risky deployments or excessive manual testing. Brittle or slow tests reduce
    developer productivity and erode trust in the test suite.
  when_to_run:
  - Before major refactoring efforts
  - When test failures become unreliable indicators
  - During technical debt assessments
  - When teams report lack of confidence in tests
prerequisites:
  required_artifacts:
  - type: source_code
    description: Application and test source code
  - type: ci_configuration
    description: CI pipeline with test execution
  - type: coverage_reports
    description: Historical test coverage data
  access_requirements:
  - Read access to source repositories
  - Access to CI/CD pipeline
  - Test execution capabilities
discovery:
  file_patterns:
  - glob: '**/*test*.{py,js,ts,java,cs,rb,go}'
    purpose: Find test files
  - glob: '**/*spec*.{py,js,ts,rb}'
    purpose: Find spec files
  - glob: '**/coverage/**'
    purpose: Find coverage reports
  - glob: '**/jest.config*'
    purpose: Find Jest configuration
  - glob: '**/pytest.ini'
    purpose: Find pytest configuration
  interview_questions:
  - role: QA Engineer
    questions:
    - Which tests fail intermittently?
    - What areas of the code are hardest to test?
    - How confident are you in the current test suite?
  - role: Developer
    questions:
    - Do you write tests before or after implementation?
    - Which tests slow down the build?
    - Are there areas you avoid testing?
knowledge_sources:
  guides:
  - id: test-pyramid
    name: The Practical Test Pyramid
    url: https://martinfowler.com/articles/practical-test-pyramid.html
  - id: test-patterns
    name: xUnit Test Patterns
    url: http://xunitpatterns.com/
  standards:
  - id: istqb-testing
    name: ISTQB Testing Standards
    relevance: Testing best practices and terminology
tooling:
  analysis_tools:
  - tool: Istanbul/nyc
    purpose: JavaScript code coverage
    command: nyc npm test
  - tool: pytest-cov
    purpose: Python code coverage
    command: pytest --cov=src --cov-report=html
  - tool: JaCoCo
    purpose: Java code coverage
  - tool: mutation-testing
    purpose: Test quality through mutation analysis
    command: stryker run
  - tool: flaky-test-detector
    purpose: Identify unreliable tests
signals:
  critical:
  - id: TDA-CRIT-001
    signal: Critical business logic with zero test coverage
    evidence_indicators:
    - Payment, security, or compliance code untested
    - Core algorithms without verification
    - High-risk areas excluded from coverage
    explanation: |
      Critical code paths without tests represent significant business risk.
      Changes to these areas cannot be made safely without manual verification.
    remediation: Implement comprehensive tests for critical paths immediately
  - id: TDA-CRIT-002
    signal: Test suite passes with obviously broken code
    evidence_indicators:
    - Mutation testing shows <50% mutation coverage
    - Tests pass without assertions
    - Mocks replace actual verification
    explanation: |
      Tests that don't actually verify behavior provide false confidence
      and are worse than no tests at all.
    remediation: Review and strengthen test assertions and verification
  high:
  - id: TDA-HIGH-001
    signal: Overall code coverage below 50%
    remediation: Implement coverage targets and track improvement
  - id: TDA-HIGH-002
    signal: Flaky tests causing >10% of build failures
    remediation: Quarantine and fix flaky tests
  - id: TDA-HIGH-003
    signal: Test execution time exceeding 30 minutes
    remediation: Optimize slow tests and implement parallel execution
  medium:
  - id: TDA-MED-001
    signal: Code coverage between 50-70%
    remediation: Systematically improve coverage for uncovered areas
  - id: TDA-MED-002
    signal: Test code quality lower than production code
    remediation: Apply same quality standards to test code
  - id: TDA-MED-003
    signal: Integration tests overrepresented vs unit tests
    remediation: Rebalance test pyramid toward unit tests
  low:
  - id: TDA-LOW-001
    signal: Minor coverage gaps in utility code
    remediation: Add tests during routine maintenance
  - id: TDA-LOW-002
    signal: Test naming conventions inconsistent
    remediation: Standardize test naming in style guide
  positive:
  - id: TDA-POS-001
    signal: Code coverage above 80% with quality assertions
  - id: TDA-POS-002
    signal: Fast, reliable test suite with clear feedback
procedure:
  context:
    cognitive_mode: analytical
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Measure Coverage
    description: Run coverage tools and collect metrics
    duration_estimate: 1 hour
  - id: '2'
    name: Analyze Coverage Gaps
    description: Identify uncovered code and assess risk
    duration_estimate: 1 hour
  - id: '3'
    name: Evaluate Test Quality
    description: Review test assertions and patterns
    duration_estimate: 1 hour
  - id: '4'
    name: Identify Flaky Tests
    description: Analyze CI history for unreliable tests
    duration_estimate: 1 hour
  - id: '5'
    name: Assess Test Performance
    description: Identify slow tests impacting feedback loops
    duration_estimate: 30 minutes
  - id: '6'
    name: Prioritize Improvements
    description: Create ranked list of test debt items
    duration_estimate: 1 hour
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Coverage Analysis
    - Test Quality Assessment
    - Flaky Test Report
    - Performance Analysis
    - Improvement Roadmap
closeout_checklist:
- id: tda-001
  item: Coverage metrics collected and analyzed
  level: WARNING
  verification: tool_output
- id: tda-002
  item: Critical coverage gaps identified
  level: WARNING
  verification: manual
- id: tda-003
  item: Test improvement priorities documented
  level: WARNING
  verification: manual
governance:
  applicable_to:
    archetypes:
    - any-software-project
    - safety-critical-systems
  compliance_mappings:
  - framework: ISO 25010
    control: Reliability
    description: Testability characteristics
  - framework: IEC 62304
    control: Software Testing
    description: Medical device software testing requirements
relationships:
  commonly_combined:
  - code-quality.test-coverage
  - ci-cd.test-automation
  depends_on:
  - code-quality.static-analysis
  feeds_into:
  - legacy-migration.code-modernization.testability-improvement
  - quality-assurance.test-strategy
