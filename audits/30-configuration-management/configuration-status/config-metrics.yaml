# ============================================================
# AUDIT: Configuration Metrics
# Category: 30 - Configuration Management
# Subcategory: configuration-status
# ============================================================
# Metrics and KPIs for configuration management effectiveness
# and operational visibility.
# ============================================================

audit:
  id: "configuration-management.configuration-status.config-metrics"
  name: "Configuration Metrics Audit"
  version: "1.0.0"
  last_updated: "2025-01-22"
  status: "active"

  category: "configuration-management"
  category_number: 30
  subcategory: "configuration-status"

  tier: "expert"
  estimated_duration: "2-3 hours"  # median: 2h

  completeness: "complete"
  requires_runtime: false
  destructive: false

execution:
  automatable: "partial"
  severity: "medium"
  scope: "infrastructure"

  default_profiles:
    - "full"
    - "production"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    This audit examines the metrics and KPIs used to measure configuration
    management effectiveness. It evaluates:
    - Change volume and frequency metrics
    - Change success and failure rates
    - Configuration drift metrics
    - Time to implement changes
    - Approval cycle time metrics
    - Compliance and policy adherence rates
    - Configuration-related incident correlation

  why_it_matters: |
    Configuration metrics enable data-driven improvement:
    - CMMI requires measurement for process improvement
    - ITIL recommends CSFs and KPIs for configuration management
    - Metrics identify bottlenecks and improvement opportunities
    - Trend analysis enables proactive management
    - Incident correlation reveals configuration-related issues
    - Benchmarking enables comparison and goal setting
    - Reporting to management requires quantifiable data

  when_to_run:
    - "When establishing configuration management"
    - "During process improvement initiatives"
    - "For management reporting"
    - "When metrics accuracy is questioned"
    - "Quarterly metrics reviews"

prerequisites:
  required_artifacts:
    - type: "metrics_systems"
      description: "Metrics and monitoring systems"
    - type: "documentation"
      description: "Metrics definitions and targets"

  access_requirements:
    - "Access to metrics and monitoring systems"
    - "Access to change management data"
    - "Access to incident data for correlation"

discovery:
  code_patterns:
    - pattern: "(metric|kpi|measure|indicator)[-_](config|change|drift)"
      type: "regex"
      scope: "config"
      purpose: "Detect metrics configurations"

    - pattern: "(prometheus|datadog|cloudwatch|grafana)[-_]"
      type: "regex"
      scope: "config"
      purpose: "Detect monitoring tool integration"

  file_patterns:
    - glob: "**/metrics/**"
      purpose: "Metrics configurations"
    - glob: "**/dashboards/**"
      purpose: "Dashboard definitions"
    - glob: "**/*prometheus*"
      purpose: "Prometheus configurations"

knowledge_sources:
  specifications:
    - id: "itil-csfs-kpis"
      name: "ITIL CSFs and KPIs for Configuration Management"
      url: "https://www.axelos.com/best-practice-solutions/itil"
      offline_cache: true
      priority: "required"

  guides:
    - id: "dora-metrics"
      name: "DORA Metrics"
      url: "https://dora.dev/research/"
      offline_cache: true

tooling:
  scripts:
    - id: "metrics-audit"
      language: "bash"
      purpose: "Audit configuration metrics"
      source: "inline"
      code: |
        #!/bin/bash
        echo "=== Configuration Metrics Audit ==="
        echo ""
        echo "=== Metrics Configurations ==="
        find . -type f \( -name "*metrics*" -o -name "*prometheus*" \) \
          -not -path "*/node_modules/*" 2>/dev/null | head -20
        echo ""
        echo "=== Dashboard Configurations ==="
        find . -name "*dashboard*" -not -path "*/node_modules/*" 2>/dev/null | head -20
        echo ""
        echo "=== Change Frequency (last 30 days) ==="
        git log --since="30 days ago" --oneline -- "*.yaml" "*.json" "*.tf" 2>/dev/null | wc -l

signals:
  critical:
    - id: "CMET-CRIT-001"
      signal: "No configuration management metrics"
      evidence_indicators:
        - "No metrics collected"
        - "No dashboards for configuration"
        - "No way to measure effectiveness"
      explanation: |
        ITIL recommends KPIs for configuration management. Without
        metrics, effectiveness cannot be measured or improved,
        and management lacks visibility.
      remediation: |
        - Define configuration management KPIs
        - Implement metrics collection
        - Create dashboards for visibility
        - Establish baselines and targets
      cwe: "CWE-1059"

  high:
    - id: "CMET-HIGH-001"
      signal: "Change success rate not measured"
      evidence_indicators:
        - "No tracking of successful vs failed changes"
        - "Rollback frequency unknown"
        - "Change quality not quantified"
      explanation: |
        Change success rate is a key DORA metric. Without this
        metric, change quality cannot be assessed or improved.
      remediation: |
        - Track change outcomes
        - Measure rollback frequency
        - Calculate success rates
        - Set improvement targets

    - id: "CMET-HIGH-002"
      signal: "Configuration drift not quantified"
      evidence_indicators:
        - "No drift metrics"
        - "Drift discovered ad-hoc"
        - "Cannot measure drift trends"
      explanation: |
        Drift metrics enable proactive management. Without
        quantification, drift accumulates until it causes
        incidents.
      remediation: |
        - Implement drift detection
        - Quantify drift by environment/type
        - Track drift trends
        - Alert on drift thresholds

    - id: "CMET-HIGH-003"
      signal: "No correlation with incidents"
      evidence_indicators:
        - "Changes not linked to incidents"
        - "Configuration-related incidents not tracked"
        - "Cannot identify change impact"
      explanation: |
        Incident correlation identifies problematic changes.
        Without correlation, systemic issues related to
        configuration changes go unaddressed.
      remediation: |
        - Link incidents to recent changes
        - Track configuration-related incidents
        - Measure mean time to recovery
        - Analyze incident patterns

  medium:
    - id: "CMET-MED-001"
      signal: "Change cycle time not measured"
      evidence_indicators:
        - "Time from request to deployment unknown"
        - "Approval delays not tracked"
        - "No lead time metrics"
      explanation: |
        Cycle time reveals process efficiency. Long cycle
        times indicate bottlenecks that slow delivery.
      remediation: |
        - Track change cycle time
        - Measure approval duration
        - Identify bottlenecks
        - Set efficiency targets

    - id: "CMET-MED-002"
      signal: "Metrics not visible to stakeholders"
      evidence_indicators:
        - "Metrics not in dashboards"
        - "No regular reporting"
        - "Stakeholders lack access"
      explanation: |
        Visible metrics enable informed decisions. Hidden
        metrics don't influence behavior or enable oversight.
      remediation: |
        - Create visible dashboards
        - Share metrics in reports
        - Enable stakeholder access
        - Discuss metrics in reviews

  low:
    - id: "CMET-LOW-001"
      signal: "Metrics definitions not documented"
      evidence_indicators:
        - "Metrics meaning unclear"
        - "Calculation methods undocumented"
        - "Inconsistent interpretation"
      explanation: |
        Documented definitions ensure consistent understanding.
        Undocumented metrics may be misinterpreted.
      remediation: |
        - Document all metric definitions
        - Explain calculation methods
        - Provide interpretation guidance
        - Keep documentation current

  positive:
    - id: "CMET-POS-001"
      signal: "Comprehensive configuration metrics"
      evidence_indicators:
        - "Key KPIs defined and tracked"
        - "Dashboards provide visibility"
        - "Metrics drive improvement"

procedure:
  context:
    cognitive_mode: "methodical"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Metrics Inventory"
      description: "Inventory current configuration metrics."
      duration_estimate: "30 min"
      commands:
        - purpose: "Find metrics configurations"
          command: |
            find . -type f \( -name "*metrics*" -o -name "*prometheus*" \
              -o -name "*alert*" \) -not -path "*/node_modules/*" 2>/dev/null | head -30
        - purpose: "Find dashboard definitions"
          command: |
            find . -name "*dashboard*" -not -path "*/node_modules/*" 2>/dev/null | head -20

    - id: "2"
      name: "Change Metrics Analysis"
      description: "Analyze change-related metrics availability."
      duration_estimate: "30 min"
      commands:
        - purpose: "Calculate change frequency"
          command: |
            echo "Changes in last 7 days:"
            git log --since="7 days ago" --oneline -- "*.yaml" "*.json" "*.tf" 2>/dev/null | wc -l
            echo "Changes in last 30 days:"
            git log --since="30 days ago" --oneline -- "*.yaml" "*.json" "*.tf" 2>/dev/null | wc -l
        - purpose: "Analyze change distribution"
          command: |
            git log --since="30 days ago" --format="%ad" --date=short -- "*.yaml" "*.json" "*.tf" 2>/dev/null | \
              sort | uniq -c | head -30

output:
  deliverables:
    - type: "finding_list"
      format: "structured"
    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Metrics Coverage"
        - "Gap Analysis"
        - "Recommendations"
    - type: "metrics_catalog"
      format: "table"
      description: "Configuration metrics inventory"

offline:
  capability: "full"
  cache_manifest:
    knowledge:
      - source_id: "itil-csfs-kpis"
        priority: "required"

profiles:
  membership:
    quick:
      included: false
      reason: "Metrics audit requires thorough review"
    full:
      included: true
      priority: 2
    production:
      included: true
      priority: 2

closeout_checklist:
  - id: "cmet-001"
    item: "Configuration management KPIs defined"
    level: "BLOCKING"
    verification: "manual"
    verification_notes: "Verify KPIs are defined and documented"
    expected: "Confirmed by reviewer"

governance:
  applicable_to:
    archetypes: ["all"]
  compliance_frameworks:
    - framework: "ITIL"
      controls: ["CSFs and KPIs"]
    - framework: "CMMI"
      controls: ["MA"]

relationships:
  commonly_combined:
    - "configuration-management.configuration-status.config-reporting"
    - "configuration-management.configuration-status.change-tracking"
