audit:
  id: documentation-knowledge.operational-docs.monitoring-documentation
  name: Monitoring Documentation Audit
  version: 1.0.0
  last_updated: '2025-01-22'
  status: active
  category: documentation-knowledge
  category_number: 27
  subcategory: operational-docs
  tier: expert
  estimated_duration: 2-4 hours  # median: 3h
  completeness: complete
  requires_runtime: false
  destructive: false
execution:
  automatable: partial
  severity: medium
  scope: documentation
  default_profiles:
  - full
  blocks_phase: false
  parallelizable: true
description:
  what: |
    This audit evaluates documentation of monitoring systems, including
    dashboard guides, metric explanations, alert documentation, and
    observability architecture. The audit examines whether teams can
    effectively use monitoring tools to understand system health and
    diagnose issues.
  why_it_matters: |
    Monitoring systems are only valuable when operators understand how to
    use them. Without documentation, dashboards become confusing, metrics
    lack context, and alerts fire without clear meaning. Well-documented
    monitoring enables faster incident detection and resolution while
    reducing cognitive load on operators.
  when_to_run:
  - When establishing monitoring for new services
  - After observability platform changes
  - When onboarding new operations staff
  - During observability maturity assessments
prerequisites:
  required_artifacts:
  - type: monitoring_platform
    description: Access to monitoring dashboards and configuration
  - type: alerting_rules
    description: Alert definitions with associated documentation
  access_requirements:
  - Read access to monitoring documentation
  - View access to monitoring dashboards
  - Access to alerting rule definitions
discovery:
  file_patterns:
  - glob: '**/docs/monitoring/**/*'
    purpose: Find monitoring documentation
  - glob: '**/dashboards/**/*.json'
    purpose: Find dashboard definitions
  - glob: '**/alerts/**/*.yaml'
    purpose: Find alert configurations
  - glob: '**/observability/**/*.md'
    purpose: Find observability documentation
  - glob: '**/metrics/**/*.md'
    purpose: Find metric documentation
  interview_questions:
  - role: SRE/Operations
    questions:
    - How do you find the right dashboard for a service?
    - How do you understand what a metric means?
    - How are dashboards and alerts documented?
    - What monitoring documentation is missing?
knowledge_sources:
  guides:
  - id: google-sre-monitoring
    name: Google SRE - Monitoring Distributed Systems
    url: https://sre.google/sre-book/monitoring-distributed-systems/
    offline_cache: true
  - id: grafana-best-practices
    name: Grafana Dashboard Best Practices
    url: https://grafana.com/docs/grafana/latest/dashboards/build-dashboards/best-practices/
    offline_cache: true
tooling:
  analysis_commands:
  - purpose: List dashboards
    command: find . -name '*.json' -path '*/dashboards/*' | head -20
  - purpose: Find alerting rules
    command: find . -name '*.yaml' -path '*/alerts/*' -o -name '*rules*.yaml'
  - purpose: Check for runbook links in alerts
    command: grep -r 'runbook_url' --include='*.yaml' alerts/
signals:
  critical:
  - id: MONITORING-CRIT-001
    signal: No monitoring documentation exists
    evidence_indicators:
    - Dashboards undocumented
    - No metric glossary or explanations
    - Teams don't understand monitoring outputs
    explanation: |
      Without monitoring documentation, operators cannot effectively
      use monitoring tools during incidents or for proactive detection.
    remediation: Create documentation for key dashboards and metrics
  - id: MONITORING-CRIT-002
    signal: Alerts lack runbook or explanation
    evidence_indicators:
    - Alert messages don't explain meaning
    - No runbook links in alert annotations
    - Operators confused by alerts
    explanation: |
      Alerts without context waste time during incidents as responders
      must research the alert's meaning before acting.
    remediation: Add runbook_url and description to all alerts
  high:
  - id: MONITORING-HIGH-001
    signal: Dashboard purpose and usage not documented
    evidence_indicators:
    - No dashboard README or descriptions
    - Panel purposes unclear
    - Teams create duplicate dashboards
    explanation: |
      Undocumented dashboards lead to misinterpretation and duplicate
      effort as teams create their own dashboards.
    remediation: Add documentation to all production dashboards
  - id: MONITORING-HIGH-002
    signal: Metrics lack definition or units
    evidence_indicators:
    - Metric names ambiguous
    - Units not specified
    - Teams interpret metrics differently
    explanation: |
      Ambiguous metrics lead to incorrect conclusions and poor decisions
      based on misunderstood data.
    remediation: Create metric glossary with definitions and units
  medium:
  - id: MONITORING-MED-001
    signal: Alert thresholds not explained
    explanation: |
      Without threshold rationale, teams may adjust thresholds incorrectly
      or not understand alert significance.
    remediation: Document threshold rationale for all alerts
  - id: MONITORING-MED-002
    signal: Monitoring architecture not documented
    remediation: Create observability architecture documentation
  - id: MONITORING-MED-003
    signal: Dashboard organization not consistent
    remediation: Establish dashboard naming and organization conventions
  low:
  - id: MONITORING-LOW-001
    signal: No dashboard change tracking
    remediation: Version control dashboard definitions
  - id: MONITORING-LOW-002
    signal: Missing metric collection documentation
    remediation: Document how metrics are collected and processed
  positive:
  - id: MONITORING-POS-001
    signal: Comprehensive metric glossary maintained
  - id: MONITORING-POS-002
    signal: All alerts link to runbooks
  - id: MONITORING-POS-003
    signal: Dashboards include documentation panels
procedure:
  context:
    cognitive_mode: analytical
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Inventory Monitoring Assets
    description: |
      Identify all dashboards, alerts, and metrics that require documentation.
    duration_estimate: 30 min
    commands:
    - purpose: List all dashboards
      command: 'curl -s ''http://grafana:3000/api/search?type=dash-db'' -H ''Authorization: Bearer TOKEN''
        | jq ''.[].title'''
    - purpose: List alert rules
      command: find . -name '*.yaml' -exec grep -l 'alert:' {} \;
    expected_findings:
    - Dashboard inventory
    - Alert rule inventory
    - Key metrics list
  - id: '2'
    name: Assess Dashboard Documentation
    description: |
      Review dashboard documentation and in-dashboard descriptions.
    duration_estimate: 45 min
    quality_checklist:
    - Dashboard purpose clearly stated
    - Panel descriptions present
    - Usage instructions provided
    - Audience identified
    - Related dashboards linked
    expected_findings:
    - Dashboard documentation coverage
    - Quality assessment
  - id: '3'
    name: Review Alert Documentation
    description: |
      Evaluate alert definitions for documentation quality.
    duration_estimate: 45 min
    quality_checklist:
    - Alert description explains meaning
    - Runbook link provided
    - Severity rationale documented
    - Threshold explanation provided
    expected_findings:
    - Alert documentation coverage
    - Missing runbook links
  - id: '4'
    name: Evaluate Metric Documentation
    description: |
      Review metric documentation for key system metrics.
    duration_estimate: 30 min
    questions:
    - Is there a metric glossary?
    - Are metric units documented?
    - Are metric collection methods explained?
    expected_findings:
    - Metric documentation status
    - Documentation gaps
  - id: '5'
    name: Assess Discoverability
    description: |
      Evaluate how easily team members can find relevant monitoring
      documentation and assets.
    duration_estimate: 30 min
    expected_findings:
    - Discoverability assessment
    - Navigation improvements needed
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Dashboard Documentation Review
    - Alert Documentation Review
    - Metric Documentation Review
    - Recommendations
  confidence_guidance:
    high: All monitoring assets reviewed comprehensively
    medium: Representative sample reviewed
    low: High-level inventory only
closeout_checklist:
- id: monitoring-001
  item: Key dashboards have documentation
  level: CRITICAL
  verification: manual
  verification_notes: Check production dashboards for descriptions
  expected: All Tier 1 dashboards documented
- id: monitoring-002
  item: All alerts have runbook links
  level: BLOCKING
  verification: grep -L 'runbook_url' alerts/*.yaml
  expected: No alerts without runbook links
- id: monitoring-003
  item: Metric glossary exists and is current
  level: WARNING
  verification: find . -name '*metric*glossary*' -o -name '*metrics*dictionary*'
  expected: Glossary file exists and recently updated
governance:
  applicable_to:
    archetypes:
    - monitored-systems
    - production-services
relationships:
  commonly_combined:
  - observability.dashboard-quality
  - observability.alerting-effectiveness
  feeds_into:
  - incident-management.response-time
  - sre.mttr-metrics
