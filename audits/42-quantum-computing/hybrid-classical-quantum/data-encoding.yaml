# ============================================================
# AUDIT: Data Encoding
# Category: 42 - Quantum Computing
# Subcategory: hybrid-classical-quantum
# ============================================================

audit:
  id: "quantum-computing.hybrid-classical-quantum.data-encoding"
  name: "Quantum Data Encoding Audit"
  version: "1.0.0"
  last_updated: "2025-01-22"
  status: "active"

  category: "quantum-computing"
  category_number: 42
  subcategory: "hybrid-classical-quantum"

  tier: "expert"
  estimated_duration: "3-4 hours"  # median: 3h

  completeness: "requires_discovery"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "quantum-systems"

  default_profiles:
    - "full"
    - "quick"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Evaluates how classical data is encoded into quantum states for processing.
    Assesses encoding efficiency, expressiveness, hardware compatibility, and
    impact on circuit depth. Reviews amplitude encoding, angle encoding, basis
    encoding, and other encoding strategies.

  why_it_matters: |
    Data encoding determines what quantum operations can extract useful
    information. Poor encoding wastes qubits, adds depth, or fails to
    capture relevant data structure. Encoding is often the bottleneck
    for quantum advantage in machine learning and optimization.

  when_to_run:
    - "When designing quantum ML algorithms"
    - "When optimizing circuit efficiency"
    - "When scaling to larger datasets"
    - "When changing problem encoding"

prerequisites:
  required_artifacts:
    - type: "encoding_code"
      description: "Data encoding implementation"
    - type: "data_specification"
      description: "Structure of data to encode"
    - type: "algorithm_requirements"
      description: "What algorithm needs from encoding"

  access_requirements:
    - "Access to encoding code"
    - "Sample data for testing"
    - "Algorithm specification"

discovery:
  file_patterns:
    - glob: "**/encoding/**/*.py"
      purpose: "Find encoding implementations"
    - glob: "**/feature_map/**/*.py"
      purpose: "Find feature maps"

  code_patterns:
    - pattern: "amplitude_encoding|angle_encoding"
      type: "keyword"
      scope: "source"
      purpose: "Find encoding methods"
    - pattern: "feature_map|ZZFeatureMap"
      type: "keyword"
      scope: "source"
      purpose: "Find Qiskit feature maps"

knowledge_sources:
  specifications:
    - id: "quantum-encoding"
      name: "Quantum Data Encoding Strategies"
      url: "https://arxiv.org/abs/2001.03622"
      offline_cache: true
      priority: "required"

  guides:
    - id: "qiskit-ml-encoding"
      name: "Qiskit Machine Learning Encoding"
      url: "https://qiskit.org/documentation/machine-learning/"
      offline_cache: true

tooling:
  analysis_tools:
    - tool: "qiskit-machine-learning"
      purpose: "Quantum ML feature maps"

    - tool: "pennylane"
      purpose: "Quantum ML encoding"

signals:
  critical:
    - id: "DE-CRIT-001"
      signal: "Encoding loses essential information"
      evidence_indicators:
        - "Data features not recoverable from encoding"
        - "Encoding precision insufficient"
        - "Critical correlations not captured"
      explanation: |
        If encoding loses information needed by the algorithm,
        quantum processing cannot produce useful results.
      remediation: |
        Analyze information preservation.
        Use higher-precision encoding.
        Choose encoding that preserves needed structure.

    - id: "DE-CRIT-002"
      signal: "Encoding depth exceeds coherence limits"
      evidence_threshold: "encoding_depth > 0.1 * T2 / gate_time"
      explanation: |
        Deep encoding circuits consume coherence time before the
        algorithm even begins, leaving insufficient time for computation.
      remediation: "Use shallower encoding or approximate encoding"

  high:
    - id: "DE-HIGH-001"
      signal: "Inefficient qubit utilization"
      evidence_indicators:
        - "More qubits than necessary for data"
        - "Amplitude encoding not used when applicable"
      remediation: "Optimize encoding for qubit efficiency"

    - id: "DE-HIGH-002"
      signal: "Encoding not matched to algorithm"
      evidence_indicators:
        - "Algorithm cannot leverage encoded structure"
        - "Encoding-algorithm mismatch"
      remediation: "Choose encoding that benefits algorithm"

  medium:
    - id: "DE-MED-001"
      signal: "No encoding normalization"
      remediation: "Normalize data before encoding"

    - id: "DE-MED-002"
      signal: "Encoding not tested for range of inputs"
      remediation: "Test encoding across input domain"

  low:
    - id: "DE-LOW-001"
      signal: "Encoding choice not documented"
      remediation: "Document encoding rationale"

  positive:
    - id: "DE-POS-001"
      signal: "Efficient encoding for data structure"
    - id: "DE-POS-002"
      signal: "Encoding well-matched to algorithm"
    - id: "DE-POS-003"
      signal: "Encoding depth minimized"

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Identify Encoding Method"
      description: "Document encoding strategy used"
      duration_estimate: "30 min"

    - id: "2"
      name: "Analyze Information Preservation"
      description: "Check what information encoding preserves"
      duration_estimate: "1 hour"

    - id: "3"
      name: "Measure Encoding Overhead"
      description: "Calculate qubit and depth cost"
      duration_estimate: "45 min"

    - id: "4"
      name: "Assess Algorithm Compatibility"
      description: "Verify encoding suits algorithm needs"
      duration_estimate: "45 min"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "encoding_analysis"
      format: "json"
      description: "Encoding efficiency analysis"

closeout_checklist:
  - id: "de-001"
    item: "Information preservation verified"
    level: "CRITICAL"
    verification: "manual"

  - id: "de-002"
    item: "Encoding depth acceptable"
    level: "BLOCKING"
    verification: "automated"

  - id: "de-003"
    item: "Algorithm compatibility verified"
    level: "WARNING"
    verification: "manual"

governance:
  applicable_to:
    archetypes: ["quantum-systems", "quantum-ml"]

relationships:
  commonly_combined:
    - "quantum-computing.hybrid-classical-quantum.result-decoding"
    - "quantum-computing.quantum-algorithm.circuit-depth"
  feeds_into:
    - "quantum-computing.quantum-algorithm.algorithm-correctness"
