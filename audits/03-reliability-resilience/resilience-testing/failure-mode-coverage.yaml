audit:
  id: reliability-resilience.resilience-testing.failure-mode-coverage
  name: Failure Mode Coverage Audit
  version: 1.0.0
  last_updated: '2026-01-18'
  status: active
  category: reliability-resilience
  category_number: 3
  subcategory: resilience-testing
  tier: phd
  estimated_duration: 4 hours
  completeness: requires_discovery
  requires_runtime: true
  destructive: true
execution:
  automatable: partial
  severity: critical
  scope: testing
  default_profiles:
  - full
  - production
  blocks_phase: false
  parallelizable: false
description:
  what: |
    This audit assesses the breadth and depth of chaos engineering experiments
    in covering known and potential failure modes. It evaluates whether failure
    scenarios across infrastructure, application, and dependency layers are
    systematically tested, documented, and validated against expected behaviors.
  why_it_matters: |
    Incomplete failure mode coverage leaves systems vulnerable to unexpected
    outages. Organizations that only test happy paths or common failures
    experience longer and more severe incidents when novel failures occur.
    Comprehensive failure mode testing builds operational muscle memory and
    validates that monitoring, alerting, and recovery mechanisms work as designed.
  when_to_run:
  - Quarterly chaos engineering maturity assessment
  - Before major production deployments
  - After significant architectural changes
  - Following production incidents caused by untested failure modes
prerequisites:
  required_artifacts:
  - type: chaos-experiment-catalog
    description: Registry of all defined chaos experiments
  - type: system-architecture
    description: Current system architecture documentation
  - type: failure-mode-inventory
    description: Documented list of known failure modes
  access_requirements:
  - Read access to chaos engineering platform (Gremlin, LitmusChaos, etc.)
  - Access to experiment execution history and results
  - Read access to incident post-mortem documentation
discovery:
  code_patterns:
  - pattern: chaos|experiment|fault.*inject|failure.*test
    type: regex
    scope: config
    purpose: Identify chaos experiment definitions
  - pattern: gremlin|litmus|chaosmonkey|toxiproxy
    type: keyword
    scope: config
    purpose: Identify chaos tooling configurations
  file_patterns:
  - glob: '**/chaos/**/*.yaml'
    purpose: Chaos experiment definition files
  - glob: '**/experiments/**/*'
    purpose: Experiment configurations
  - glob: '**/gameday/**/*'
    purpose: Game day runbooks and scenarios
  documents_to_review:
  - type: Failure Mode and Effects Analysis (FMEA)
    purpose: Understand known failure modes and their priorities
  - type: Post-incident reviews
    purpose: Identify failure modes discovered in production
  - type: Chaos experiment results
    purpose: Assess current test coverage
knowledge_sources:
  specifications:
  - id: principles-of-chaos
    name: Principles of Chaos Engineering
    url: https://principlesofchaos.org/
    offline_cache: true
    priority: required
  guides:
  - id: gremlin-failure-modes
    name: Gremlin Failure Mode Catalog
    url: https://www.gremlin.com/community/tutorials/chaos-engineering-the-history-principles-and-practice/
    offline_cache: true
  - id: netflix-chaos
    name: Netflix Chaos Engineering
    url: https://netflixtechblog.com/tagged/chaos-engineering
    offline_cache: true
  papers:
  - id: chaos-engineering-netflix
    title: Chaos Engineering at Netflix
    url: https://arxiv.org/abs/1702.05843
  learning_resources:
  - id: chaos-engineering-book
    title: 'Chaos Engineering: System Resiliency in Practice'
    type: book
    reference: 'ISBN: 978-1492043867'
tooling:
  infrastructure_tools:
  - tool: Gremlin
    purpose: Enterprise chaos engineering platform
    command: gremlin attack list
  - tool: LitmusChaos
    purpose: Kubernetes-native chaos engineering
    command: kubectl get chaosengines -A
  - tool: Chaos Monkey
    purpose: Random instance termination
    command: Check Spinnaker integration
  - tool: Toxiproxy
    purpose: Network failure simulation
    command: toxiproxy-cli list
  monitoring_queries:
  - system: Prometheus
    query: count(chaos_experiment_total) by (experiment_type)
    purpose: Count chaos experiments by type
    threshold: Coverage across all failure categories
  scripts:
  - id: coverage-analyzer
    language: python
    purpose: Analyze failure mode coverage gaps
    source: inline
    code: |
      #!/usr/bin/env python3
      """
      Failure Mode Coverage Analyzer
      Compares known failure modes against chaos experiments
      """
      import yaml
      import json

      FAILURE_CATEGORIES = [
          'compute_failure',
          'network_failure',
          'storage_failure',
          'dependency_failure',
          'resource_exhaustion',
          'data_corruption',
          'configuration_error',
          'security_incident'
      ]

      def analyze_coverage(experiments_file, fmea_file):
          # Load experiments and FMEA
          # Compare coverage
          # Report gaps
          pass
signals:
  critical:
  - id: FMC-CRIT-001
    signal: No chaos experiments exist for critical services
    evidence_indicators:
    - Zero experiments defined for Tier-1 services
    - No experiment history in chaos platform
    explanation: |
      Critical services with no chaos testing represent significant risk.
      Production failures in these services will reveal unknown failure
      modes under pressure, leading to extended outages.
    remediation: Implement baseline chaos experiments for all critical services
  - id: FMC-CRIT-002
    signal: Major failure categories have no coverage
    evidence_indicators:
    - No network partition experiments
    - No dependency failure experiments
    - No resource exhaustion experiments
    explanation: |
      Missing entire categories of failure testing indicates systemic
      gaps in resilience validation. These gaps often correspond to
      the most severe production incidents.
    remediation: Develop experiments for each failure category in FMEA
  high:
  - id: FMC-HIGH-001
    signal: Experiments not run in production-like environment
    explanation: Staging-only chaos testing misses production-specific behaviors
    remediation: Establish safe production chaos testing practices
  - id: FMC-HIGH-002
    signal: Failure mode inventory not maintained
    explanation: Without a current FMEA, coverage cannot be properly assessed
    remediation: Create and maintain failure mode inventory
  medium:
  - id: FMC-MED-001
    signal: Low-probability high-impact failures not tested
    remediation: Prioritize tail-risk failure mode experiments
  - id: FMC-MED-002
    signal: Experiments not updated after architecture changes
    remediation: Include chaos experiment review in architecture change process
  low:
  - id: FMC-LOW-001
    signal: Experiment documentation incomplete
  positive:
  - id: FMC-POS-001
    signal: Comprehensive failure mode coverage matrix maintained
  - id: FMC-POS-002
    signal: Regular game days exercising multiple failure modes
procedure:
  context:
    cognitive_mode: critical
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Inventory Known Failure Modes
    description: |
      Collect and categorize all known failure modes from FMEA documents,
      post-incident reviews, and architecture risk assessments.
    duration_estimate: 45 min
    questions:
    - What failure modes are documented in the FMEA?
    - What new failure modes were discovered in recent incidents?
    - What failure modes are theoretical but untested?
    expected_findings:
    - Complete list of known failure modes by category
    - Priority ranking of failure modes by impact
  - id: '2'
    name: Catalog Existing Experiments
    description: |
      Document all chaos experiments across tooling platforms,
      including their target components and failure types.
    duration_estimate: 60 min
    commands:
    - purpose: List Litmus chaos experiments
      command: kubectl get chaosengines -A -o yaml
    - purpose: List Gremlin attacks
      command: gremlin attack list --format json
    expected_findings:
    - Inventory of all defined chaos experiments
    - Mapping of experiments to target services
  - id: '3'
    name: Perform Coverage Gap Analysis
    description: |
      Compare the failure mode inventory against existing experiments
      to identify gaps in coverage.
    duration_estimate: 60 min
    questions:
    - Which failure modes have no corresponding experiments?
    - Which critical services lack chaos testing?
    - What failure categories are underrepresented?
    expected_findings:
    - Coverage matrix showing tested vs untested failure modes
    - List of priority gaps to address
  - id: '4'
    name: Assess Experiment Quality
    description: |
      Evaluate the quality and realism of existing experiments,
      including blast radius controls and success criteria.
    duration_estimate: 45 min
    questions:
    - Do experiments have proper blast radius controls?
    - Are success/failure criteria well-defined?
    - Are experiments regularly executed?
    expected_findings:
    - Quality assessment of existing experiments
    - Recommendations for experiment improvements
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: coverage_matrix
    format: table
    sections:
    - Failure Mode by Category
    - Current Coverage Status
    - Priority Gap List
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Coverage Analysis
    - Key Findings
    - Prioritized Recommendations
  confidence_guidance:
    high: Experiments verified through execution logs and platform audit
    medium: Experiment definitions exist but execution not verified
    low: Coverage inferred from documentation without verification
offline:
  capability: partial
  cache_manifest:
    knowledge:
    - source_id: principles-of-chaos
      priority: required
    - source_id: gremlin-failure-modes
      priority: recommended
profiles:
  membership:
    quick:
      included: false
      reason: Requires comprehensive analysis of experiments and failure modes
    full:
      included: true
      priority: 1
    production:
      included: true
      priority: 1
closeout_checklist:
- id: fmc-001
  item: Failure mode inventory documented
  level: CRITICAL
  verification: manual
  verification_notes: Confirm FMEA or equivalent documentation exists and is current
  expected: Confirmed by reviewer
- id: fmc-002
  item: Chaos experiments cataloged
  level: CRITICAL
  verification: manual
  verification_notes: Verify complete inventory of chaos experiments across all platforms
  expected: Confirmed by reviewer
- id: fmc-003
  item: Coverage matrix generated
  level: BLOCKING
  verification: manual
  verification_notes: Coverage matrix maps experiments to failure modes
  expected: Confirmed by reviewer
- id: fmc-004
  item: Critical gaps identified and prioritized
  level: BLOCKING
  verification: manual
  verification_notes: Priority list of coverage gaps with remediation plan
  expected: Confirmed by reviewer
governance:
  applicable_to:
    archetypes:
    - distributed-system
    - microservices
    - cloud-native
  compliance_frameworks:
  - framework: SOC 2
    controls:
    - CC7.1
    - CC7.2
  - framework: ISO 27001
    controls:
    - A.17.1
relationships:
  commonly_combined:
  - reliability-resilience.resilience-testing.blast-radius-verification
  - reliability-resilience.resilience-testing.recovery-automation
  - reliability-resilience.fault-tolerance.graceful-degradation
