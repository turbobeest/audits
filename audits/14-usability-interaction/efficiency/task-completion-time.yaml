audit:
  id: usability-interaction.efficiency.task-completion-time
  name: Task Completion Time Audit
  version: 1.0.0
  last_updated: '2026-01-19'
  status: active
  category: usability-interaction
  category_number: 14
  subcategory: efficiency
  tier: expert
  estimated_duration: 4 hours
  completeness: complete
  requires_runtime: true
  destructive: false
execution:
  automatable: partial
  severity: high
  scope: qualitative
  default_profiles:
  - full
  blocks_phase: false
  parallelizable: true
description:
  what: |
    This audit measures and analyzes the time required for users to complete
    key tasks within the application. It evaluates:

    - Time-on-task for critical user journeys
    - Comparison against benchmarks and competitors
    - Identification of bottlenecks and delays
    - Efficiency differences between user types
    - Impact of interface design on completion speed
    - Learning curve effects on task time
  why_it_matters: |
    Task completion time is a core usability metric that directly impacts:
    - User productivity and satisfaction
    - Operational efficiency (time = money for business users)
    - Competitive positioning
    - User perception of application quality
    - Willingness to continue using the product

    Unnecessarily slow task completion leads to frustration, workarounds,
    and eventually abandonment of the product.
  when_to_run:
  - Usability benchmarking
  - Post-redesign validation
  - Competitive analysis
  - User complaints about slowness
  - Productivity optimization initiatives
prerequisites:
  required_artifacts:
  - type: application
    description: Running application for task timing
  - type: task_definitions
    description: Defined set of tasks to measure
  - type: test_users
    description: Representative users for testing
  access_requirements:
  - Full application access
  - Session recording capability
  - Stopwatch or timing software
discovery:
  documents_to_review:
  - type: User flow documentation
    purpose: Identify critical task paths
  - type: Analytics dashboards
    purpose: Find common user journeys
  - type: Support tickets
    purpose: Identify tasks users struggle with
  interviews:
  - role: End users
    questions:
    - What tasks take longer than you expect?
    - What workflows feel inefficient?
    - Where do you experience delays?
    purpose: Identify perceived bottlenecks
  file_patterns:
  - glob: '**/*.md'
    purpose: Documentation files
  - glob: '**/*.yaml'
    purpose: Configuration files
  - glob: '**/*.json'
    purpose: JSON configuration
knowledge_sources:
  specifications:
  - id: iso-9241-11
    name: ISO 9241-11 Usability Guidance
    url: https://www.iso.org/standard/63500.html
    offline_cache: false
    priority: required
  guides:
  - id: nngroup-task-time
    name: Task Time Measurement
    url: https://www.nngroup.com/articles/task-time/
    offline_cache: true
  - id: nngroup-usability-metrics
    name: Usability Metrics
    url: https://www.nngroup.com/articles/usability-metrics/
    offline_cache: true
  learning_resources:
  - id: measuring-ux
    title: Measuring the User Experience
    type: book
    reference: Tom Tullis & Bill Albert, ISBN 978-0128180808
tooling:
  assessment_tools:
  - tool: Session recording software
    purpose: Record and time user sessions
  - tool: Stopwatch/timing tool
    purpose: Measure task completion times
  - tool: Spreadsheet for data analysis
    purpose: Calculate statistics and identify patterns
  scripts:
  - id: task-time-calculator
    language: python
    purpose: Calculate task time statistics
    source: inline
    code: |
      import statistics

      def analyze_times(times):
          return {
              "mean": statistics.mean(times),
              "median": statistics.median(times),
              "stdev": statistics.stdev(times) if len(times) > 1 else 0,
              "min": min(times),
              "max": max(times)
          }
signals:
  critical:
  - id: TCT-CRIT-001
    signal: Critical task takes 5x longer than competitor benchmark
    evidence_indicators:
    - Task time significantly exceeds industry standard
    - Users abandon task before completion
    - Workarounds are commonly used
    explanation: |
      When core tasks take dramatically longer than alternatives,
      users will seek other solutions or abandon the product.
    remediation: Analyze task flow; eliminate unnecessary steps; optimize interface
  - id: TCT-CRIT-002
    signal: Task completion rate below 50% due to time/complexity
    evidence_indicators:
    - Users give up mid-task
    - High task abandonment rates
    - Support requests about task completion
    explanation: |
      Tasks that most users cannot complete fail their basic purpose
      and indicate fundamental usability problems.
    remediation: Simplify task flow; reduce required steps; add guidance
  high:
  - id: TCT-HIGH-001
    signal: Frequent task requires more than 10 steps to complete
    explanation: |
      Frequently performed tasks should be optimized for efficiency.
      Excessive steps waste user time and invite errors.
    remediation: Consolidate steps; add shortcuts; automate where possible
  - id: TCT-HIGH-002
    signal: Expert users show no time improvement over novices
    explanation: |
      The interface should reward experience with efficiency gains.
      If experts aren't faster, the interface lacks expert-level optimizations.
    remediation: Add keyboard shortcuts, templates, bulk actions, or automation
  - id: TCT-HIGH-003
    signal: Significant wait times between steps (system latency)
    explanation: |
      System delays compound across steps, dramatically increasing
      total task time and user frustration.
    remediation: Optimize system performance; add asynchronous processing
  medium:
  - id: TCT-MED-001
    signal: Task time varies widely (CV > 50%) indicating unclear flow
    remediation: Clarify task instructions and flow; reduce decision points
  - id: TCT-MED-002
    signal: Repetitive tasks lack time-saving features
    remediation: Add templates, presets, or batch operations
  low:
  - id: TCT-LOW-001
    signal: Minor inconsistencies in task time across similar workflows
  positive:
  - id: TCT-POS-001
    signal: Task times at or below industry benchmarks
  - id: TCT-POS-002
    signal: Clear learning curve showing expert efficiency gains
  - id: TCT-POS-003
    signal: Optimized paths for frequent users
procedure:
  context:
    cognitive_mode: evaluative
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Task Identification and Prioritization
    description: |
      Identify the most critical and frequent tasks to measure,
      prioritizing by user impact and business importance.
    duration_estimate: 30 min
    questions:
    - What are the most frequent tasks?
    - What tasks are business-critical?
    - What tasks have known efficiency concerns?
    expected_findings:
    - Prioritized list of tasks to measure
    - Success criteria for each task
  - id: '2'
    name: Baseline Measurement
    description: |
      Conduct timed task testing with representative users to
      establish baseline completion times.
    duration_estimate: 90 min
    questions:
    - How long does each task take?
    - What is the variance between users?
    - Where do delays occur?
    expected_findings:
    - Task time measurements
    - Statistical analysis of times
  - id: '3'
    name: Bottleneck Analysis
    description: |
      Identify specific steps or interactions that contribute
      disproportionately to total task time.
    duration_estimate: 30 min
    questions:
    - Which steps take longest?
    - Where do users hesitate?
    - What causes delays?
    expected_findings:
    - Bottleneck identification
    - Root cause analysis
  - id: '4'
    name: Benchmark Comparison
    description: |
      Compare measured times against available benchmarks,
      competitor analysis, or industry standards.
    duration_estimate: 30 min
    questions:
    - How do times compare to benchmarks?
    - Where are the biggest gaps?
    - What competitors do better?
    expected_findings:
    - Benchmark comparison
    - Gap analysis
  - id: '5'
    name: Improvement Opportunity Assessment
    description: |
      Identify and prioritize opportunities to reduce task
      completion time based on findings.
    duration_estimate: 30 min
    questions:
    - What changes would reduce time most?
    - What is the effort vs. impact?
    - What quick wins are available?
    expected_findings:
    - Improvement recommendations
    - Priority ranking
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Task Time Measurements
    - Benchmark Comparison
    - Bottleneck Analysis
    - Recommendations
  confidence_guidance:
    high: Multiple users measured; statistical significance achieved
    medium: Limited sample size; directional findings
    low: Single user or estimated times
offline:
  capability: partial
  cache_manifest:
    knowledge:
    - source_id: nngroup-task-time
      priority: required
profiles:
  membership:
    quick:
      included: false
      reason: Requires user testing and timing measurement
    full:
      included: true
      priority: 1
closeout_checklist:
- id: tct-001
  item: Critical tasks identified and measured
  level: CRITICAL
  verification: manual
  verification_notes: Task times recorded with statistical analysis
  expected: Confirmed by reviewer
- id: tct-002
  item: Bottlenecks identified
  level: BLOCKING
  verification: manual
  verification_notes: Specific steps/interactions causing delays documented
  expected: Confirmed by reviewer
- id: tct-003
  item: Improvement recommendations provided
  level: BLOCKING
  verification: manual
  verification_notes: Prioritized list of efficiency improvements
  expected: Confirmed by reviewer
governance:
  applicable_to:
    archetypes:
    - all
  compliance_frameworks:
  - framework: ISO 9241
    controls:
    - 9241-11
relationships:
  commonly_combined:
  - usability-interaction.efficiency.click-tap-depth
  - usability-interaction.efficiency.frequent-action-optimization
  - usability-interaction.navigation.navigation-structure
