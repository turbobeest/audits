# ============================================================
# AUDIT: First-Use Experience
# ============================================================
# Evaluates the initial user experience when encountering an
# application or feature for the first time.
# ============================================================

audit:
  id: "usability-interaction.learnability.first-use-experience"

  name: "First-Use Experience Audit"

  version: "1.0.0"
  last_updated: "2026-01-19"
  status: "active"

  category: "usability-interaction"
  category_number: 14
  subcategory: "learnability"

  tier: "expert"
  estimated_duration: "3 hours"

  completeness: "complete"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "qualitative"

  default_profiles:
    - "full"
    - "quick"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    This audit examines the first-use experience (FUX) of an application or feature,
    assessing how effectively new users can understand, navigate, and achieve their
    first goals. It evaluates initial screen design, welcome flows, setup wizards,
    and the overall "out of the box" experience that shapes user first impressions.

    Key areas examined include:
    - First screen/view effectiveness
    - Initial value demonstration
    - Friction points in first interactions
    - Time-to-first-value metrics
    - Cognitive load during initial use

  why_it_matters: |
    The first-use experience is critical for user retention and product success.
    Research shows that users form lasting impressions within the first few minutes
    of using an application. A poor first-use experience leads to:
    - High bounce rates and immediate abandonment
    - Negative word-of-mouth and reviews
    - Lost conversion opportunities
    - Increased support burden
    - Reduced likelihood of feature adoption

    Products that nail the first-use experience see significantly higher
    activation rates, better retention, and stronger user advocacy.

  when_to_run:
    - "New product launch"
    - "Major feature release"
    - "Onboarding redesign"
    - "User activation rate drops"
    - "Support ticket analysis reveals first-use confusion"

prerequisites:
  required_artifacts:
    - type: "application"
      description: "Running application accessible for testing"
    - type: "user_flow"
      description: "Documented expected user flows for new users"

  access_requirements:
    - "Access to application as a new user (fresh account/session)"
    - "Ability to reset user state for repeated testing"
    - "Analytics access for funnel and drop-off data"

discovery:
  code_patterns:
    - pattern: "(onboarding|welcome|first.?run|intro|tutorial|getting.?started)"
      type: "regex"
      scope: "source"
      purpose: "Identify onboarding-related components"
    - pattern: "(new.?user|first.?time|is.?new|has.?completed)"
      type: "regex"
      scope: "source"
      purpose: "Find first-use state checks"

  file_patterns:
    - glob: "**/onboarding/**"
      purpose: "Locate onboarding flow components"
    - glob: "**/welcome/**"
      purpose: "Find welcome screen implementations"
    - glob: "**/tutorial/**"
      purpose: "Identify tutorial components"

  interviews:
    - role: "New users (< 7 days)"
      questions:
        - "What was your first impression of the application?"
        - "How long did it take you to accomplish your first goal?"
        - "What confused you during initial use?"
        - "What would have made getting started easier?"
      purpose: "Gather direct feedback on first-use experience"
    - role: "Product managers"
      questions:
        - "What is the intended first-use flow?"
        - "What metrics define successful activation?"
        - "What are known pain points in onboarding?"
      purpose: "Understand design intent and known issues"

knowledge_sources:
  specifications:
    - id: "nielsen-10"
      name: "Nielsen's 10 Usability Heuristics"
      url: "https://www.nngroup.com/articles/ten-usability-heuristics/"
      offline_cache: true
      priority: "required"

  guides:
    - id: "nngroup-onboarding"
      name: "UX Guidelines for Onboarding"
      url: "https://www.nngroup.com/articles/onboarding/"
      offline_cache: true
    - id: "apple-hig-onboarding"
      name: "Apple Human Interface Guidelines - Onboarding"
      url: "https://developer.apple.com/design/human-interface-guidelines/onboarding"
      offline_cache: true
    - id: "material-onboarding"
      name: "Material Design - Onboarding"
      url: "https://m3.material.io/foundations/content-design/onboarding"
      offline_cache: true

  learning_resources:
    - id: "dont-make-me-think"
      title: "Don't Make Me Think"
      type: "book"
      reference: "Steve Krug, ISBN 978-0321965516"

tooling:
  assessment_tools:
    - tool: "Heuristic evaluation checklist"
      purpose: "Systematic assessment of first-use experience against UX principles"
    - tool: "User journey mapping"
      purpose: "Visualize and analyze the first-use flow"
    - tool: "Screen recording analysis"
      purpose: "Observe actual user behavior during first use"

  scripts:
    - id: "fux-checklist-generator"
      language: "python"
      purpose: "Generate first-use experience evaluation checklist"
      source: "inline"
      code: |
        import json

        fux_checklist = {
            "first_screen": [
                "Clear value proposition visible",
                "Primary action obvious",
                "Minimal cognitive load",
                "No overwhelming options"
            ],
            "first_action": [
                "Easy to identify next step",
                "Action is low-commitment",
                "Immediate feedback provided",
                "Success path clear"
            ],
            "first_value": [
                "Value demonstrated quickly",
                "Aha moment achievable",
                "Progress visible",
                "Encouragement provided"
            ]
        }
        print(json.dumps(fux_checklist, indent=2))

signals:
  critical:
    - id: "FUX-CRIT-001"
      signal: "Users cannot complete core action within first session"
      evidence_indicators:
        - "Session abandonment before primary action"
        - "Zero feature engagement after initial view"
        - "Support requests about basic functionality"
      explanation: |
        If users cannot accomplish a core action in their first session,
        they will likely never return. This represents a fundamental
        failure of the first-use experience.
      remediation: "Redesign first-use flow to guide users to core value immediately"

    - id: "FUX-CRIT-002"
      signal: "First screen presents barrier without value demonstration"
      evidence_indicators:
        - "Mandatory registration before any interaction"
        - "Long forms before value preview"
        - "No guest/trial experience available"
      explanation: |
        Requiring significant investment before showing value creates
        high friction and violates the principle of progressive disclosure.
      remediation: "Allow users to experience core value before requiring commitment"

  high:
    - id: "FUX-HIGH-001"
      signal: "Time-to-first-value exceeds 5 minutes for simple products"
      explanation: |
        Users expect quick wins. If a simple product cannot demonstrate
        value within a few minutes, users will seek alternatives.
      remediation: "Streamline path to first successful action"

    - id: "FUX-HIGH-002"
      signal: "First screen overwhelms with options and features"
      explanation: |
        Presenting too many options creates analysis paralysis and
        cognitive overload for new users.
      remediation: "Apply progressive disclosure; show essential actions first"

  medium:
    - id: "FUX-MED-001"
      signal: "Missing or inadequate welcome guidance"
      remediation: "Add contextual help or welcome tour for key features"

    - id: "FUX-MED-002"
      signal: "No clear next steps after initial action"
      remediation: "Provide guidance on logical next actions"

  low:
    - id: "FUX-LOW-001"
      signal: "Generic welcome message without personalization"

  positive:
    - id: "FUX-POS-001"
      signal: "Clear, focused first screen with obvious primary action"
    - id: "FUX-POS-002"
      signal: "Value demonstrated within first 2 minutes"
    - id: "FUX-POS-003"
      signal: "Progressive complexity that grows with user familiarity"

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Baseline Assessment"
      description: |
        Access the application as a completely new user. Document
        everything visible on the first screen without taking any action.
      duration_estimate: "20 min"
      questions:
        - "What is the first thing a user sees?"
        - "Is the value proposition clear?"
        - "What actions are available?"
        - "What is the cognitive load of the first screen?"
      expected_findings:
        - "First screen composition and elements"
        - "Available actions and their visual prominence"

    - id: "2"
      name: "First Action Analysis"
      description: |
        Attempt to perform the primary action as a new user would.
        Document friction points, confusion, and required steps.
      duration_estimate: "30 min"
      questions:
        - "How many steps to first meaningful action?"
        - "Are instructions clear and sufficient?"
        - "What barriers exist before first value?"
      expected_findings:
        - "Step count to first action"
        - "Friction points identified"

    - id: "3"
      name: "Time-to-Value Measurement"
      description: |
        Measure the time required for a new user to achieve
        meaningful value from the product.
      duration_estimate: "30 min"
      questions:
        - "How long until first 'aha moment'?"
        - "What percentage of the product's value is accessible quickly?"
      expected_findings:
        - "Time-to-first-value metrics"
        - "Blocking factors identified"

    - id: "4"
      name: "Error Path Testing"
      description: |
        Deliberately make mistakes a new user might make and
        evaluate error handling and recovery guidance.
      duration_estimate: "20 min"
      questions:
        - "Are errors clearly explained?"
        - "Can users recover easily?"
        - "Is help available at error points?"
      expected_findings:
        - "Error handling quality assessment"
        - "Recovery path effectiveness"

    - id: "5"
      name: "Cognitive Load Assessment"
      description: |
        Evaluate the mental effort required during first use,
        including terminology, interface complexity, and decision points.
      duration_estimate: "30 min"
      questions:
        - "Is jargon avoided or explained?"
        - "How many decisions are required upfront?"
        - "Is the interface overwhelming?"
      expected_findings:
        - "Cognitive load assessment"
        - "Complexity reduction opportunities"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "First-Use Journey Map"
        - "Friction Point Analysis"
        - "Key Findings"
        - "Recommendations"

  confidence_guidance:
    high: "Direct observation with multiple test users confirms finding"
    medium: "Heuristic evaluation identifies issue; user testing recommended"
    low: "Potential issue based on best practice deviation"

offline:
  capability: "partial"

  cache_manifest:
    knowledge:
      - source_id: "nielsen-10"
        priority: "required"
      - source_id: "nngroup-onboarding"
        priority: "recommended"

profiles:
  membership:
    quick:
      included: true
      priority: 2
    full:
      included: true
      priority: 1

closeout_checklist:
  - id: "fux-001"
    item: "First screen documented and evaluated"
    level: "CRITICAL"
    verification: "manual"
    verification_notes: "Reviewer confirms first screen analysis is complete"
    expected: "Confirmed by reviewer"

  - id: "fux-002"
    item: "Time-to-first-value measured"
    level: "BLOCKING"
    verification: "manual"
    verification_notes: "Confirm time measurement from new user perspective"
    expected: "Confirmed by reviewer"

  - id: "fux-003"
    item: "Friction points documented"
    level: "BLOCKING"
    verification: "manual"
    verification_notes: "All blocking friction points identified and prioritized"
    expected: "Confirmed by reviewer"

governance:
  applicable_to:
    archetypes: ["all"]

  compliance_frameworks:
    - framework: "WCAG"
      controls: ["1.3.1", "3.3.2"]

relationships:
  commonly_combined:
    - "usability-interaction.learnability.onboarding-flow"
    - "usability-interaction.learnability.empty-state-design"
    - "usability-interaction.feedback-response.system-status-visibility"
