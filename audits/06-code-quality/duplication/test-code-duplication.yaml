audit:
  id: code-quality.duplication.test-code-duplication
  name: Test Code Duplication Audit
  version: 1.0.0
  last_updated: '2026-01-18'
  status: active
  category: code-quality
  category_number: 6
  subcategory: duplication
  tier: expert
  estimated_duration: 30 minutes
  completeness: complete
  requires_runtime: false
  destructive: false
execution:
  automatable: partial
  severity: medium
  scope: testing
  default_profiles:
  - full
  - quality
  blocks_phase: false
  parallelizable: true
description:
  what: |
    Identifies duplication within test code, including repeated test setup
    and teardown logic, similar test data creation, duplicated assertions,
    and copy-pasted test cases with minor variations. Evaluates use of
    test fixtures, parameterized tests, and shared test utilities.
  why_it_matters: |
    Test code duplication is often tolerated more than production code
    duplication, but it creates significant maintenance burden. Duplicated
    tests are harder to maintain, often become stale, and may mask the
    true intent of the test. Studies show test suites with high duplication
    have 3x higher maintenance cost and are more likely to be abandoned.
  when_to_run:
  - Test suite maintenance
  - Before adding new test patterns
  - Code quality assessments
  - Test refactoring initiatives
prerequisites:
  required_artifacts:
  - type: test_code
    description: Test suite source code
  access_requirements:
  - Read access to test code
discovery:
  code_patterns:
  - pattern: 'def test_.*\(self\):|def test_.*\(\):'
    type: regex
    scope: source
    purpose: Identify test functions
  - pattern: '@pytest\.fixture|@fixture|setUp\(|setUpClass\('
    type: regex
    scope: source
    purpose: Find test fixtures
  - pattern: assert.*==|self\.assert|expect\(
    type: regex
    scope: source
    purpose: Find assertion patterns
  file_patterns:
  - glob: '**/test_*.py'
    purpose: Python test files
  - glob: '**/*_test.py'
    purpose: Python test files (alt)
  - glob: '**/*.test.{js,ts}'
    purpose: JavaScript test files
  - glob: '**/*.spec.{js,ts}'
    purpose: JavaScript spec files
knowledge_sources:
  guides:
  - id: test-dry
    name: DRY Test Patterns
    url: https://www.oreilly.com/library/view/xunit-test-patterns/9780131495050/
    offline_cache: true
  - id: pytest-fixtures
    name: pytest Fixtures Documentation
    url: https://docs.pytest.org/en/stable/fixture.html
    offline_cache: true
  - id: refactoring-fowler
    name: Martin Fowler - Refactoring
    url: https://refactoring.com/
    offline_cache: false
  - id: refactoring-catalog
    name: Refactoring Catalog
    url: https://refactoring.com/catalog/
    offline_cache: false
  - id: clean-code
    name: Robert C. Martin - Clean Code
    url: https://www.oreilly.com/library/view/clean-code-a/9780136083238/
    offline_cache: false
  learning_resources:
  - id: xunit-patterns
    title: 'xUnit Test Patterns: Refactoring Test Code'
    type: book
    reference: 'ISBN: 978-0131495050'
tooling:
  static_analysis:
  - tool: jscpd
    purpose: Test file clone detection
    offline_capable: true
  - tool: pytest
    purpose: Parameterized test support
    offline_capable: true
  scripts:
  - id: test-duplication-scan
    language: bash
    purpose: Detect test code duplication
    source: inline
    code: |
      # Find duplicated test setup patterns
      grep -roh --include="test_*.py" "def setUp\|@pytest.fixture" . 2>/dev/null | sort | uniq -c | sort -rn
      # Find similar test names suggesting copy-paste
      grep -roh --include="test_*.py" "def test_[a-z_]*" . 2>/dev/null | sort | uniq -c | sort -rn | awk '$1 > 1' | head -20
      # Find repeated assertion patterns
      grep -roh --include="test_*.py" "assert.*==" . 2>/dev/null | sort | uniq -c | sort -rn | head -20
signals:
  critical:
  - id: TCD-CRIT-001
    signal: Identical test cases in multiple test files
    evidence_pattern: Exact same test function in different files
    explanation: |
      When the same test exists in multiple files, it creates confusion
      about which is authoritative, wastes CI time, and may lead to
      inconsistent results if the copies diverge.
    remediation: Consolidate into single location or shared test suite
  - id: TCD-CRIT-002
    signal: Security test logic duplicated across test suites
    evidence_pattern: Auth/permission test patterns repeated
    explanation: |
      Security tests must be comprehensive and consistent. When security
      test patterns are copied rather than shared, updates to security
      testing approach may not be applied uniformly.
    remediation: Create shared security test utilities and base classes
  high:
  - id: TCD-HIGH-001
    signal: Test setup duplicated across many test files
    evidence_pattern: Same setUp/fixture code in 5+ files
    explanation: |
      Duplicated test setup code means changes to test infrastructure
      must be made in many places. This leads to inconsistent test
      environments and forgotten updates.
    remediation: Extract to shared fixtures or conftest.py
  - id: TCD-HIGH-002
    signal: Test data creation duplicated
    evidence_pattern: Same factory/builder patterns repeated
    explanation: |
      Repeated test data creation code makes it hard to ensure test
      data is realistic and consistent. Changes to data models require
      updates in many places.
    remediation: Create factory functions or builder patterns
  medium:
  - id: TCD-MED-001
    signal: Similar test cases that could be parameterized
    evidence_pattern: test_foo_1, test_foo_2 patterns
    remediation: Use parameterized tests
  - id: TCD-MED-002
    signal: Assertion helper logic duplicated
    evidence_pattern: Complex assertions repeated
    remediation: Create custom assertion helpers
  low:
  - id: TCD-LOW-001
    signal: Minor duplication in test boilerplate
    evidence_pattern: Standard imports and setup
    remediation: Consider shared test base module
  positive:
  - id: TCD-POS-001
    signal: Effective use of parameterized tests
  - id: TCD-POS-002
    signal: Shared fixtures in conftest.py
  - id: TCD-POS-003
    signal: Factory patterns for test data
procedure:
  context:
    cognitive_mode: analytical
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Inventory Test Files
    description: |
      Map the test file structure and identify test patterns
      used across the suite.
    duration_estimate: 5 min
    commands:
    - purpose: Count test files
      command: |
        find . -name "test_*.py" -o -name "*_test.py" -o -name "*.test.js" -o -name "*.spec.ts" 2>/dev/null | wc -l
    - purpose: List test directories
      command: |
        find . -type d -name "test*" -o -name "__tests__" 2>/dev/null | head -20
    expected_findings:
    - Test file count
    - Test organization
  - id: '2'
    name: Analyze Fixture Usage
    description: |
      Examine how test fixtures and setup methods are used
      and whether they are shared effectively.
    duration_estimate: 8 min
    commands:
    - purpose: Find fixture definitions
      command: |
        grep -rn --include="test_*.py" "@pytest.fixture\|@fixture\|def setUp" . 2>/dev/null | head -20
    - purpose: Check for conftest.py usage
      command: |
        find . -name "conftest.py" 2>/dev/null | head -10
    - purpose: Count setUp methods
      command: |
        grep -rn --include="test_*.py" "def setUp" . 2>/dev/null | wc -l
    expected_findings:
    - Fixture patterns
    - Setup method usage
  - id: '3'
    name: Detect Test Duplication
    description: |
      Run clone detection on test files to identify
      duplicated test logic.
    duration_estimate: 10 min
    commands:
    - purpose: Run clone detection on tests
      command: |
        npx jscpd --min-lines 8 --min-tokens 30 --pattern "**/test_*.py,**/*_test.py" . 2>/dev/null | head -30 || echo "Use jscpd for analysis"
    - purpose: Find similar test function names
      command: |
        grep -roh --include="test_*.py" "def test_[a-z_]*" . 2>/dev/null | sort | uniq -c | sort -rn | awk '$1 > 1' | head -15
    expected_findings:
    - Duplicated tests
    - Similar test patterns
  - id: '4'
    name: Check Parameterized Test Usage
    description: |
      Identify opportunities for parameterized tests where
      similar test cases exist.
    duration_estimate: 7 min
    commands:
    - purpose: Find existing parameterized tests
      command: |
        grep -rn --include="test_*.py" "@pytest.mark.parametrize\|@parametrize\|@parameterized" . 2>/dev/null | wc -l
    - purpose: Find numbered test functions
      command: |
        grep -roh --include="test_*.py" "def test_[a-z_]*_[0-9]" . 2>/dev/null | head -15
    expected_findings:
    - Parameterized test usage
    - Parameterization opportunities
output:
  deliverables:
  - type: finding_list
    format: structured
    content:
    - duplicated_tests
    - fixture_opportunities
    - parameterization_candidates
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Test Duplication Analysis
    - Fixture Recommendations
    - Refactoring Plan
  confidence_guidance:
    high: Comprehensive test suite analysis
    medium: Sampling of test files
    low: Limited test coverage analysis
offline:
  capability: full
profiles:
  membership:
    quick:
      included: false
      reason: Lower priority than production code
    full:
      included: true
      priority: 3
    quality:
      included: true
      priority: 2
closeout_checklist:
- id: tcd-001
  item: Test duplication analyzed
  level: BLOCKING
  verification: |
    find . -name "test_*.py" 2>/dev/null | wc -l | awk '{print ($1 >= 0) ? "PASS" : "FAIL"}'
  expected: PASS
- id: tcd-002
  item: Shared fixtures exist
  level: WARNING
  verification: |
    find . -name "conftest.py" 2>/dev/null | wc -l | awk '{print ($1 > 0) ? "PASS" : "FAIL"}'
  expected: PASS
governance:
  applicable_to:
    archetypes:
    - all
  compliance_frameworks:
  - framework: ISO 25010
    controls:
    - Maintainability
relationships:
  commonly_combined:
  - code-quality.duplication.copy-paste-detection
  - code-quality.testing.test-coverage
  - code-quality.testing.test-maintainability
