# ============================================================
# AUDIT FILE - Integration Test Coverage v1.0
# ============================================================

# ============================================================
# SECTION 1: IDENTITY & METADATA
# ============================================================

audit:
  id: "code-quality.testing.integration-test-coverage"

  name: "Integration Test Coverage"

  version: "1.0.0"
  last_updated: "2026-01-18"
  status: "active"

  category: "code-quality"
  category_number: 6
  subcategory: "testing"

  tier: "expert"
  estimated_duration: "2-3 hours"  # median: 2h

  completeness: "complete"
  requires_runtime: true
  destructive: false

# ============================================================
# SECTION 2: EXECUTION CLASSIFICATION
# ============================================================

execution:
  automatable: "partial"

  severity: "high"

  scope: "testing"

  default_profiles:
    - "full"

  blocks_phase: false
  parallelizable: false

# ============================================================
# SECTION 3: DESCRIPTION & RATIONALE
# ============================================================

description:
  what: |
    Evaluates integration test coverage for component interactions,
    API contracts, database operations, external service integrations,
    and cross-module communication. Assesses both coverage breadth
    and test quality for integration scenarios.

  why_it_matters: |
    Unit tests verify isolated components but miss integration bugs.
    Most production issues stem from component interactions, data flow
    between services, and integration edge cases. Integration tests
    catch what unit tests cannot.

  when_to_run:
    - "Before major releases"
    - "After architectural changes"
    - "When adding new integrations"
    - "Periodic quality assessment"

# ============================================================
# SECTION 4: PREREQUISITES
# ============================================================

prerequisites:
  required_artifacts:
    - type: "source_code"
      description: "Complete source code repository"
    - type: "test_suite"
      description: "Integration test suite"
    - type: "test_infrastructure"
      description: "Test databases, mock servers, or containers"

  access_requirements:
    - "Ability to run integration tests"
    - "Access to test infrastructure"
    - "Database and service credentials for test environment"

# ============================================================
# SECTION 5: DISCOVERY SPECIFICATION
# ============================================================

discovery:
  file_patterns:
    - glob: "**/*.integration.test.*"
      purpose: "Integration test files (explicit naming)"
    - glob: "**/integration/**/*.test.*"
      purpose: "Integration test directory"
    - glob: "**/tests/integration/**"
      purpose: "Integration test folder"
    - glob: "**/*.e2e.test.*"
      purpose: "E2E tests that may include integration"

  code_patterns:
    - pattern: "describe.*integration|it.*integrates|test.*database"
      type: "regex"
      scope: "source"
      purpose: "Integration test patterns in test files"
    - pattern: "beforeAll.*connect|afterAll.*disconnect"
      type: "regex"
      scope: "source"
      purpose: "Database connection setup/teardown"

# ============================================================
# SECTION 6: EXTERNAL KNOWLEDGE SOURCES
# ============================================================

knowledge_sources:
  guides:
    - id: "testing-pyramid"
      name: "The Practical Test Pyramid"
      url: "https://martinfowler.com/articles/practical-test-pyramid.html"
      offline_cache: true

    - id: "xunit-patterns"
      name: "xUnit Test Patterns: Refactoring Test Code"
      url: "https://www.amazon.com/xUnit-Test-Patterns-Refactoring-Code/dp/0131495054"
      offline_cache: false

    - id: "working-effectively-legacy"
      name: "Working Effectively with Legacy Code"
      url: "https://www.oreilly.com/library/view/working-effectively-with/0131177052/"
      offline_cache: false

  learning_resources:
    - id: "integration-testing"
      title: "Growing Object-Oriented Software, Guided by Tests"
      type: "book"
      reference: "Freeman and Pryce, ISBN 978-0321503626"

# ============================================================
# SECTION 7: TOOLING & AUTOMATION
# ============================================================

tooling:
  static_analysis:
    - tool: "jest"
      purpose: "JavaScript integration testing"
      offline_capable: true
    - tool: "pytest"
      purpose: "Python integration testing"
      offline_capable: true
    - tool: "testcontainers"
      purpose: "Docker-based integration testing"
      offline_capable: true
    - tool: "supertest"
      purpose: "HTTP integration testing"
      offline_capable: true

  scripts:
    - id: "integration-test-run"
      language: "bash"
      purpose: "Run integration tests"
      source: "inline"
      code: |
        #!/bin/bash
        npm run test:integration 2>/dev/null || pytest -m integration 2>/dev/null

# ============================================================
# SECTION 8: SIGNALS & FINDINGS TAXONOMY
# ============================================================

signals:
  critical:
    - id: "INTCOV-CRIT-001"
      signal: "No integration tests present"
      evidence_pattern: "Absence of integration test files"
      explanation: |
        Without integration tests, component interactions are
        never verified before production.
      remediation: "Implement integration tests for critical data flows"

  high:
    - id: "INTCOV-HIGH-001"
      signal: "API endpoints lack integration tests"
      evidence_pattern: "Routes without corresponding integration tests"
      explanation: |
        Untested APIs may have contract violations, validation
        issues, or authorization bugs.
      remediation: "Add integration tests for all API endpoints"

    - id: "INTCOV-HIGH-002"
      signal: "Database operations untested"
      evidence_pattern: "Repository/DAO code without integration tests"
      explanation: |
        Database interactions can fail due to schema mismatches,
        query bugs, or transaction issues.
      remediation: "Test database operations against real or containerized database"

  medium:
    - id: "INTCOV-MED-001"
      signal: "External service integrations lack tests"
      remediation: "Add tests with mocked or stubbed external services"

    - id: "INTCOV-MED-002"
      signal: "Integration tests only cover happy paths"
      remediation: "Add error handling and edge case scenarios"

  low:
    - id: "INTCOV-LOW-001"
      signal: "Integration test naming inconsistent"

  positive:
    - id: "INTCOV-POS-001"
      signal: "Comprehensive API integration tests"
    - id: "INTCOV-POS-002"
      signal: "Database tests use isolated test data"

# ============================================================
# SECTION 9: EXECUTION PROCEDURE
# ============================================================

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Inventory integration tests"
      description: |
        Identify all integration test files and categorize
        by type of integration tested.
      duration_estimate: "20 min"
      commands:
        - purpose: "Find integration test files"
          command: "find . -name '*.integration.*' -o -path '*/integration/*' -name '*.test.*' 2>/dev/null | head -30"
      expected_findings:
        - "Integration test file count"
        - "Categories of integrations tested"

    - id: "2"
      name: "Map integrations to tests"
      description: |
        Identify all integration points (APIs, databases,
        services) and verify test coverage.
      duration_estimate: "30 min"
      expected_findings:
        - "List of integration points"
        - "Coverage gaps"

    - id: "3"
      name: "Run integration test suite"
      description: |
        Execute integration tests and analyze results.
      duration_estimate: "30 min"
      commands:
        - purpose: "Run integration tests"
          command: "npm run test:integration 2>&1 | tail -30"
      expected_findings:
        - "Test pass/fail status"
        - "Execution time"

    - id: "4"
      name: "Evaluate test quality"
      description: |
        Review integration tests for meaningful assertions,
        error case coverage, and test isolation.
      duration_estimate: "25 min"
      expected_findings:
        - "Assertion quality"
        - "Error handling coverage"

    - id: "5"
      name: "Check CI integration"
      description: |
        Verify integration tests run in CI and results
        block merges on failure.
      duration_estimate: "15 min"
      commands:
        - purpose: "Check CI for integration tests"
          command: "grep -rn 'integration\\|test:integration' .github/workflows/ 2>/dev/null"
      expected_findings:
        - "CI integration test configuration"
        - "Blocking behavior"

# ============================================================
# SECTION 10: OUTPUT SPECIFICATION
# ============================================================

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Integration Point Inventory"
        - "Coverage Analysis"
        - "Recommendations"

    - type: "metrics"
      format: "table"
      fields:
        - "integration_test_count"
        - "integration_points_tested"
        - "integration_points_total"
        - "coverage_percentage"

  confidence_guidance:
    high: "All integration points mapped and verified"
    medium: "Major integrations assessed"
    low: "Estimated based on test file presence"

# ============================================================
# SECTION 11: OFFLINE SUPPORT
# ============================================================

offline:
  capability: "partial"

  cache_manifest:
    knowledge:
      - source_id: "testing-pyramid"
        priority: "recommended"

# ============================================================
# SECTION 12: PROFILES
# ============================================================

profiles:
  membership:
    quick:
      included: false
      reason: "Integration test analysis requires significant time"
    full:
      included: true
      priority: 1

# ============================================================
# SECTION 13: DETERMINISTIC VERIFICATION
# ============================================================

closeout_checklist:
  - id: "integration-test-001"
    item: "Integration tests exist"
    level: "CRITICAL"
    verification: "find . -name '*integration*' -name '*.test.*' 2>/dev/null | head -1 | grep -q . && echo PASS || echo FAIL"
    expected: "PASS"

  - id: "integration-test-002"
    item: "API endpoints have integration tests"
    level: "BLOCKING"
    verification: "manual"
    verification_notes: "Cross-reference routes with test coverage"
    expected: "Confirmed by reviewer"

  - id: "integration-test-003"
    item: "Integration tests pass"
    level: "BLOCKING"
    verification: "npm run test:integration 2>/dev/null && echo PASS || echo FAIL"
    expected: "PASS"

# ============================================================
# SECTION 14: GOVERNANCE
# ============================================================

governance:
  applicable_to:
    archetypes: ["all"]

  compliance_frameworks:
    - framework: "ISO 25010"
      controls: ["Reliability", "Testability"]

# ============================================================
# SECTION 15: RELATIONSHIPS
# ============================================================

relationships:
  commonly_combined:
    - "code-quality.testing.unit-test-coverage"
    - "code-quality.testing.e2e-test-coverage"
    - "code-quality.testing.contract-testing"
