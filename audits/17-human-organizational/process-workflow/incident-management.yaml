audit:
  id: human-organizational.process-workflow.incident-management
  name: Incident Management Process Assessment
  version: 1.0.0
  last_updated: '2026-01-19'
  status: active
  category: human-organizational
  category_number: 17
  subcategory: process-workflow
  tier: expert
  estimated_duration: 3-4 hours  # median: 3h
  completeness: complete
  requires_runtime: false
  destructive: false
execution:
  automatable: partial
  severity: critical
  scope: process
  default_profiles:
  - full
  - production
  parallelizable: true
description:
  what: |
    Assesses the complete incident management lifecycle including detection
    and alerting, triage and escalation, response coordination, stakeholder
    communication, resolution, and post-incident review. Evaluates both the
    documented process and actual incident response capability through
    review of recent incidents and interviews with responders.
  why_it_matters: |
    Effective incident management minimizes customer impact, reduces
    responder stress, and accelerates organizational learning. Poor
    incident management extends outages, burns out on-call engineers,
    and fails to prevent recurrence. MTTR (mean time to recovery) is
    a key DORA metric that correlates with overall software delivery
    performance.
  when_to_run:
  - Quarterly SRE assessments
  - After major incidents
  - When MTTR trends upward
  - As part of on-call health reviews
prerequisites:
  required_artifacts:
  - type: documentation
    description: Incident management runbooks and procedures
  - type: records
    description: Recent incident reports and postmortems
  - type: configuration
    description: Alerting and on-call configuration
  access_requirements:
  - Access to incident management system
  - Access to recent incident reports and postmortems
  - Availability of on-call engineers and incident commanders
discovery:
  interviews:
  - role: On-Call Engineers
    questions:
    - Walk me through your most recent incident response
    - How do you get paged? Is signal-to-noise good?
    - Do you feel prepared to handle incidents?
    - What tools do you use during incident response?
    purpose: Understand responder experience
  - role: Incident Commanders / SRE Leads
    questions:
    - How do you decide when to escalate?
    - What's your communication strategy during incidents?
    - How do you coordinate across multiple responders?
    purpose: Understand coordination and leadership
  - role: Engineering Manager
    questions:
    - How do you measure incident management effectiveness?
    - What happens after incidents are resolved?
    - How do you prevent responder burnout?
    purpose: Understand organizational support and metrics
  documents_to_review:
  - type: Incident response runbooks
    purpose: Assess documented procedures
  - type: Recent incident reports/postmortems
    purpose: Evaluate actual response and learning
  - type: On-call schedules and policies
    purpose: Understand coverage and rotation
  - type: Escalation matrices
    purpose: Assess escalation clarity
  metrics_queries:
  - system: Incident management system
    query: MTTR (Mean Time To Recovery) trend
    purpose: Measure resolution efficiency
    threshold: < 1 hour for elite, < 1 day for high performers
  - system: Alerting system
    query: Alert volume and noise ratio
    purpose: Assess alert quality
    threshold: < 2 pages per on-call shift as sustainable
  - system: Incident management system
    query: Incident frequency by severity
    purpose: Understand incident load
  file_patterns:
  - glob: '**/*.md'
    purpose: Documentation files
  - glob: '**/CODEOWNERS'
    purpose: Code ownership files
  - glob: '**/*.org'
    purpose: Org structure files
  - glob: '**/team*.yaml'
    purpose: Team configuration
  code_patterns:
  - pattern: '@team|@owner|maintainer'
    type: regex
    scope: all
    purpose: Ownership references
knowledge_sources:
  guides:
  - id: google-sre
    name: Google SRE Book - Incident Management
    url: https://sre.google/sre-book/managing-incidents/
    offline_cache: true
  - id: pagerduty-response
    name: PagerDuty Incident Response Guide
    url: https://response.pagerduty.com/
    offline_cache: true
  papers:
  - id: ntsb-model
    title: Learning from Incidents
    url: https://www.learningfromincidents.io/
  learning_resources:
  - id: incident-command
    title: Incident Command for IT
    type: course
    reference: PagerDuty University
tooling:
  infrastructure_tools:
  - tool: Incident management platform
    purpose: Review incident history and timelines
    command: Platform-specific (PagerDuty, OpsGenie, etc.)
  assessment_tools:
  - tool: Incident timeline reconstruction
    purpose: Analyze response patterns from recent incidents
  - tool: On-call survey
    purpose: Measure responder satisfaction and burnout risk
signals:
  critical:
  - id: INCMGT-CRIT-001
    signal: No documented incident response process
    evidence_indicators:
    - Responders unsure what to do when paged
    - Ad-hoc coordination during incidents
    - No clear escalation path
    explanation: |
      Without a documented process, every incident is chaos.
      Responders waste time figuring out what to do instead of
      resolving the problem. This extends outages and increases stress.
    remediation: Document and drill a clear incident response process
  - id: INCMGT-CRIT-002
    signal: No post-incident review process
    evidence_indicators:
    - No postmortems conducted
    - Same incidents recur without action
    - No learning captured from outages
    explanation: |
      Without learning from incidents, organizations are doomed to
      repeat them. Post-incident review is the primary mechanism for
      converting outages into resilience improvements.
    remediation: Institute blameless postmortem practice for all significant incidents
  high:
  - id: INCMGT-HIGH-001
    signal: MTTR consistently exceeds 4 hours
    explanation: Extended outages indicate response process or tooling problems
    remediation: Analyze resolution timeline bottlenecks; improve detection, escalation, or remediation
  - id: INCMGT-HIGH-002
    signal: Alert fatigue with high noise ratio
    explanation: Noisy alerts lead to ignored pages and delayed response
    remediation: Tune alerting thresholds; consolidate related alerts; eliminate flapping
  - id: INCMGT-HIGH-003
    signal: Single point of failure for incident response
    explanation: Dependency on specific individuals creates fragility and burnout
    remediation: Cross-train responders; document tribal knowledge; rotate incident commander role
  medium:
  - id: INCMGT-MED-001
    signal: Runbooks are outdated or incomplete
    remediation: Schedule regular runbook review; test runbooks during game days
  - id: INCMGT-MED-002
    signal: Stakeholder communication is ad-hoc during incidents
    remediation: Create status page and communication templates
  low:
  - id: INCMGT-LOW-001
    signal: Incident severity levels inconsistently applied
  positive:
  - id: INCMGT-POS-001
    signal: Blameless postmortems conducted for all significant incidents
  - id: INCMGT-POS-002
    signal: MTTR under 1 hour for most incidents
  - id: INCMGT-POS-003
    signal: Sustainable on-call load with low responder burnout
procedure:
  context:
    cognitive_mode: critical
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Documentation Review
    description: |
      Review incident management documentation including runbooks,
      escalation matrices, and communication templates.
    duration_estimate: 30 min
    questions:
    - Is the incident response process documented?
    - Are runbooks current and actionable?
    - Is escalation clear?
    expected_findings:
    - Documentation completeness
    - Process clarity assessment
  - id: '2'
    name: Incident History Analysis
    description: |
      Review recent incident reports and postmortems to understand
      actual response patterns and outcomes.
    duration_estimate: 60 min
    questions:
    - What does MTTR look like?
    - Are incidents recurring?
    - What do postmortems reveal about process gaps?
    expected_findings:
    - MTTR trends
    - Common incident patterns
    - Quality of postmortems
  - id: '3'
    name: Responder Interviews
    description: |
      Interview on-call engineers and incident commanders to
      understand the responder experience.
    duration_estimate: 60 min
    questions:
    - What's working well in incident response?
    - What causes the most frustration?
    - Do you feel supported during incidents?
    expected_findings:
    - Responder pain points
    - Burnout indicators
    - Process improvement suggestions
  - id: '4'
    name: Alerting Assessment
    description: |
      Evaluate alerting configuration and noise levels.
    duration_estimate: 30 min
    questions:
    - What's the alert volume?
    - What percentage are actionable?
    - Are alerts well-documented?
    expected_findings:
    - Alert quality assessment
    - Noise ratio
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Incident Metrics Analysis
    - Process Assessment
    - Responder Experience
    - Recommendations
  confidence_guidance:
    high: Incident records analyzed; consistent interview themes; documentation reviewed
    medium: Some records available; interview input gathered; documentation partial
    low: Limited incident history; few interviews; documentation sparse
offline:
  capability: partial
  cache_manifest:
    knowledge:
    - source_id: google-sre
      priority: required
    - source_id: pagerduty-response
      priority: recommended
profiles:
  membership:
    quick:
      included: false
      reason: Requires incident analysis and interviews
    full:
      included: true
      priority: 1
    production:
      included: true
      priority: 1
closeout_checklist:
- id: incmgt-001
  item: Incident response documentation reviewed
  level: BLOCKING
  verification: manual
  verification_notes: Confirm runbooks and procedures were examined
  expected: Confirmed by reviewer
- id: incmgt-002
  item: Recent incident history analyzed
  level: CRITICAL
  verification: manual
  verification_notes: Verify at least 5 recent incidents were reviewed
  expected: Confirmed by reviewer
- id: incmgt-003
  item: MTTR and incident metrics collected
  level: CRITICAL
  verification: manual
  verification_notes: Confirm MTTR trend data was gathered
  expected: Confirmed by reviewer
- id: incmgt-004
  item: Responder interviews completed
  level: BLOCKING
  verification: manual
  verification_notes: Confirm at least 3 responders were interviewed
  expected: Confirmed by reviewer
governance:
  applicable_to:
    archetypes:
    - all
  compliance_frameworks:
  - framework: SOC 2
    controls:
    - CC7.4
    - CC7.5
  - framework: ISO 27001
    controls:
    - A.16.1
relationships:
  commonly_combined:
  - human-organizational.process-workflow.deployment-process
  - human-organizational.culture-practices.failure-postmortem
  - human-organizational.metrics-improvement.dora-metrics
