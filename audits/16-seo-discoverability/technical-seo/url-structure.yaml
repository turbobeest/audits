# ============================================================
# AUDIT: URL Structure Optimization
# ============================================================
# Evaluates URL design for SEO best practices, readability,
# and technical correctness.
# ============================================================

audit:
  id: "seo-discoverability.technical-seo.url-structure"

  name: "URL Structure Optimization Audit"

  version: "1.0.0"
  last_updated: "2026-01-19"
  status: "active"

  category: "seo-discoverability"
  category_number: 16
  subcategory: "technical-seo"

  tier: "expert"
  estimated_duration: "1-2 hours"  # median: 1h

  completeness: "complete"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "medium"
  scope: "codebase"

  default_profiles:
    - "full"
    - "production"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    This audit examines URL structure and design patterns across the
    website for SEO optimization. It evaluates URL length, readability,
    keyword inclusion, folder hierarchy, use of hyphens vs underscores,
    URL parameters, trailing slashes, case sensitivity, and consistency
    of URL patterns across the site.

  why_it_matters: |
    Well-structured URLs improve user experience, click-through rates
    in search results, and help search engines understand page content
    and site hierarchy. Poor URL structure can create duplicate content,
    confuse users, and miss keyword opportunities. Clean URLs are also
    easier to share and link to.

  when_to_run:
    - "When planning site architecture"
    - "Before launching a new website"
    - "When restructuring URL patterns"
    - "During technical SEO audits"
    - "After CMS migrations"

prerequisites:
  required_artifacts:
    - type: "website"
      description: "Live website with established URL structure"
    - type: "crawl_data"
      description: "Complete site crawl with URL inventory"

  access_requirements:
    - "Ability to crawl the website"
    - "Access to URL patterns/routing configuration"

discovery:
  code_patterns:
    - pattern: "router|routes|path"
      type: "keyword"
      scope: "config"
      purpose: "Find routing configuration files"
    - pattern: "slug|permalink|url"
      type: "keyword"
      scope: "config"
      purpose: "Identify URL generation patterns"

  file_patterns:
    - glob: "**/routes.{js,ts,php,rb}"
      purpose: "Find routing configuration"
    - glob: "**/*.htaccess"
      purpose: "Apache URL rewrite rules"
    - glob: "**/nginx.conf"
      purpose: "Nginx URL configuration"

knowledge_sources:
  guides:
    - id: "google-url-structure"
      name: "Google: Keep a Simple URL Structure"
      url: "https://developers.google.com/search/docs/crawling-indexing/url-structure"
      offline_cache: true
    - id: "moz-url-seo"
      name: "Moz: URL Structure SEO Best Practices"
      url: "https://moz.com/learn/seo/url"
      offline_cache: true
    - id: "ahrefs-url-seo"
      name: "Ahrefs: URL SEO - How to Create SEO-Friendly URLs"
      url: "https://ahrefs.com/blog/seo-friendly-urls/"
      offline_cache: true

tooling:
  static_analysis:
    - tool: "Screaming Frog SEO Spider"
      purpose: "Bulk URL analysis and pattern detection"
      offline_capable: true
    - tool: "Sitebulb"
      purpose: "URL structure visualization"
      offline_capable: true

  scripts:
    - id: "url-structure-analyzer"
      language: "bash"
      purpose: "Analyze URL patterns from crawl"
      source: "inline"
      code: |
        #!/bin/bash
        # Analyze URL structure from a list of URLs

        echo "=== URL Structure Analysis ==="

        # Check for common issues in URL list
        while read URL; do
          # Check length
          LEN=${#URL}
          if [ $LEN -gt 100 ]; then
            echo "LONG URL ($LEN chars): $URL"
          fi

          # Check for underscores
          if [[ $URL == *"_"* ]]; then
            echo "UNDERSCORE: $URL"
          fi

          # Check for uppercase
          if [[ $URL =~ [A-Z] ]]; then
            echo "UPPERCASE: $URL"
          fi

          # Check for multiple parameters
          PARAMS=$(echo $URL | grep -o "?" | wc -l)
          if [ $PARAMS -gt 0 ]; then
            echo "PARAMETERS: $URL"
          fi

        done < urls.txt

signals:
  critical:
    - id: "URL-CRIT-001"
      signal: "URLs contain sensitive information or session IDs"
      evidence_pattern: "session|token|sid=|uid="
      explanation: |
        Exposing session IDs or tokens in URLs is a security risk and
        causes massive duplicate content as each session creates unique URLs.
      remediation: "Remove session IDs from URLs, use cookies instead"

  high:
    - id: "URL-HIGH-001"
      signal: "Excessive URL parameters creating duplicate content"
      explanation: |
        Unmanaged URL parameters (sorting, filtering, tracking) can
        exponentially multiply the number of crawlable URLs.
      remediation: "Implement canonical tags or parameter handling in GSC"

    - id: "URL-HIGH-002"
      signal: "Mixed case URLs creating duplicates"
      explanation: |
        URLs are case-sensitive on most servers, so /Page and /page
        are different URLs with potentially duplicate content.
      remediation: "Enforce lowercase URLs via redirects"

    - id: "URL-HIGH-003"
      signal: "Inconsistent trailing slash handling"
      explanation: |
        /page and /page/ being accessible creates duplicate content
        and dilutes link equity.
      remediation: "Choose one format and redirect the other"

  medium:
    - id: "URL-MED-001"
      signal: "URLs using underscores instead of hyphens"
      remediation: "Use hyphens to separate words (Google recommends)"

    - id: "URL-MED-002"
      signal: "Very long URLs (>100 characters)"
      remediation: "Shorten URLs by removing unnecessary words/folders"

    - id: "URL-MED-003"
      signal: "Deep folder hierarchy (>4 levels)"
      remediation: "Flatten URL structure for important pages"

    - id: "URL-MED-004"
      signal: "Non-descriptive URLs (IDs only, no keywords)"
      remediation: "Include relevant keywords in URL slugs"

  low:
    - id: "URL-LOW-001"
      signal: "URLs contain special characters or non-ASCII"

    - id: "URL-LOW-002"
      signal: "File extensions in URLs (.html, .php)"

  positive:
    - id: "URL-POS-001"
      signal: "Clean, readable URL structure with descriptive slugs"
    - id: "URL-POS-002"
      signal: "Consistent URL patterns across site sections"

procedure:
  context:
    cognitive_mode: "critical"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Extract Complete URL Inventory"
      description: |
        Crawl the site to build a complete inventory of all URLs
        for pattern analysis.
      duration_estimate: "20 min"
      commands:
        - purpose: "Export URL list from crawl"
          command: "Extract all URLs from Screaming Frog crawl"
      expected_findings:
        - "Total URL count"
        - "URL depth distribution"
        - "Parameter usage patterns"

    - id: "2"
      name: "Analyze URL Length and Readability"
      description: |
        Review URL lengths and assess human readability of URL slugs.
      duration_estimate: "15 min"
      expected_findings:
        - "Average URL length"
        - "URLs over 100 characters"
        - "Readability assessment"

    - id: "3"
      name: "Check Character Usage"
      description: |
        Verify URLs use recommended characters (lowercase, hyphens)
        and avoid problematic characters.
      duration_estimate: "15 min"
      expected_findings:
        - "Underscore usage"
        - "Uppercase characters"
        - "Special characters"

    - id: "4"
      name: "Audit URL Hierarchy"
      description: |
        Analyze folder depth and hierarchical structure for
        logical organization and SEO impact.
      duration_estimate: "20 min"
      expected_findings:
        - "Folder depth distribution"
        - "Hierarchy patterns"
        - "Important pages buried deep"

    - id: "5"
      name: "Evaluate Parameter Handling"
      description: |
        Identify URL parameters and assess their impact on
        crawl budget and duplicate content.
      duration_estimate: "20 min"
      expected_findings:
        - "Parameter types (tracking, filtering, sorting)"
        - "Canonical implementation for parameters"
        - "GSC parameter handling settings"

    - id: "6"
      name: "Test Trailing Slash and Case Handling"
      description: |
        Verify consistent behavior for trailing slashes and
        URL case sensitivity.
      duration_estimate: "15 min"
      commands:
        - purpose: "Test trailing slash handling"
          command: "curl -sI https://example.com/page vs https://example.com/page/"
      expected_findings:
        - "Trailing slash behavior"
        - "Case sensitivity behavior"
        - "Redirect implementation"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "summary"
      format: "prose"
      sections:
        - "URL Structure Overview"
        - "Pattern Analysis"
        - "Issues Found"
        - "Recommendations"

  confidence_guidance:
    high: "Issues verified with actual URL testing"
    medium: "Issues identified via pattern analysis"
    low: "Potential issues based on best practice comparison"

offline:
  capability: "partial"

  cache_manifest:
    knowledge:
      - source_id: "google-url-structure"
        priority: "required"
      - source_id: "moz-url-seo"
        priority: "recommended"

profiles:
  membership:
    quick:
      included: false
      reason: "Requires comprehensive URL analysis"
    full:
      included: true
      priority: 2
    production:
      included: true
      priority: 2

closeout_checklist:
  - id: "url-structure-001"
    item: "No session IDs or sensitive data in URLs"
    level: "CRITICAL"
    verification: "manual"
    verification_notes: "Review URL patterns for session/token parameters"
    expected: "Confirmed by reviewer"

  - id: "url-structure-002"
    item: "Consistent trailing slash handling"
    level: "BLOCKING"
    verification: "manual"
    verification_notes: "Test /page vs /page/ behavior"
    expected: "Confirmed by reviewer"

  - id: "url-structure-003"
    item: "URLs use hyphens, not underscores"
    level: "WARNING"
    verification: "manual"
    verification_notes: "Search URL inventory for underscores"
    expected: "Confirmed by reviewer"

  - id: "url-structure-004"
    item: "All URLs are lowercase"
    level: "WARNING"
    verification: "manual"
    verification_notes: "Check for uppercase characters in URLs"
    expected: "Confirmed by reviewer"

governance:
  applicable_to:
    archetypes: ["web-application", "marketing-site", "ecommerce", "content-site"]

  compliance_frameworks:
    - framework: "SEO Best Practices"
      controls: ["URL Optimization", "Technical SEO"]

relationships:
  commonly_combined:
    - "seo-discoverability.technical-seo.canonical-url"
    - "seo-discoverability.technical-seo.redirect-chain"
    - "seo-discoverability.on-page-seo.keyword-optimization"
