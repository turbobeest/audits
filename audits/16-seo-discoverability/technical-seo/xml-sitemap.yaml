audit:
  id: seo-discoverability.technical-seo.xml-sitemap
  name: XML Sitemap Configuration Audit
  version: 1.0.0
  last_updated: '2026-01-19'
  status: active
  category: seo-discoverability
  category_number: 16
  subcategory: technical-seo
  tier: expert
  estimated_duration: 30-60 minutes
  completeness: complete
  requires_runtime: true
  destructive: false
execution:
  automatable: 'yes'
  severity: high
  scope: config
  default_profiles:
  - full
  - quick
  - production
  blocks_phase: false
  parallelizable: true
description:
  what: |
    This audit examines XML sitemap implementation to ensure it properly
    communicates site structure to search engines. It validates XML format
    according to the sitemaps.org protocol, checks URL validity and status,
    verifies lastmod accuracy, assesses sitemap completeness against actual
    site content, and reviews sitemap index structure for large sites.
  why_it_matters: |
    XML sitemaps help search engines discover and understand your site
    structure, particularly for new pages, deep pages, or pages with
    limited internal linking. Properly configured sitemaps can accelerate
    indexing, communicate page importance via priority and changefreq,
    and provide accurate lastmod dates to trigger re-crawling.
  when_to_run:
  - After launching new site sections
  - When indexation is delayed
  - After CMS or sitemap generator changes
  - During technical SEO audits
  - Monthly validation checks
prerequisites:
  required_artifacts:
  - type: xml_sitemap
    description: XML sitemap file(s) accessible via HTTP
  - type: robots_txt
    description: Robots.txt with sitemap declaration
  access_requirements:
  - HTTP access to sitemap URLs
  - Google Search Console for submission status
discovery:
  file_patterns:
  - glob: '**/sitemap*.xml'
    purpose: Locate sitemap files
  - glob: '**/sitemap-index.xml'
    purpose: Find sitemap index files
knowledge_sources:
  specifications:
  - id: sitemaps-protocol
    name: Sitemaps XML Format
    url: https://www.sitemaps.org/protocol.html
    offline_cache: true
    priority: required
  guides:
  - id: google-sitemaps
    name: 'Google: Build and Submit a Sitemap'
    url: https://developers.google.com/search/docs/crawling-indexing/sitemaps/build-sitemap
    offline_cache: true
  - id: google-sitemap-best-practices
    name: 'Google: Sitemap Best Practices'
    url: https://developers.google.com/search/docs/crawling-indexing/sitemaps/best-practices
    offline_cache: true
tooling:
  static_analysis:
  - tool: Screaming Frog SEO Spider
    purpose: Sitemap validation and cross-referencing
    offline_capable: true
  - tool: XML Sitemap Validator
    purpose: Online XML validation
    offline_capable: false
  infrastructure_tools:
  - tool: Google Search Console
    purpose: Sitemap submission and status monitoring
    command: Sitemaps report in GSC
  - tool: curl
    purpose: Fetch and inspect sitemap
    command: curl -s https://example.com/sitemap.xml | head -50
  scripts:
  - id: sitemap-validator
    language: bash
    purpose: Basic sitemap validation
    source: inline
    code: |
      #!/bin/bash
      SITEMAP_URL=$1

      echo "=== Fetching sitemap from $SITEMAP_URL ==="

      # Check HTTP status
      STATUS=$(curl -s -o /dev/null -w "%{http_code}" "$SITEMAP_URL")
      echo "HTTP Status: $STATUS"

      if [ "$STATUS" == "200" ]; then
        # Get content type
        CONTENT_TYPE=$(curl -sI "$SITEMAP_URL" | grep -i "content-type")
        echo "Content-Type: $CONTENT_TYPE"

        # Count URLs
        URL_COUNT=$(curl -s "$SITEMAP_URL" | grep -c "<loc>")
        echo "URL Count: $URL_COUNT"

        # Check for lastmod
        LASTMOD_COUNT=$(curl -s "$SITEMAP_URL" | grep -c "<lastmod>")
        echo "URLs with lastmod: $LASTMOD_COUNT"

        # Check file size
        SIZE=$(curl -sI "$SITEMAP_URL" | grep -i "content-length" | awk '{print $2}')
        echo "File size: $SIZE bytes"
      fi
signals:
  critical:
  - id: SITEMAP-CRIT-001
    signal: Sitemap returns 4xx/5xx error
    evidence_indicators:
    - HTTP 404/500 status code
    explanation: |
      An inaccessible sitemap prevents search engines from using it
      to discover pages, negating its benefits entirely.
    remediation: Fix sitemap generation or hosting issues
  - id: SITEMAP-CRIT-002
    signal: Sitemap contains invalid XML
    evidence_indicators:
    - XML parsing errors
    - Malformed tags
    explanation: |
      Invalid XML prevents search engines from parsing the sitemap,
      making it useless for page discovery.
    remediation: Fix XML syntax errors and validate format
  high:
  - id: SITEMAP-HIGH-001
    signal: Sitemap contains URLs returning 4xx/5xx
    explanation: |
      Including error pages in the sitemap wastes crawl budget and
      may signal quality issues to search engines.
    remediation: Remove non-200 URLs from sitemap
  - id: SITEMAP-HIGH-002
    signal: Sitemap exceeds 50MB uncompressed or 50,000 URLs
    explanation: |
      Search engines have limits on sitemap size. Oversized sitemaps
      may be truncated or ignored.
    remediation: Split into multiple sitemaps with a sitemap index
  - id: SITEMAP-HIGH-003
    signal: Important pages missing from sitemap
    explanation: |
      Pages not in the sitemap may be discovered more slowly or
      miss priority/lastmod signals.
    remediation: Ensure sitemap includes all indexable pages
  medium:
  - id: SITEMAP-MED-001
    signal: lastmod dates not reflecting actual content changes
    remediation: Implement accurate lastmod dates based on content modification
  - id: SITEMAP-MED-002
    signal: Sitemap not referenced in robots.txt
    remediation: 'Add Sitemap: directive to robots.txt'
  - id: SITEMAP-MED-003
    signal: Sitemap contains noindex URLs
    remediation: Remove noindex pages from sitemap
  low:
  - id: SITEMAP-LOW-001
    signal: changefreq and priority not used consistently
  - id: SITEMAP-LOW-002
    signal: Sitemap not gzipped (optional optimization)
  positive:
  - id: SITEMAP-POS-001
    signal: All sitemap URLs return 200 OK
  - id: SITEMAP-POS-002
    signal: Sitemap index properly organizes multiple sitemaps
procedure:
  context:
    cognitive_mode: critical
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Locate and Fetch Sitemaps
    description: |
      Find all sitemap files via robots.txt declaration, common
      locations, and GSC sitemap report.
    duration_estimate: 5 min
    commands:
    - purpose: Check robots.txt for sitemap declaration
      command: curl -s https://example.com/robots.txt | grep -i Sitemap
    - purpose: Try common sitemap locations
      command: curl -sI https://example.com/sitemap.xml
    expected_findings:
    - Sitemap URL(s)
    - Sitemap index presence
  - id: '2'
    name: Validate XML Format
    description: |
      Verify sitemap XML is well-formed and complies with the
      sitemaps.org protocol specification.
    duration_estimate: 10 min
    commands:
    - purpose: Validate XML syntax
      command: curl -s https://example.com/sitemap.xml | xmllint --noout -
    expected_findings:
    - XML validity status
    - Schema compliance
    - Encoding issues
  - id: '3'
    name: Audit URL Status
    description: |
      Check HTTP status codes of URLs in the sitemap to ensure
      all listed pages are accessible.
    duration_estimate: 15 min
    expected_findings:
    - URLs returning 200
    - URLs returning 3xx (redirects)
    - URLs returning 4xx/5xx
  - id: '4'
    name: Compare Sitemap to Crawl
    description: |
      Cross-reference sitemap URLs with a site crawl to identify
      pages missing from or incorrectly included in the sitemap.
    duration_estimate: 20 min
    expected_findings:
    - Pages in sitemap but not crawled
    - Pages crawled but not in sitemap
    - Coverage percentage
  - id: '5'
    name: Review GSC Sitemap Status
    description: |
      Check Google Search Console for sitemap submission status,
      discovered URLs, and any reported errors.
    duration_estimate: 10 min
    expected_findings:
    - Submission status
    - URLs discovered vs indexed
    - GSC-reported errors
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: summary
    format: prose
    sections:
    - Sitemap Inventory
    - Validation Results
    - Coverage Analysis
    - Recommendations
  confidence_guidance:
    high: Issues verified via GSC sitemap report and URL testing
    medium: Issues identified via XML validation
    low: Potential issues based on best practice comparison
offline:
  capability: partial
  cache_manifest:
    knowledge:
    - source_id: sitemaps-protocol
      priority: required
    - source_id: google-sitemaps
      priority: required
profiles:
  membership:
    quick:
      included: true
      priority: 2
    full:
      included: true
      priority: 1
    production:
      included: true
      priority: 1
closeout_checklist:
- id: sitemap-001
  item: Sitemap returns HTTP 200
  level: CRITICAL
  verification: curl -s -o /dev/null -w '%{http_code}' https://example.com/sitemap.xml
  expected: '200'
- id: sitemap-002
  item: Sitemap XML is valid and well-formed
  level: CRITICAL
  verification: curl -s https://example.com/sitemap.xml | xmllint --noout -
  expected: No errors
- id: sitemap-003
  item: Sitemap under 50,000 URLs per file
  level: BLOCKING
  verification: manual
  verification_notes: Count URLs in sitemap, use index for larger sites
  expected: Confirmed by reviewer
- id: sitemap-004
  item: Sitemap declared in robots.txt
  level: WARNING
  verification: curl -s https://example.com/robots.txt | grep -i Sitemap
  expected: Sitemap directive found
governance:
  applicable_to:
    archetypes:
    - web-application
    - marketing-site
    - ecommerce
    - content-site
  compliance_frameworks:
  - framework: SEO Best Practices
    controls:
    - Technical SEO
    - Crawl Optimization
relationships:
  commonly_combined:
  - seo-discoverability.technical-seo.robots-txt
  - seo-discoverability.technical-seo.crawlability
  - seo-discoverability.technical-seo.indexability
