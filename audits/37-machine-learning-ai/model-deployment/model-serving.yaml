# ============================================================
# AUDIT: Model Serving
# Category: 37 - Machine Learning & AI
# Subcategory: model-deployment
# ============================================================

audit:
  id: "machine-learning-ai.model-deployment.model-serving"
  name: "Model Serving Audit"
  version: "1.0.0"
  last_updated: "2025-01-22"
  status: "active"

  category: "machine-learning-ai"
  category_number: 37
  subcategory: "model-deployment"

  tier: "expert"
  estimated_duration: "5-7 hours"  # median: 6h

  completeness: "requires_discovery"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "ml-systems"

  default_profiles:
    - "full"
    - "quick"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Evaluates model serving infrastructure including inference APIs, model loading,
    request handling, latency optimization, scaling configuration, and health checks.
    Examines whether models are served reliably, efficiently, and securely in production.

  why_it_matters: |
    Model serving is the interface between ML models and production systems. Poor serving
    infrastructure causes latency issues, outages, and security vulnerabilities that
    directly impact users. Robust serving ensures models deliver value reliably.

  when_to_run:
    - "Before production deployment"
    - "After infrastructure changes"
    - "When latency issues arise"
    - "During capacity planning"

prerequisites:
  required_artifacts:
    - type: "serving_infrastructure"
      description: "Access to model serving systems"
    - type: "api_documentation"
      description: "Model API specifications"
    - type: "performance_metrics"
      description: "Serving performance data"

  access_requirements:
    - "Access to serving infrastructure"
    - "Access to model APIs"
    - "Access to performance dashboards"
    - "Access to infrastructure configurations"

discovery:
  file_patterns:
    - glob: "**/serving/**/*.py"
      purpose: "Find serving code"
    - glob: "**/inference/**"
      purpose: "Find inference code"
    - glob: "**/api/**/*.py"
      purpose: "Find API implementations"
    - glob: "**/deployment/**/*.yaml"
      purpose: "Find deployment configs"

knowledge_sources:
  guides:
    - id: "tf-serving-docs"
      name: "TensorFlow Serving Documentation"
      url: "https://www.tensorflow.org/tfx/guide/serving"
    - id: "torchserve-docs"
      name: "TorchServe Documentation"
      url: "https://pytorch.org/serve/"
    - id: "triton-docs"
      name: "NVIDIA Triton Documentation"
      url: "https://docs.nvidia.com/deeplearning/triton-inference-server/"

  standards:
    - id: "ml-serving-best-practices"
      name: "ML Serving Best Practices"
      relevance: "Production model serving"

tooling:
  analysis_tools:
    - tool: "tf-serving"
      purpose: "TensorFlow model serving"
    - tool: "torchserve"
      purpose: "PyTorch model serving"
    - tool: "triton"
      purpose: "High-performance inference server"
    - tool: "seldon"
      purpose: "ML deployment platform"
    - tool: "bentoml"
      purpose: "ML serving framework"

signals:
  critical:
    - id: "MS-CRIT-001"
      signal: "Model serving outages affecting production"
      evidence_indicators:
        - "Frequent service unavailability"
        - "No failover mechanisms"
        - "Single points of failure"
      explanation: |
        Serving outages directly impact users and business operations, potentially causing
        significant revenue loss and user experience degradation.
      remediation: "Implement redundancy, failover, and robust health checks"

    - id: "MS-CRIT-002"
      signal: "Security vulnerabilities in serving endpoint"
      evidence_indicators:
        - "No authentication on model API"
        - "Unvalidated inputs to model"
        - "Model extraction attacks possible"
      explanation: |
        Insecure serving exposes models to attacks, data theft, and unauthorized use,
        potentially causing significant security and business risk.
      remediation: "Implement authentication, input validation, and rate limiting"

  high:
    - id: "MS-HIGH-001"
      signal: "Latency exceeds requirements"
      remediation: "Optimize inference, add caching, or scale infrastructure"

    - id: "MS-HIGH-002"
      signal: "No health checks or liveness probes"
      remediation: "Implement comprehensive health monitoring"

    - id: "MS-HIGH-003"
      signal: "Model loading not optimized"
      remediation: "Implement model caching and warm-up"

  medium:
    - id: "MS-MED-001"
      signal: "No request batching"
      remediation: "Implement request batching for throughput"

    - id: "MS-MED-002"
      signal: "Scaling not configured properly"
      remediation: "Configure auto-scaling based on load"

    - id: "MS-MED-003"
      signal: "No graceful shutdown"
      remediation: "Implement graceful shutdown and draining"

  low:
    - id: "MS-LOW-001"
      signal: "Serving documentation incomplete"
      remediation: "Document API contracts and deployment procedures"

    - id: "MS-LOW-002"
      signal: "No request logging"
      remediation: "Implement comprehensive request logging"

  positive:
    - id: "MS-POS-001"
      signal: "Highly available serving with failover"
    - id: "MS-POS-002"
      signal: "Optimized latency meeting SLAs"
    - id: "MS-POS-003"
      signal: "Secure API with authentication and validation"

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Review Serving Architecture"
      description: "Examine serving infrastructure design"
      duration_estimate: "1 hour"

    - id: "2"
      name: "Assess Reliability"
      description: "Evaluate availability and failover mechanisms"
      duration_estimate: "1 hour"

    - id: "3"
      name: "Analyze Performance"
      description: "Profile latency and throughput"
      duration_estimate: "1 hour"

    - id: "4"
      name: "Review Security"
      description: "Assess authentication and input validation"
      duration_estimate: "45 minutes"

    - id: "5"
      name: "Check Scaling"
      description: "Review auto-scaling configuration"
      duration_estimate: "45 minutes"

    - id: "6"
      name: "Evaluate Monitoring"
      description: "Assess health checks and observability"
      duration_estimate: "45 minutes"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Architecture Analysis"
        - "Performance Assessment"
        - "Security Review"
        - "Recommendations"

closeout_checklist:
  - id: "ms-001"
    item: "Reliability assessed"
    level: "CRITICAL"
    verification: "automated"

  - id: "ms-002"
    item: "Security reviewed"
    level: "CRITICAL"
    verification: "manual"

  - id: "ms-003"
    item: "Performance profiled"
    level: "HIGH"
    verification: "automated"

governance:
  applicable_to:
    archetypes: ["ml-systems", "ai-applications"]

  compliance_mappings:
    - framework: "SOC 2"
      control: "Availability"
      description: "System availability requirements"

relationships:
  commonly_combined:
    - "machine-learning-ai.model-deployment.model-versioning"
    - "machine-learning-ai.model-monitoring.performance-monitoring"
  depends_on:
    - "machine-learning-ai.model-validation.model-testing"
  feeds_into:
    - "machine-learning-ai.model-monitoring.performance-monitoring"
