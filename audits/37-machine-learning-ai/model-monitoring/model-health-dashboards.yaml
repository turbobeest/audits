audit:
  id: machine-learning-ai.model-monitoring.model-health-dashboards
  name: Model Health Dashboards Audit
  version: 1.0.0
  last_updated: '2025-01-22'
  status: active
  category: machine-learning-ai
  category_number: 37
  subcategory: model-monitoring
  tier: expert
  estimated_duration: 2-4 hours  # median: 3h
  completeness: requires_discovery
  requires_runtime: true
  destructive: false
execution:
  automatable: partial
  severity: medium
  scope: ml-systems
  default_profiles:
  - full
  - quick
  blocks_phase: false
  parallelizable: true
description:
  what: |
    Evaluates model health dashboards including metric visualization, drill-down
    capabilities, refresh rates, and usability. Examines whether dashboards provide
    the visibility needed to understand and maintain model health.
  why_it_matters: |
    Dashboards are the primary interface for understanding model health. Poor dashboards
    hide problems, slow incident response, and make it difficult to maintain ML systems.
    Well-designed dashboards enable proactive monitoring and quick issue diagnosis.
  when_to_run:
  - When establishing monitoring practices
  - After usability complaints
  - During monitoring reviews
  - When adding new models
prerequisites:
  required_artifacts:
  - type: dashboards
    description: Access to monitoring dashboards
  - type: metric_definitions
    description: Metric documentation
  - type: user_feedback
    description: Dashboard user feedback
  access_requirements:
  - Access to dashboard tools
  - Access to metric sources
  - Access to dashboard configurations
discovery:
  file_patterns:
  - glob: '**/dashboards/**'
    purpose: Find dashboard configurations
  - glob: '**/grafana/**'
    purpose: Find Grafana dashboards
  - glob: '**/visualization/**'
    purpose: Find visualization code
knowledge_sources:
  guides:
  - id: grafana-docs
    name: Grafana Documentation
    url: https://grafana.com/docs/
  - id: dashboard-design
    name: Dashboard Design Best Practices
    url: https://grafana.com/blog/2022/01/11/dashboard-design-best-practices/
  standards:
  - id: dashboard-best-practices
    name: Dashboard Best Practices
    relevance: Effective data visualization
tooling:
  analysis_tools:
  - tool: grafana
    purpose: Dashboard platform
  - tool: datadog
    purpose: Observability dashboards
  - tool: tableau
    purpose: Business intelligence
  - tool: evidently
    purpose: ML-specific dashboards
signals:
  critical:
  - id: MHD-CRIT-001
    signal: No model health dashboards
    evidence_indicators:
    - No visibility into model performance
    - Cannot view key metrics
    - No centralized monitoring view
    explanation: |
      Without dashboards, understanding model health requires manual investigation,
      delaying issue detection and response.
    remediation: Create comprehensive model health dashboards
  high:
  - id: MHD-HIGH-001
    signal: Key metrics missing from dashboards
    remediation: Add missing performance and health metrics
  - id: MHD-HIGH-002
    signal: Dashboard refresh too slow
    remediation: Increase refresh rate for timely data
  - id: MHD-HIGH-003
    signal: No drill-down capability
    remediation: Add ability to investigate anomalies
  medium:
  - id: MHD-MED-001
    signal: Dashboard layout confusing
    remediation: Reorganize for intuitive navigation
  - id: MHD-MED-002
    signal: No historical comparison
    remediation: Add time range selection and comparison
  - id: MHD-MED-003
    signal: Metrics not segmented
    remediation: Add segment filters and breakdowns
  low:
  - id: MHD-LOW-001
    signal: No dashboard documentation
    remediation: Document dashboard panels and meanings
  - id: MHD-LOW-002
    signal: Inconsistent styling
    remediation: Standardize dashboard appearance
  positive:
  - id: MHD-POS-001
    signal: Comprehensive visibility with drill-down
  - id: MHD-POS-002
    signal: Real-time refresh with historical comparison
  - id: MHD-POS-003
    signal: Intuitive layout with clear documentation
procedure:
  context:
    cognitive_mode: evaluative
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Review Dashboard Coverage
    description: Assess what metrics are visualized
    duration_estimate: 30 minutes
  - id: '2'
    name: Evaluate Usability
    description: Test dashboard navigation and clarity
    duration_estimate: 30 minutes
  - id: '3'
    name: Check Refresh Rates
    description: Verify data freshness
    duration_estimate: 15 minutes
  - id: '4'
    name: Test Drill-Down
    description: Verify ability to investigate issues
    duration_estimate: 30 minutes
  - id: '5'
    name: Review Documentation
    description: Check dashboard documentation
    duration_estimate: 15 minutes
  - id: '6'
    name: Gather Feedback
    description: Collect user feedback on dashboards
    duration_estimate: 30 minutes
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Coverage Assessment
    - Usability Review
    - User Feedback
    - Recommendations
closeout_checklist:
- id: mhd-001
  item: Dashboard coverage verified
  level: HIGH
  verification: manual
- id: mhd-002
  item: Usability assessed
  level: MEDIUM
  verification: manual
- id: mhd-003
  item: Refresh rates checked
  level: MEDIUM
  verification: automated
governance:
  applicable_to:
    archetypes:
    - ml-systems
    - ai-applications
  compliance_mappings:
  - framework: SOC 2
    control: Monitoring
    description: System monitoring visibility requirements
relationships:
  commonly_combined:
  - machine-learning-ai.model-monitoring.performance-monitoring
  - machine-learning-ai.model-monitoring.alerting-configuration
  depends_on:
  - machine-learning-ai.model-monitoring.prediction-logging
  feeds_into:
  - machine-learning-ai.model-monitoring.incident-response
