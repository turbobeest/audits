# ============================================================
# AUDIT: ML Pipeline Orchestration
# Category: 37 - Machine Learning & AI
# Subcategory: mlops-infrastructure
# ============================================================

audit:
  id: "machine-learning-ai.mlops-infrastructure.ml-pipeline-orchestration"
  name: "ML Pipeline Orchestration Audit"
  version: "1.0.0"
  last_updated: "2025-01-22"
  status: "active"

  category: "machine-learning-ai"
  category_number: 37
  subcategory: "mlops-infrastructure"

  tier: "expert"
  estimated_duration: "4-6 hours"  # median: 5h

  completeness: "requires_discovery"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "ml-systems"

  default_profiles:
    - "full"
    - "quick"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Evaluates ML pipeline orchestration including workflow management, DAG definitions,
    scheduling, error handling, and integration with ML components. Examines whether
    pipelines are reliable, maintainable, and enable efficient ML operations.

  why_it_matters: |
    Pipeline orchestration coordinates the complex workflows that power ML systems.
    Poor orchestration leads to unreliable pipelines, failed training runs, and
    operational burden. Good orchestration enables automated, reliable ML operations.

  when_to_run:
    - "When establishing MLOps practices"
    - "After pipeline failures"
    - "During ML platform reviews"
    - "When scaling ML operations"

prerequisites:
  required_artifacts:
    - type: "orchestration_platform"
      description: "Access to pipeline orchestration system"
    - type: "pipeline_definitions"
      description: "Pipeline DAG definitions"
    - type: "execution_history"
      description: "Pipeline run history"

  access_requirements:
    - "Access to orchestration platform"
    - "Access to pipeline code"
    - "Access to execution logs"
    - "Access to monitoring dashboards"

discovery:
  file_patterns:
    - glob: "**/kubeflow/**"
      purpose: "Find Kubeflow pipelines"
    - glob: "**/airflow/dags/**"
      purpose: "Find Airflow DAGs"
    - glob: "**/prefect/**"
      purpose: "Find Prefect flows"
    - glob: "**/dagster/**"
      purpose: "Find Dagster pipelines"

knowledge_sources:
  guides:
    - id: "kubeflow-docs"
      name: "Kubeflow Pipelines Documentation"
      url: "https://www.kubeflow.org/docs/components/pipelines/"
    - id: "airflow-docs"
      name: "Apache Airflow Documentation"
      url: "https://airflow.apache.org/docs/"

  standards:
    - id: "ml-orchestration"
      name: "ML Pipeline Orchestration Best Practices"
      relevance: "Reliable ML workflows"

tooling:
  analysis_tools:
    - tool: "kubeflow"
      purpose: "ML pipeline orchestration"
    - tool: "airflow"
      purpose: "Workflow orchestration"
    - tool: "prefect"
      purpose: "Modern workflow orchestration"
    - tool: "dagster"
      purpose: "Data orchestration"
    - tool: "zenml"
      purpose: "ML pipeline framework"

signals:
  critical:
    - id: "PO-CRIT-001"
      signal: "Pipeline failures causing production impact"
      evidence_indicators:
        - "Failed pipelines affecting model freshness"
        - "No automated recovery"
        - "Production data delayed"
      explanation: |
        Pipeline failures that impact production cause stale models and delayed
        predictions, directly affecting users and business outcomes.
      remediation: "Implement robust error handling and automated recovery"

    - id: "PO-CRIT-002"
      signal: "No pipeline orchestration"
      evidence_indicators:
        - "Manual pipeline execution"
        - "No workflow management"
        - "Ad hoc script execution"
      explanation: |
        Without orchestration, ML operations are manual, error-prone, and
        unsustainable at scale.
      remediation: "Implement proper pipeline orchestration"

  high:
    - id: "PO-HIGH-001"
      signal: "Pipeline monitoring inadequate"
      remediation: "Implement comprehensive pipeline monitoring"

    - id: "PO-HIGH-002"
      signal: "No retry or failure handling"
      remediation: "Add retry logic and failure handling"

    - id: "PO-HIGH-003"
      signal: "Pipeline dependencies not managed"
      remediation: "Define and manage pipeline dependencies"

  medium:
    - id: "PO-MED-001"
      signal: "Pipeline testing missing"
      remediation: "Add pipeline testing before deployment"

    - id: "PO-MED-002"
      signal: "Resource management inefficient"
      remediation: "Optimize resource allocation for pipelines"

    - id: "PO-MED-003"
      signal: "Pipeline versioning not implemented"
      remediation: "Version pipeline definitions"

  low:
    - id: "PO-LOW-001"
      signal: "Pipeline documentation incomplete"
      remediation: "Document pipeline architecture and components"

    - id: "PO-LOW-002"
      signal: "Pipeline naming inconsistent"
      remediation: "Establish naming conventions"

  positive:
    - id: "PO-POS-001"
      signal: "Reliable pipelines with automated recovery"
    - id: "PO-POS-002"
      signal: "Comprehensive monitoring and alerting"
    - id: "PO-POS-003"
      signal: "Well-tested pipeline components"

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Review Orchestration Platform"
      description: "Assess pipeline orchestration infrastructure"
      duration_estimate: "1 hour"

    - id: "2"
      name: "Evaluate Pipeline Reliability"
      description: "Review failure rates and recovery"
      duration_estimate: "1 hour"

    - id: "3"
      name: "Check Error Handling"
      description: "Assess retry and failure handling"
      duration_estimate: "45 minutes"

    - id: "4"
      name: "Review Monitoring"
      description: "Evaluate pipeline monitoring coverage"
      duration_estimate: "30 minutes"

    - id: "5"
      name: "Assess Testing"
      description: "Review pipeline testing practices"
      duration_estimate: "30 minutes"

    - id: "6"
      name: "Check Documentation"
      description: "Review pipeline documentation"
      duration_estimate: "30 minutes"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Platform Assessment"
        - "Reliability Analysis"
        - "Monitoring Review"
        - "Recommendations"

closeout_checklist:
  - id: "po-001"
    item: "Pipeline reliability assessed"
    level: "CRITICAL"
    verification: "automated"

  - id: "po-002"
    item: "Error handling verified"
    level: "HIGH"
    verification: "manual"

  - id: "po-003"
    item: "Monitoring reviewed"
    level: "HIGH"
    verification: "manual"

governance:
  applicable_to:
    archetypes: ["ml-systems", "ai-applications", "data-platforms"]

  compliance_mappings:
    - framework: "SOC 2"
      control: "Operations"
      description: "Operational reliability requirements"

relationships:
  commonly_combined:
    - "machine-learning-ai.model-development.training-pipeline-quality"
    - "machine-learning-ai.data-quality.data-pipeline-reliability"
  depends_on:
    - "infrastructure-as-code.compute-infrastructure"
  feeds_into:
    - "machine-learning-ai.model-deployment.model-serving"
