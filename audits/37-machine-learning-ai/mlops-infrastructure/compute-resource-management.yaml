audit:
  id: machine-learning-ai.mlops-infrastructure.compute-resource-management
  name: Compute Resource Management Audit
  version: 1.0.0
  last_updated: '2025-01-22'
  status: active
  category: machine-learning-ai
  category_number: 37
  subcategory: mlops-infrastructure
  tier: expert
  estimated_duration: 3-5 hours  # median: 4h
  completeness: requires_discovery
  requires_runtime: true
  destructive: false
execution:
  automatable: partial
  severity: medium
  scope: ml-systems
  default_profiles:
  - full
  - quick
  blocks_phase: false
  parallelizable: true
description:
  what: |
    Evaluates ML compute resource management including GPU allocation, job scheduling,
    resource quotas, cost optimization, and capacity planning. Examines whether compute
    resources are used efficiently and cost-effectively.
  why_it_matters: |
    ML workloads consume expensive compute resources, especially GPUs. Poor resource
    management leads to wasted costs, training bottlenecks, and team friction over
    resources. Efficient management enables more experimentation and faster delivery
    at lower cost.
  when_to_run:
  - During cost optimization efforts
  - When compute demand increases
  - After resource contention issues
  - During capacity planning
prerequisites:
  required_artifacts:
  - type: compute_infrastructure
    description: Access to compute systems
  - type: resource_policies
    description: Resource allocation policies
  - type: cost_data
    description: Compute cost information
  access_requirements:
  - Access to compute infrastructure
  - Access to job scheduler
  - Access to cost monitoring
  - Access to usage metrics
discovery:
  file_patterns:
  - glob: '**/kubernetes/**'
    purpose: Find K8s configurations
  - glob: '**/slurm/**'
    purpose: Find SLURM configs
  - glob: '**/ray/**'
    purpose: Find Ray configurations
knowledge_sources:
  guides:
  - id: k8s-gpu
    name: Kubernetes GPU Scheduling
    url: https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/
  - id: ray-docs
    name: Ray Documentation
    url: https://docs.ray.io/
  standards:
  - id: compute-management
    name: ML Compute Best Practices
    relevance: Efficient resource utilization
tooling:
  analysis_tools:
  - tool: kubernetes
    purpose: Container orchestration
  - tool: ray
    purpose: Distributed computing
  - tool: slurm
    purpose: HPC job scheduling
  - tool: nvidia-smi
    purpose: GPU monitoring
signals:
  critical:
  - id: CRM-CRIT-001
    signal: Compute bottlenecks blocking ML work
    evidence_indicators:
    - Long wait times for GPUs
    - Training jobs queued for days
    - Teams unable to iterate
    explanation: |
      Compute bottlenecks directly impede ML development, slowing model
      improvement and business value delivery.
    remediation: Increase capacity or optimize resource usage
  - id: CRM-CRIT-002
    signal: Significant compute waste
    evidence_indicators:
    - GPUs sitting idle
    - Over-provisioned resources
    - Unused reserved instances
    explanation: |
      Compute waste directly translates to unnecessary cost, potentially
      diverting budget from other valuable activities.
    remediation: Implement usage monitoring and optimization
  high:
  - id: CRM-HIGH-001
    signal: No resource quotas
    remediation: Implement team and project quotas
  - id: CRM-HIGH-002
    signal: No cost visibility
    remediation: Implement cost tracking and attribution
  - id: CRM-HIGH-003
    signal: No job preemption
    remediation: Implement priority-based preemption
  medium:
  - id: CRM-MED-001
    signal: Spot/preemptible not utilized
    remediation: Use spot instances for fault-tolerant workloads
  - id: CRM-MED-002
    signal: No auto-scaling
    remediation: Implement auto-scaling for variable loads
  - id: CRM-MED-003
    signal: Resource requests not optimized
    remediation: Right-size resource requests
  low:
  - id: CRM-LOW-001
    signal: No capacity planning
    remediation: Implement capacity planning process
  - id: CRM-LOW-002
    signal: Resource usage not visible
    remediation: Create resource usage dashboards
  positive:
  - id: CRM-POS-001
    signal: Efficient resource utilization
  - id: CRM-POS-002
    signal: Clear cost attribution by team/project
  - id: CRM-POS-003
    signal: No resource contention issues
procedure:
  context:
    cognitive_mode: evaluative
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Review Resource Architecture
    description: Assess compute infrastructure setup
    duration_estimate: 45 minutes
  - id: '2'
    name: Analyze Utilization
    description: Review resource utilization metrics
    duration_estimate: 45 minutes
  - id: '3'
    name: Evaluate Cost Efficiency
    description: Assess compute cost management
    duration_estimate: 45 minutes
  - id: '4'
    name: Check Quotas and Policies
    description: Review resource allocation policies
    duration_estimate: 30 minutes
  - id: '5'
    name: Assess Scheduling
    description: Review job scheduling effectiveness
    duration_estimate: 30 minutes
  - id: '6'
    name: Review Capacity
    description: Evaluate capacity planning
    duration_estimate: 30 minutes
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Utilization Analysis
    - Cost Assessment
    - Capacity Review
    - Recommendations
closeout_checklist:
- id: crm-001
  item: Utilization analyzed
  level: HIGH
  verification: automated
- id: crm-002
  item: Cost efficiency assessed
  level: HIGH
  verification: automated
- id: crm-003
  item: Capacity reviewed
  level: MEDIUM
  verification: manual
governance:
  applicable_to:
    archetypes:
    - ml-systems
    - ai-applications
  compliance_mappings:
  - framework: FinOps
    control: Cost Management
    description: Cloud cost optimization
relationships:
  commonly_combined:
  - machine-learning-ai.model-development.training-pipeline-quality
  - infrastructure-as-code.compute-infrastructure
  depends_on:
  - infrastructure-as-code.compute-infrastructure
  feeds_into:
  - machine-learning-ai.mlops-infrastructure.ml-pipeline-orchestration
