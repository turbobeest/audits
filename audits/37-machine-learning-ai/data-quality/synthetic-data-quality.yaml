# ============================================================
# AUDIT: Synthetic Data Quality
# Category: 37 - Machine Learning & AI
# Subcategory: data-quality
# ============================================================

audit:
  id: "machine-learning-ai.data-quality.synthetic-data-quality"
  name: "Synthetic Data Quality Audit"
  version: "1.0.0"
  last_updated: "2025-01-22"
  status: "active"

  category: "machine-learning-ai"
  category_number: 37
  subcategory: "data-quality"

  tier: "expert"
  estimated_duration: "4-6 hours"  # median: 5h

  completeness: "requires_discovery"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "ml-systems"

  default_profiles:
    - "full"
    - "quick"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Evaluates the quality and appropriateness of synthetic data used in ML training,
    including data generation methods, distribution fidelity, privacy guarantees,
    and validation against real data. Examines whether synthetic data meets quality
    standards for its intended use.

  why_it_matters: |
    Synthetic data enables ML development when real data is scarce, expensive, or
    privacy-constrained. However, poor quality synthetic data can teach models
    incorrect patterns or fail to represent edge cases. Quality synthetic data
    requires careful generation and rigorous validation.

  when_to_run:
    - "Before using synthetic data for training"
    - "After implementing new data generation methods"
    - "When model trained on synthetic data underperforms"
    - "During privacy compliance reviews"

prerequisites:
  required_artifacts:
    - type: "synthetic_data"
      description: "Access to synthetic datasets"
    - type: "generation_code"
      description: "Data generation implementations"
    - type: "real_data_sample"
      description: "Real data for comparison"

  access_requirements:
    - "Access to synthetic data generation code"
    - "Access to generated synthetic data"
    - "Access to real data samples for comparison"
    - "Access to generation configurations"

discovery:
  file_patterns:
    - glob: "**/synthetic/**/*.py"
      purpose: "Find synthetic data generation code"
    - glob: "**/generators/**"
      purpose: "Find data generators"
    - glob: "**/sdv/**"
      purpose: "Find SDV configurations"
    - glob: "**/fake_data/**"
      purpose: "Find fake data generation"

knowledge_sources:
  guides:
    - id: "sdv-docs"
      name: "Synthetic Data Vault Documentation"
      url: "https://docs.sdv.dev/"
    - id: "gretel-docs"
      name: "Gretel AI Documentation"
      url: "https://docs.gretel.ai/"

  standards:
    - id: "synthetic-data-best-practices"
      name: "Synthetic Data Generation Best Practices"
      relevance: "Quality standards for synthetic data"

tooling:
  analysis_tools:
    - tool: "sdv"
      purpose: "Synthetic Data Vault generation"
    - tool: "gretel"
      purpose: "Enterprise synthetic data"
    - tool: "faker"
      purpose: "Simple fake data generation"
    - tool: "synthpop"
      purpose: "Statistical synthetic data"

signals:
  critical:
    - id: "SDQ-CRIT-001"
      signal: "Synthetic data reveals real data patterns"
      evidence_indicators:
        - "Real records recoverable from synthetic data"
        - "Privacy attacks successful"
        - "Differential privacy not implemented"
      explanation: |
        Synthetic data that leaks real data patterns defeats its privacy purpose and
        creates serious privacy and compliance violations.
      remediation: "Implement differential privacy and conduct membership inference attacks"

    - id: "SDQ-CRIT-002"
      signal: "Synthetic data fundamentally misrepresents reality"
      evidence_indicators:
        - "Key statistical properties not preserved"
        - "Critical correlations missing"
        - "Edge cases systematically underrepresented"
      explanation: |
        Synthetic data that doesn't represent real data distributions trains models
        that fail on actual production data.
      remediation: "Validate synthetic data against real data distributions comprehensively"

  high:
    - id: "SDQ-HIGH-001"
      signal: "No validation against real data"
      remediation: "Implement statistical comparison with real data"

    - id: "SDQ-HIGH-002"
      signal: "Synthetic data generation not reproducible"
      remediation: "Fix seeds and version generation configurations"

    - id: "SDQ-HIGH-003"
      signal: "Generated data fails schema validation"
      remediation: "Add constraints to ensure valid data generation"

  medium:
    - id: "SDQ-MED-001"
      signal: "Limited diversity in synthetic data"
      remediation: "Increase generation diversity and validate coverage"

    - id: "SDQ-MED-002"
      signal: "Synthetic data purpose not documented"
      remediation: "Document intended use and limitations"

    - id: "SDQ-MED-003"
      signal: "No quality metrics for synthetic data"
      remediation: "Define and track synthetic data quality metrics"

  low:
    - id: "SDQ-LOW-001"
      signal: "Generation parameters not tuned"
      remediation: "Tune generation parameters for optimal fidelity"

    - id: "SDQ-LOW-002"
      signal: "Synthetic data not versioned"
      remediation: "Implement versioning for synthetic datasets"

  positive:
    - id: "SDQ-POS-001"
      signal: "Validated privacy guarantees with differential privacy"
    - id: "SDQ-POS-002"
      signal: "Statistical fidelity verified against real data"
    - id: "SDQ-POS-003"
      signal: "Comprehensive quality metrics tracked"

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Review Generation Methods"
      description: "Examine synthetic data generation approach"
      duration_estimate: "45 minutes"

    - id: "2"
      name: "Assess Privacy Guarantees"
      description: "Evaluate privacy protection mechanisms"
      duration_estimate: "1 hour"

    - id: "3"
      name: "Compare Distributions"
      description: "Statistical comparison with real data"
      duration_estimate: "1 hour"

    - id: "4"
      name: "Validate Schema Compliance"
      description: "Verify synthetic data meets schema requirements"
      duration_estimate: "30 minutes"

    - id: "5"
      name: "Check Edge Case Coverage"
      description: "Assess representation of edge cases"
      duration_estimate: "45 minutes"

    - id: "6"
      name: "Review Documentation"
      description: "Evaluate documentation of limitations"
      duration_estimate: "30 minutes"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Generation Method Analysis"
        - "Privacy Assessment"
        - "Fidelity Analysis"
        - "Recommendations"

closeout_checklist:
  - id: "sdq-001"
    item: "Privacy guarantees verified"
    level: "CRITICAL"
    verification: "automated"

  - id: "sdq-002"
    item: "Statistical fidelity assessed"
    level: "HIGH"
    verification: "automated"

  - id: "sdq-003"
    item: "Limitations documented"
    level: "MEDIUM"
    verification: "manual"

governance:
  applicable_to:
    archetypes: ["ml-systems", "ai-applications", "data-platforms"]

  compliance_mappings:
    - framework: "GDPR"
      control: "Data Minimization"
      description: "Using synthetic data to minimize real data usage"
    - framework: "HIPAA"
      control: "De-identification"
      description: "Synthetic data as alternative to de-identification"

relationships:
  commonly_combined:
    - "machine-learning-ai.data-quality.training-data-quality"
    - "privacy-security.data-privacy"
  depends_on:
    - "data-state-management.data-governance"
  feeds_into:
    - "machine-learning-ai.model-development.training-pipeline-quality"
