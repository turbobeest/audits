# ============================================================
# AUDIT: Data Leakage Detection
# Category: 37 - Machine Learning & AI
# Subcategory: data-quality
# ============================================================

audit:
  id: "machine-learning-ai.data-quality.data-leakage-detection"
  name: "Data Leakage Detection Audit"
  version: "1.0.0"
  last_updated: "2025-01-22"
  status: "active"

  category: "machine-learning-ai"
  category_number: 37
  subcategory: "data-quality"

  tier: "expert"
  estimated_duration: "4-6 hours"  # median: 5h

  completeness: "requires_discovery"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "critical"
  scope: "ml-systems"

  default_profiles:
    - "full"
    - "quick"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Examines ML pipelines for data leakage including target leakage, temporal leakage,
    and train-test contamination. Identifies cases where information from the future
    or from test data influences training, leading to artificially inflated performance
    metrics.

  why_it_matters: |
    Data leakage is one of the most common and damaging mistakes in ML. It causes models
    to appear highly accurate during development but fail catastrophically in production
    when leaked information is unavailable. Detecting leakage early prevents wasted
    resources and deployment failures.

  when_to_run:
    - "Before trusting model performance metrics"
    - "When model performance seems too good"
    - "After pipeline refactoring"
    - "During model validation reviews"

prerequisites:
  required_artifacts:
    - type: "ml_pipeline"
      description: "Access to complete ML pipeline code"
    - type: "data_splits"
      description: "Access to train/validation/test splits"
    - type: "feature_definitions"
      description: "Feature engineering documentation"

  access_requirements:
    - "Read access to ML pipeline code"
    - "Access to feature engineering logic"
    - "Access to data splitting procedures"
    - "Access to training/evaluation code"

discovery:
  file_patterns:
    - glob: "**/train*.py"
      purpose: "Find training code"
    - glob: "**/features/**/*.py"
      purpose: "Find feature engineering"
    - glob: "**/preprocessing/**/*.py"
      purpose: "Find preprocessing code"
    - glob: "**/split*.py"
      purpose: "Find data splitting code"

knowledge_sources:
  guides:
    - id: "sklearn-leakage"
      name: "Scikit-learn Data Leakage Guide"
      url: "https://scikit-learn.org/stable/common_pitfalls.html"
    - id: "kaggle-leakage"
      name: "Kaggle Data Leakage Tutorial"
      url: "https://www.kaggle.com/learn/data-leakage"

  standards:
    - id: "ml-validation"
      name: "ML Validation Best Practices"
      relevance: "Preventing data leakage in ML"

tooling:
  analysis_tools:
    - tool: "static_analysis"
      purpose: "Code analysis for leakage patterns"
    - tool: "deepchecks"
      purpose: "ML validation checks"
    - tool: "feature_importance"
      purpose: "Identify suspicious features"

signals:
  critical:
    - id: "DL-CRIT-001"
      signal: "Target leakage in features"
      evidence_indicators:
        - "Features derived from target variable"
        - "Post-outcome data used as features"
        - "Feature highly correlated with target in suspicious way"
      explanation: |
        Target leakage occurs when features contain information about the target that
        would not be available at prediction time, making production predictions impossible.
      remediation: "Remove leaked features and recreate feature engineering with temporal awareness"

    - id: "DL-CRIT-002"
      signal: "Test data used in training"
      evidence_indicators:
        - "Test samples appear in training set"
        - "Statistics from full dataset used in preprocessing"
        - "Cross-validation implemented incorrectly"
      explanation: |
        Train-test contamination invalidates all performance metrics, making it impossible
        to know actual model generalization ability.
      remediation: "Implement strict data isolation and recompute all metrics"

    - id: "DL-CRIT-003"
      signal: "Temporal leakage in time-series data"
      evidence_indicators:
        - "Future data used to predict past"
        - "Random split on time-series data"
        - "Look-ahead bias in feature engineering"
      explanation: |
        Temporal leakage uses information from the future that won't be available at
        prediction time, making models useless for real-world forecasting.
      remediation: "Implement time-aware splitting and point-in-time correct features"

  high:
    - id: "DL-HIGH-001"
      signal: "Preprocessing fit on full dataset"
      remediation: "Fit preprocessing only on training data"

    - id: "DL-HIGH-002"
      signal: "Feature selection using test data"
      remediation: "Perform feature selection only on training data"

    - id: "DL-HIGH-003"
      signal: "Model performance too good to be true"
      remediation: "Investigate suspiciously high metrics for leakage"

  medium:
    - id: "DL-MED-001"
      signal: "Data splitting not reproducible"
      remediation: "Use fixed random seeds for data splits"

    - id: "DL-MED-002"
      signal: "No validation of feature availability at inference"
      remediation: "Document and validate feature availability timing"

    - id: "DL-MED-003"
      signal: "Cross-validation leakage in nested pipelines"
      remediation: "Use Pipeline objects to prevent preprocessing leakage"

  low:
    - id: "DL-LOW-001"
      signal: "Leakage checks not automated"
      remediation: "Add automated leakage detection to CI/CD"

    - id: "DL-LOW-002"
      signal: "Feature timing not documented"
      remediation: "Document when each feature becomes available"

  positive:
    - id: "DL-POS-001"
      signal: "Automated leakage detection in pipeline"
    - id: "DL-POS-002"
      signal: "Point-in-time correct feature engineering"
    - id: "DL-POS-003"
      signal: "Strict train/test isolation verified"

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Review Data Splitting"
      description: "Examine train/validation/test split procedures"
      duration_estimate: "45 minutes"

    - id: "2"
      name: "Analyze Feature Engineering"
      description: "Check features for target and temporal leakage"
      duration_estimate: "1.5 hours"

    - id: "3"
      name: "Examine Preprocessing"
      description: "Verify preprocessing uses only training data"
      duration_estimate: "45 minutes"

    - id: "4"
      name: "Check Cross-Validation"
      description: "Verify proper isolation in CV procedures"
      duration_estimate: "30 minutes"

    - id: "5"
      name: "Validate Feature Timing"
      description: "Confirm features available at inference time"
      duration_estimate: "45 minutes"

    - id: "6"
      name: "Investigate Suspicious Metrics"
      description: "Examine unusually high performance metrics"
      duration_estimate: "45 minutes"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Leakage Analysis"
        - "Feature Timeline Validation"
        - "Risk Assessment"
        - "Recommendations"

closeout_checklist:
  - id: "dl-001"
    item: "Target leakage checked"
    level: "CRITICAL"
    verification: "manual"

  - id: "dl-002"
    item: "Train-test isolation verified"
    level: "CRITICAL"
    verification: "automated"

  - id: "dl-003"
    item: "Temporal correctness validated"
    level: "CRITICAL"
    verification: "manual"

governance:
  applicable_to:
    archetypes: ["ml-systems", "ai-applications"]

  compliance_mappings:
    - framework: "EU AI Act"
      control: "Accuracy"
      description: "Requirements for AI system accuracy and reliability"

relationships:
  commonly_combined:
    - "machine-learning-ai.model-validation.model-testing"
    - "machine-learning-ai.model-development.feature-engineering-quality"
  depends_on:
    - "machine-learning-ai.data-quality.training-data-quality"
  feeds_into:
    - "machine-learning-ai.model-validation.cross-validation-practices"
