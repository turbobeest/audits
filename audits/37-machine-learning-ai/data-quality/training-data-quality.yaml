# ============================================================
# AUDIT: Training Data Quality
# Category: 37 - Machine Learning & AI
# Subcategory: data-quality
# ============================================================

audit:
  id: "machine-learning-ai.data-quality.training-data-quality"
  name: "Training Data Quality Audit"
  version: "1.0.0"
  last_updated: "2025-01-22"
  status: "active"

  category: "machine-learning-ai"
  category_number: 37
  subcategory: "data-quality"

  tier: "expert"
  estimated_duration: "5-8 hours"  # median: 6h

  completeness: "requires_discovery"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "critical"
  scope: "ml-systems"

  default_profiles:
    - "full"
    - "quick"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Evaluates the quality of training data including completeness, accuracy, consistency,
    representativeness, and freshness. Examines data collection processes, validation
    pipelines, and quality metrics to ensure training data supports reliable model
    development.

  why_it_matters: |
    Training data quality is the single most important factor in ML model performance.
    Poor quality data leads to biased, inaccurate, or unreliable models regardless of
    algorithm sophistication. Data quality issues propagate through the entire ML
    pipeline and can cause significant business harm.

  when_to_run:
    - "Before training new models"
    - "After data source changes"
    - "When model performance degrades"
    - "During data pipeline audits"

prerequisites:
  required_artifacts:
    - type: "training_data"
      description: "Access to training datasets"
    - type: "data_documentation"
      description: "Data dictionaries and schemas"
    - type: "collection_processes"
      description: "Data collection documentation"

  access_requirements:
    - "Read access to training data"
    - "Access to data pipelines"
    - "Access to data quality reports"
    - "Access to data documentation"

discovery:
  file_patterns:
    - glob: "**/data/**/*.csv"
      purpose: "Find CSV data files"
    - glob: "**/data/**/*.parquet"
      purpose: "Find Parquet data files"
    - glob: "**/schemas/**"
      purpose: "Find data schemas"
    - glob: "**/great_expectations/**"
      purpose: "Find data validation configs"

knowledge_sources:
  guides:
    - id: "great-expectations-docs"
      name: "Great Expectations Documentation"
      url: "https://docs.greatexpectations.io/"
    - id: "data-quality-guide"
      name: "Data Quality Best Practices"
      url: "https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning"

  standards:
    - id: "data-quality-dimensions"
      name: "Data Quality Dimensions Framework"
      relevance: "Standard data quality metrics"

tooling:
  analysis_tools:
    - tool: "great_expectations"
      purpose: "Data validation and profiling"
    - tool: "pandas-profiling"
      purpose: "Automated data profiling"
    - tool: "tfdv"
      purpose: "TensorFlow Data Validation"
    - tool: "whylogs"
      purpose: "Data logging and profiling"
    - tool: "deequ"
      purpose: "Data quality on Spark"

signals:
  critical:
    - id: "TDQ-CRIT-001"
      signal: "Training data contains systematic errors"
      evidence_indicators:
        - "Consistent mislabeling in ground truth"
        - "Data collection bias affecting all samples"
        - "Corrupted data not caught by validation"
      explanation: |
        Systematic errors in training data cause models to learn incorrect patterns,
        leading to consistently wrong predictions that may not be detected until
        significant harm occurs.
      remediation: "Implement comprehensive data validation and human-in-the-loop quality checks"

    - id: "TDQ-CRIT-002"
      signal: "Training data not representative of production"
      evidence_indicators:
        - "Distribution shift between training and production"
        - "Missing important subgroups in training data"
        - "Temporal misalignment with production data"
      explanation: |
        Non-representative training data leads to models that perform well in development
        but fail in production when encountering real-world data distributions.
      remediation: "Align training data collection with production data characteristics"

    - id: "TDQ-CRIT-003"
      signal: "Sensitive data in training set without authorization"
      evidence_indicators:
        - "PII in training data without consent"
        - "Protected attributes used without approval"
        - "Data retention violations"
      explanation: |
        Using unauthorized sensitive data creates legal liability and privacy violations
        that may require model deletion and retraining from scratch.
      remediation: "Audit data for sensitive information and ensure proper authorization"

  high:
    - id: "TDQ-HIGH-001"
      signal: "High rate of missing values"
      remediation: "Investigate missing data patterns and implement proper handling"

    - id: "TDQ-HIGH-002"
      signal: "No data validation pipeline"
      remediation: "Implement automated data validation using Great Expectations or similar"

    - id: "TDQ-HIGH-003"
      signal: "Class imbalance not addressed"
      remediation: "Implement sampling strategies or loss weighting for imbalanced data"

  medium:
    - id: "TDQ-MED-001"
      signal: "Data documentation incomplete"
      remediation: "Create comprehensive data dictionary and collection documentation"

    - id: "TDQ-MED-002"
      signal: "Outliers not analyzed"
      remediation: "Profile data for outliers and determine appropriate handling"

    - id: "TDQ-MED-003"
      signal: "Data freshness not monitored"
      remediation: "Implement data freshness tracking and alerting"

  low:
    - id: "TDQ-LOW-001"
      signal: "Data schema not formally defined"
      remediation: "Define formal data schemas with validation rules"

    - id: "TDQ-LOW-002"
      signal: "Data profiling not automated"
      remediation: "Implement automated data profiling in pipeline"

  positive:
    - id: "TDQ-POS-001"
      signal: "Comprehensive data validation pipeline in place"
    - id: "TDQ-POS-002"
      signal: "Full data lineage tracking"
    - id: "TDQ-POS-003"
      signal: "Regular data quality monitoring with alerting"

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Profile Training Data"
      description: "Generate comprehensive data profiles and statistics"
      duration_estimate: "1 hour"

    - id: "2"
      name: "Validate Data Quality"
      description: "Run data quality checks and identify issues"
      duration_estimate: "1.5 hours"

    - id: "3"
      name: "Assess Representativeness"
      description: "Compare training data distribution to production"
      duration_estimate: "1 hour"

    - id: "4"
      name: "Check Sensitive Data"
      description: "Audit for unauthorized sensitive data"
      duration_estimate: "1 hour"

    - id: "5"
      name: "Review Documentation"
      description: "Evaluate data documentation completeness"
      duration_estimate: "45 minutes"

    - id: "6"
      name: "Assess Pipeline Integration"
      description: "Review data validation in ML pipeline"
      duration_estimate: "45 minutes"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Data Quality Profile"
        - "Representativeness Analysis"
        - "Sensitive Data Assessment"
        - "Recommendations"

closeout_checklist:
  - id: "tdq-001"
    item: "Data profiling completed"
    level: "CRITICAL"
    verification: "automated"

  - id: "tdq-002"
    item: "Sensitive data audit performed"
    level: "CRITICAL"
    verification: "manual"

  - id: "tdq-003"
    item: "Representativeness assessed"
    level: "HIGH"
    verification: "automated"

governance:
  applicable_to:
    archetypes: ["ml-systems", "ai-applications", "data-platforms"]

  compliance_mappings:
    - framework: "EU AI Act"
      control: "Data Governance"
      description: "Requirements for training data quality and governance"
    - framework: "GDPR"
      control: "Data Protection"
      description: "Personal data processing requirements"

relationships:
  commonly_combined:
    - "machine-learning-ai.data-quality.data-labeling-quality"
    - "machine-learning-ai.responsible-ai.bias-detection"
  depends_on:
    - "data-state-management.data-governance"
  feeds_into:
    - "machine-learning-ai.model-development.training-pipeline-quality"
