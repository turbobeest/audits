audit:
  id: machine-learning-ai.llm-operations.llm-integration
  name: LLM Integration Audit
  version: 1.0.0
  last_updated: '2025-01-22'
  status: active
  category: machine-learning-ai
  category_number: 37
  subcategory: llm-operations
  tier: expert
  estimated_duration: 3-5 hours  # median: 4h
  completeness: requires_discovery
  requires_runtime: true
  destructive: false
execution:
  automatable: partial
  severity: high
  scope: ml-systems
  default_profiles:
  - full
  - quick
  blocks_phase: false
  parallelizable: true
description:
  what: |
    Evaluates LLM integration practices including API usage, error handling, rate
    limiting, cost management, and fallback strategies. Examines whether LLM
    integrations are reliable, efficient, and well-managed.
  why_it_matters: |
    LLM integrations can be unreliable, expensive, and rate-limited. Poor integration
    practices lead to outages, cost overruns, and degraded user experience. Good
    integration ensures reliable, cost-effective LLM operations.
  when_to_run:
  - When integrating LLM providers
  - After integration issues
  - During cost optimization
  - When changing LLM providers
prerequisites:
  required_artifacts:
  - type: integration_code
    description: LLM integration implementations
  - type: api_configs
    description: API configurations
  - type: usage_metrics
    description: LLM usage data
  access_requirements:
  - Access to LLM integration code
  - Access to API configurations
  - Access to usage metrics
  - Access to cost data
discovery:
  file_patterns:
  - glob: '**/llm/**'
    purpose: Find LLM integration code
  - glob: '**/openai/**'
    purpose: Find OpenAI integration
  - glob: '**/anthropic/**'
    purpose: Find Anthropic integration
  - glob: '**/langchain/**'
    purpose: Find LangChain code
knowledge_sources:
  guides:
  - id: openai-api
    name: OpenAI API Documentation
    url: https://platform.openai.com/docs/
  - id: langchain-docs
    name: LangChain Documentation
    url: https://python.langchain.com/
  standards:
  - id: llm-integration-best-practices
    name: LLM Integration Best Practices
    relevance: Reliable LLM API usage
tooling:
  analysis_tools:
  - tool: langchain
    purpose: LLM integration framework
  - tool: litellm
    purpose: Unified LLM interface
  - tool: helicone
    purpose: LLM observability
  - tool: portkey
    purpose: LLM gateway
signals:
  critical:
  - id: LI-CRIT-001
    signal: LLM integration causing outages
    evidence_indicators:
    - Rate limits causing failures
    - No error handling for API failures
    - Users affected by LLM unavailability
    explanation: |
      Unreliable LLM integration directly impacts users and can cause
      cascading failures in dependent systems.
    remediation: Implement robust error handling and fallbacks
  - id: LI-CRIT-002
    signal: API keys exposed
    evidence_indicators:
    - Keys in code or logs
    - Keys not rotated
    - Broad key permissions
    explanation: |
      Exposed API keys can be stolen and misused, causing significant
      costs and security incidents.
    remediation: Secure API keys with proper secrets management
  high:
  - id: LI-HIGH-001
    signal: No rate limiting handling
    remediation: Implement rate limit handling with backoff
  - id: LI-HIGH-002
    signal: No cost monitoring
    remediation: Implement cost tracking and alerts
  - id: LI-HIGH-003
    signal: No fallback strategy
    remediation: Implement fallbacks for LLM failures
  medium:
  - id: LI-MED-001
    signal: No request caching
    remediation: Implement semantic caching where appropriate
  - id: LI-MED-002
    signal: Single provider dependency
    remediation: Consider multi-provider strategy
  - id: LI-MED-003
    signal: No request logging
    remediation: Implement request/response logging
  low:
  - id: LI-LOW-001
    signal: Integration not documented
    remediation: Document integration patterns
  - id: LI-LOW-002
    signal: Model selection not optimized
    remediation: Use appropriate models for tasks
  positive:
  - id: LI-POS-001
    signal: Robust error handling with fallbacks
  - id: LI-POS-002
    signal: Comprehensive cost management
  - id: LI-POS-003
    signal: Secure API key management
procedure:
  context:
    cognitive_mode: evaluative
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Review Integration Architecture
    description: Assess LLM integration design
    duration_estimate: 45 minutes
  - id: '2'
    name: Check Error Handling
    description: Evaluate error handling and retries
    duration_estimate: 45 minutes
  - id: '3'
    name: Assess Security
    description: Review API key management
    duration_estimate: 30 minutes
  - id: '4'
    name: Evaluate Cost Management
    description: Review cost tracking and optimization
    duration_estimate: 30 minutes
  - id: '5'
    name: Check Rate Limiting
    description: Assess rate limit handling
    duration_estimate: 30 minutes
  - id: '6'
    name: Review Monitoring
    description: Evaluate integration monitoring
    duration_estimate: 30 minutes
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Integration Architecture
    - Reliability Assessment
    - Cost Analysis
    - Recommendations
closeout_checklist:
- id: li-001
  item: Error handling verified
  level: CRITICAL
  verification: manual
- id: li-002
  item: API key security checked
  level: CRITICAL
  verification: automated
- id: li-003
  item: Cost management assessed
  level: HIGH
  verification: automated
governance:
  applicable_to:
    archetypes:
    - llm-systems
    - ai-applications
  compliance_mappings:
  - framework: SOC 2
    control: Vendor Management
    description: Third-party integration requirements
relationships:
  commonly_combined:
  - machine-learning-ai.llm-operations.prompt-management
  - machine-learning-ai.llm-operations.llm-cost-optimization
  depends_on:
  - security-audit.api-security
  feeds_into:
  - machine-learning-ai.llm-operations.llm-evaluation
