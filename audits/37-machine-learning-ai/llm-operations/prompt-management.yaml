audit:
  id: machine-learning-ai.llm-operations.prompt-management
  name: Prompt Management Audit
  version: 1.0.0
  last_updated: '2025-01-22'
  status: active
  category: machine-learning-ai
  category_number: 37
  subcategory: llm-operations
  tier: expert
  estimated_duration: 3-5 hours  # median: 4h
  completeness: requires_discovery
  requires_runtime: true
  destructive: false
execution:
  automatable: partial
  severity: high
  scope: ml-systems
  default_profiles:
  - full
  - quick
  blocks_phase: false
  parallelizable: true
description:
  what: |
    Evaluates prompt management practices including prompt versioning, testing,
    storage, deployment, and monitoring. Examines whether prompts are treated as
    first-class artifacts with proper lifecycle management.
  why_it_matters: |
    Prompts are critical components of LLM applications that directly impact output
    quality and safety. Poor prompt management leads to inconsistent behavior,
    difficult debugging, and inability to iterate effectively. Proper management
    enables reliable LLM application development.
  when_to_run:
  - When building LLM applications
  - After prompt-related issues
  - During LLM system reviews
  - When establishing LLMOps practices
prerequisites:
  required_artifacts:
  - type: prompt_store
    description: Access to prompt storage
  - type: prompt_code
    description: Prompt implementation code
  - type: llm_applications
    description: LLM application access
  access_requirements:
  - Access to prompt storage
  - Access to prompt testing tools
  - Access to LLM applications
  - Access to prompt monitoring
discovery:
  file_patterns:
  - glob: '**/prompts/**'
    purpose: Find prompt files
  - glob: '**/*.prompt'
    purpose: Find prompt templates
  - glob: '**/langchain/**'
    purpose: Find LangChain code
  - glob: '**/llm/**'
    purpose: Find LLM code
knowledge_sources:
  guides:
  - id: langchain-prompts
    name: LangChain Prompts Guide
    url: https://python.langchain.com/docs/modules/model_io/prompts/
  - id: prompt-engineering
    name: OpenAI Prompt Engineering
    url: https://platform.openai.com/docs/guides/prompt-engineering
  standards:
  - id: prompt-management-best-practices
    name: Prompt Management Best Practices
    relevance: LLM prompt lifecycle management
tooling:
  analysis_tools:
  - tool: langchain
    purpose: LLM application framework
  - tool: promptfoo
    purpose: Prompt testing
  - tool: humanloop
    purpose: Prompt management platform
  - tool: langsmith
    purpose: LLM observability
signals:
  critical:
  - id: PM-CRIT-001
    signal: Prompts hardcoded without versioning
    evidence_indicators:
    - Prompts embedded in code
    - No version control for prompts
    - Cannot track prompt changes
    explanation: |
      Hardcoded prompts make iteration difficult, debugging impossible, and
      prevent proper testing and rollback capabilities.
    remediation: Implement prompt storage and versioning
  - id: PM-CRIT-002
    signal: Unsafe prompts deployed to production
    evidence_indicators:
    - Prompts vulnerable to injection
    - No safety testing
    - Harmful outputs possible
    explanation: |
      Unsafe prompts can be exploited to produce harmful, biased, or dangerous
      outputs, creating significant risk.
    remediation: Implement prompt safety testing and validation
  high:
  - id: PM-HIGH-001
    signal: No prompt testing
    remediation: Implement systematic prompt testing
  - id: PM-HIGH-002
    signal: Prompts not reviewed before deployment
    remediation: Add prompt review workflow
  - id: PM-HIGH-003
    signal: No prompt performance monitoring
    remediation: Monitor prompt effectiveness
  medium:
  - id: PM-MED-001
    signal: No prompt templates
    remediation: Use parameterized prompt templates
  - id: PM-MED-002
    signal: Prompt documentation missing
    remediation: Document prompt purpose and behavior
  - id: PM-MED-003
    signal: No A/B testing for prompts
    remediation: Implement prompt experimentation
  low:
  - id: PM-LOW-001
    signal: Prompt naming inconsistent
    remediation: Establish naming conventions
  - id: PM-LOW-002
    signal: No prompt reuse strategy
    remediation: Create reusable prompt components
  positive:
  - id: PM-POS-001
    signal: Versioned prompts with testing
  - id: PM-POS-002
    signal: Safety validation for all prompts
  - id: PM-POS-003
    signal: Prompt performance monitoring
procedure:
  context:
    cognitive_mode: evaluative
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Review Prompt Storage
    description: Assess prompt management infrastructure
    duration_estimate: 45 minutes
  - id: '2'
    name: Check Versioning
    description: Verify prompt versioning practices
    duration_estimate: 30 minutes
  - id: '3'
    name: Evaluate Testing
    description: Review prompt testing approach
    duration_estimate: 45 minutes
  - id: '4'
    name: Assess Safety
    description: Check prompt safety measures
    duration_estimate: 45 minutes
  - id: '5'
    name: Review Monitoring
    description: Evaluate prompt monitoring
    duration_estimate: 30 minutes
  - id: '6'
    name: Check Documentation
    description: Review prompt documentation
    duration_estimate: 15 minutes
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Management Assessment
    - Testing Review
    - Safety Analysis
    - Recommendations
closeout_checklist:
- id: pm-001
  item: Versioning verified
  level: CRITICAL
  verification: manual
- id: pm-002
  item: Safety testing assessed
  level: CRITICAL
  verification: manual
- id: pm-003
  item: Monitoring reviewed
  level: HIGH
  verification: manual
governance:
  applicable_to:
    archetypes:
    - llm-systems
    - ai-applications
  compliance_mappings:
  - framework: EU AI Act
    control: AI System Safety
    description: Requirements for safe AI outputs
relationships:
  commonly_combined:
  - machine-learning-ai.llm-operations.llm-evaluation
  - machine-learning-ai.llm-operations.llm-safety
  depends_on:
  - machine-learning-ai.llm-operations.llm-integration
  feeds_into:
  - machine-learning-ai.llm-operations.llm-evaluation
