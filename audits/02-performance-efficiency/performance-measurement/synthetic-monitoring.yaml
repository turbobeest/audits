# ============================================================
# AUDIT: Synthetic Monitoring Audit
# ============================================================

audit:
  id: "performance-efficiency.performance-measurement.synthetic-monitoring"
  name: "Synthetic Monitoring Audit"
  version: "1.0.0"
  last_updated: "2026-01-18"
  status: "active"

  category: "performance-efficiency"
  category_number: 2
  subcategory: "performance-measurement"

  tier: "expert"
  estimated_duration: "2 hours"

  completeness: "complete"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "infrastructure"

  default_profiles:
    - "full"
    - "production"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Evaluates synthetic monitoring implementation including uptime checks,
    multi-step transaction monitoring, geographic distribution of tests,
    browser-based tests for Core Web Vitals, API endpoint monitoring, and
    alerting configuration. Verifies coverage of critical user journeys.

  why_it_matters: |
    Synthetic monitoring provides consistent, proactive performance measurement
    that doesn't depend on real user traffic. It detects issues during off-peak
    hours, validates deployments before users are affected, and provides
    consistent baseline measurements. Companies using synthetic monitoring
    detect 40% of outages before users report them.

  when_to_run:
    - "Initial monitoring setup"
    - "After critical journey changes"
    - "Geographic expansion"
    - "Quarterly monitoring reviews"

prerequisites:
  required_artifacts:
    - type: "infrastructure_config"
      description: "Synthetic monitoring configuration"
    - type: "documentation"
      description: "Critical user journey documentation"

  access_requirements:
    - "Synthetic monitoring tool access (Checkly, Datadog, etc.)"
    - "Critical user journey documentation"
    - "Alerting configuration access"

discovery:
  file_patterns:
    - glob: "**/*checkly*"
      purpose: "Checkly configuration"
    - glob: "**/*synthetic*"
      purpose: "Synthetic test definitions"
    - glob: "**/*playwright*"
      purpose: "Playwright test files"
    - glob: "**/*puppeteer*"
      purpose: "Puppeteer test files"

  code_patterns:
    - pattern: "checkly|synthetic|uptime|healthcheck"
      type: "keyword"
      scope: "config"
      purpose: "Find synthetic monitoring configuration"
    - pattern: "playwright|puppeteer|selenium"
      type: "keyword"
      scope: "source"
      purpose: "Find browser automation tests"

knowledge_sources:
  guides:
    - id: "checkly-docs"
      name: "Checkly Documentation"
      url: "https://www.checklyhq.com/docs/"
      offline_cache: true
    - id: "datadog-synthetic"
      name: "Datadog Synthetic Monitoring"
      url: "https://docs.datadoghq.com/synthetics/"
      offline_cache: true
    - id: "playwright-docs"
      name: "Playwright Documentation"
      url: "https://playwright.dev/docs/intro"
      offline_cache: true

  learning_resources:
    - id: "synthetic-vs-rum"
      title: "Synthetic vs Real User Monitoring"
      type: "article"
      reference: "https://web.dev/vitals/"

tooling:
  infrastructure_tools:
    - tool: "checkly"
      purpose: "Synthetic monitoring as code"
      command: "npx checkly test"
    - tool: "playwright"
      purpose: "Browser-based synthetic tests"
      command: "npx playwright test"

  scripts:
    - id: "synthetic-check"
      language: "bash"
      purpose: "Run basic synthetic health checks"
      source: "inline"
      code: |
        #!/bin/bash
        echo "=== Synthetic Monitoring Check ==="

        # Basic health check
        echo -e "\n--- Health Endpoint ---"
        curl -s -o /dev/null -w "Status: %{http_code}, Time: %{time_total}s\n" https://example.com/health

        # Homepage availability
        echo -e "\n--- Homepage ---"
        curl -s -o /dev/null -w "Status: %{http_code}, Time: %{time_total}s\n" https://example.com/

        # API endpoint
        echo -e "\n--- API Health ---"
        curl -s -o /dev/null -w "Status: %{http_code}, Time: %{time_total}s\n" https://api.example.com/health

signals:
  critical:
    - id: "SYNTH-CRIT-001"
      signal: "No synthetic monitoring configured"
      evidence_pattern: "No Checkly, Datadog Synthetics, or equivalent found"
      explanation: |
        Without synthetic monitoring, issues during low-traffic periods go
        undetected until users return. Post-deployment problems aren't caught
        proactively. There's no consistent baseline measurement independent
        of traffic volume. This creates unacceptable detection gaps.
      remediation: "Implement synthetic monitoring with Checkly, Datadog, or similar"

    - id: "SYNTH-CRIT-002"
      signal: "Critical user journeys not covered by synthetic tests"
      evidence_pattern: "Only health check, not login, checkout, search"
      explanation: |
        Health checks only verify basic availability, not functionality.
        If the login flow breaks but the health endpoint works, users are
        blocked but monitoring shows green. Critical journeys (login, checkout,
        search) must be actively tested.
      remediation: "Implement multi-step synthetic tests for all critical user journeys"

  high:
    - id: "SYNTH-HIGH-001"
      signal: "Synthetic tests run from single location"
      evidence_pattern: "All tests from one region, no geographic distribution"
      explanation: |
        Single-location tests miss regional issues like CDN problems, DNS
        propagation delays, or regional service outages. Users in affected
        regions experience issues while monitoring shows healthy. Multi-region
        testing catches these blind spots.
      remediation: "Run synthetic tests from multiple geographic regions"

    - id: "SYNTH-HIGH-002"
      signal: "No browser-based synthetic tests for Core Web Vitals"
      evidence_pattern: "Only API checks, no real browser rendering tests"
      explanation: |
        API response time doesn't reflect user-perceived performance. Browser
        tests measure actual rendering: LCP, FID, CLS. Without browser tests,
        JavaScript errors, rendering issues, and layout shifts go undetected.
      remediation: "Implement browser-based synthetic tests measuring Core Web Vitals"

  medium:
    - id: "SYNTH-MED-001"
      signal: "Synthetic test frequency too low"
      evidence_pattern: "Tests run hourly instead of every 1-5 minutes"
      remediation: "Increase critical path test frequency to 1-5 minute intervals"

    - id: "SYNTH-MED-002"
      signal: "No alerting configured for synthetic test failures"
      evidence_pattern: "Tests run but failures don't alert"
      remediation: "Configure immediate alerts for synthetic test failures"

  low:
    - id: "SYNTH-LOW-001"
      signal: "Synthetic tests not version-controlled"

  positive:
    - id: "SYNTH-POS-001"
      signal: "Multi-step journey tests for critical paths"
    - id: "SYNTH-POS-002"
      signal: "Geographic distribution of test locations"
    - id: "SYNTH-POS-003"
      signal: "Browser-based tests measuring Core Web Vitals"
    - id: "SYNTH-POS-004"
      signal: "High-frequency testing with immediate alerting"

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Locate Synthetic Test Configuration"
      description: |
        Find synthetic monitoring configuration including test
        definitions, schedules, and locations.
      duration_estimate: "20 min"

      commands:
        - purpose: "Find Checkly configuration"
          command: "find . -name '*checkly*' -o -name '*.check.ts' -o -name '*.check.js' | head -10"
        - purpose: "Find Playwright tests"
          command: "find . -name '*playwright*' -o -name '*e2e*' | head -10"
        - purpose: "Search for synthetic configs"
          command: "grep -rn 'synthetic\\|uptime\\|healthcheck' --include='*.yaml' --include='*.json' ."

      expected_findings:
        - "Synthetic test configurations"
        - "Test schedules and locations"

    - id: "2"
      name: "Review Journey Coverage"
      description: |
        Analyze which user journeys are covered by synthetic
        tests and identify gaps.
      duration_estimate: "30 min"

      commands:
        - purpose: "Extract tested URLs from configs"
          command: "grep -rn 'url\\|endpoint\\|page' --include='*.check.*' --include='*synthetic*' . | head -20"
        - purpose: "List critical journeys tested"
          command: "grep -rn 'login\\|checkout\\|search\\|signup' --include='*.check.*' --include='*playwright*' ."

      questions:
        - "Is login/authentication tested?"
        - "Is checkout/payment tested?"
        - "Is search functionality tested?"
        - "Are key API endpoints tested?"

      expected_findings:
        - "Critical journeys covered"
        - "Gaps identified"

    - id: "3"
      name: "Verify Geographic Distribution"
      description: |
        Check that synthetic tests run from multiple locations
        to detect regional issues.
      duration_estimate: "15 min"

      commands:
        - purpose: "Find location configuration"
          command: "grep -rn 'location\\|region\\|datacenter' --include='*.check.*' --include='*.yaml' ."
        - purpose: "Count unique locations"
          command: "grep -oE '(us-east|us-west|eu-west|eu-central|ap-southeast|ap-northeast)' . -r | sort -u | wc -l"

      expected_findings:
        - "Multiple geographic locations"
        - "Coverage of key user regions"

    - id: "4"
      name: "Review Alerting and Frequency"
      description: |
        Verify synthetic tests have appropriate frequency and
        alert on failures.
      duration_estimate: "20 min"

      commands:
        - purpose: "Find test frequency"
          command: "grep -rn 'frequency\\|interval\\|schedule\\|cron' --include='*.check.*' --include='*.yaml' ."
        - purpose: "Find alert configuration"
          command: "grep -rn 'alert\\|notify\\|slack\\|pagerduty' --include='*.check.*' --include='*.yaml' ."

      expected_findings:
        - "High-frequency testing (1-5 min)"
        - "Alert routing configured"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Journey Coverage Analysis"
        - "Geographic Distribution"
        - "Test Frequency and Alerting"
        - "Recommendations"

  confidence_guidance:
    high: "Direct synthetic monitoring tool access"
    medium: "Configuration file analysis"
    low: "Interview-based assessment"

offline:
  capability: "partial"

  cache_manifest:
    knowledge:
      - source_id: "checkly-docs"
        priority: "recommended"

profiles:
  membership:
    quick:
      included: true
      reason: "Synthetic monitoring is essential for proactive detection"
    full:
      included: true
      priority: 1

closeout_checklist:
  - id: "synthetic-001"
    item: "Synthetic monitoring configured"
    level: "CRITICAL"
    verification: |
      SYNTH=$(find . -name '*checkly*' -o -name '*synthetic*' 2>/dev/null | wc -l)
      if [ "$SYNTH" -gt 0 ]; then echo "PASS"; else echo "FAIL: No synthetic monitoring"; fi
    expected: "PASS"

  - id: "synthetic-002"
    item: "Critical user journeys covered"
    level: "CRITICAL"
    verification: "manual"
    verification_notes: "Verify login, checkout, search covered by multi-step tests"
    expected: "Confirmed by reviewer"

  - id: "synthetic-003"
    item: "Multiple geographic test locations"
    level: "BLOCKING"
    verification: |
      LOCS=$(grep -rn 'location\|region' --include='*.check.*' --include='*.yaml' . 2>/dev/null | grep -oE '(us-|eu-|ap-)' | sort -u | wc -l)
      if [ "$LOCS" -ge 2 ]; then echo "PASS: $LOCS regions"; else echo "FAIL: Only $LOCS region(s)"; fi
    expected: "PASS"

  - id: "synthetic-004"
    item: "Alerting configured for test failures"
    level: "BLOCKING"
    verification: |
      ALERTS=$(grep -rn 'alert\|notify\|slack\|pagerduty' --include='*.check.*' --include='*.yaml' . 2>/dev/null | wc -l)
      if [ "$ALERTS" -gt 0 ]; then echo "PASS"; else echo "FAIL: No alerting"; fi
    expected: "PASS"

governance:
  applicable_to:
    archetypes: ["all"]

relationships:
  commonly_combined:
    - "performance-efficiency.performance-measurement.production-performance-monitoring"
    - "performance-efficiency.performance-measurement.slo-sli-alignment"
