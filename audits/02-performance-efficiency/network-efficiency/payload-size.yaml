# ============================================================
# AUDIT: Payload Size Audit
# ============================================================

audit:
  id: "performance-efficiency.network-efficiency.payload-size"
  name: "Payload Size Audit"
  version: "1.0.0"
  last_updated: "2026-01-18"
  status: "active"

  category: "performance-efficiency"
  category_number: 2
  subcategory: "network-efficiency"

  tier: "expert"
  estimated_duration: "2 hours"

  completeness: "complete"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "codebase"

  default_profiles:
    - "full"
    - "production"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Analyzes HTTP response payload sizes across API endpoints and static assets
    to identify oversized responses, unnecessary data transfer, and opportunities
    for payload optimization. Examines JSON response structures, image sizes,
    JavaScript bundle sizes, and API data over-fetching patterns.

  why_it_matters: |
    Large payloads directly impact user experience through increased load times,
    especially on mobile networks. Every 100KB increase in page weight adds
    approximately 1 second to load time on 3G connections. Oversized API responses
    waste bandwidth, increase server egress costs, and drain mobile device batteries.
    Studies show 53% of mobile users abandon sites taking longer than 3 seconds to load.

  when_to_run:
    - "Before production deployments"
    - "After adding new API endpoints"
    - "When user complaints about slow loading emerge"
    - "Quarterly performance reviews"

prerequisites:
  required_artifacts:
    - type: "codebase"
      description: "Application source code with API definitions"
    - type: "build_output"
      description: "Production build artifacts for bundle analysis"

  access_requirements:
    - "API endpoint documentation or OpenAPI spec"
    - "Access to running application instance for live testing"
    - "Build system access for bundle analysis"

discovery:
  code_patterns:
    - pattern: "res\\.json\\s*\\("
      type: "regex"
      scope: "source"
      purpose: "Identify JSON response points for payload analysis"
    - pattern: "JSON\\.stringify"
      type: "regex"
      scope: "source"
      purpose: "Find serialization points that may include unnecessary data"
    - pattern: "select\\s+\\*"
      type: "regex"
      scope: "source"
      purpose: "Detect SELECT * queries that may return excessive data"

  file_patterns:
    - glob: "**/dist/**/*.js"
      purpose: "Analyze JavaScript bundle sizes"
    - glob: "**/public/**/*.{jpg,jpeg,png,gif,webp}"
      purpose: "Identify image assets for size optimization"
    - glob: "**/api/**/*.{ts,js}"
      purpose: "Locate API endpoint definitions"

knowledge_sources:
  specifications:
    - id: "http-cache"
      name: "RFC 7234 - HTTP/1.1 Caching"
      url: "https://datatracker.ietf.org/doc/html/rfc7234"
      offline_cache: true
      priority: "recommended"

  guides:
    - id: "web-vitals"
      name: "Google Web Vitals"
      url: "https://web.dev/vitals/"
      offline_cache: true
    - id: "lighthouse-perf"
      name: "Lighthouse Performance Audits"
      url: "https://developer.chrome.com/docs/lighthouse/performance/"
      offline_cache: true

  learning_resources:
    - id: "high-perf-browser"
      title: "High Performance Browser Networking"
      type: "book"
      reference: "O'Reilly, Ilya Grigorik"

tooling:
  static_analysis:
    - tool: "webpack-bundle-analyzer"
      purpose: "Visualize JavaScript bundle composition and sizes"
      offline_capable: true
    - tool: "source-map-explorer"
      purpose: "Analyze bundle sizes with source map support"
      offline_capable: true

  infrastructure_tools:
    - tool: "curl"
      purpose: "Measure actual response sizes from endpoints"
      command: "curl -s -o /dev/null -w '%{size_download}' https://api.example.com/endpoint"
    - tool: "gzip"
      purpose: "Test compression ratios"
      command: "curl -s https://api.example.com/endpoint | gzip -c | wc -c"

  scripts:
    - id: "payload-analyzer"
      language: "bash"
      purpose: "Analyze payload sizes across endpoints"
      source: "inline"
      code: |
        #!/bin/bash
        # Analyze API response sizes
        ENDPOINTS_FILE="${1:-endpoints.txt}"
        while IFS= read -r endpoint; do
          SIZE=$(curl -s -o /dev/null -w '%{size_download}' "$endpoint")
          GZIP_SIZE=$(curl -s "$endpoint" | gzip -c | wc -c)
          echo "$endpoint: raw=${SIZE}B, gzipped=${GZIP_SIZE}B"
        done < "$ENDPOINTS_FILE"

signals:
  critical:
    - id: "PAYLOAD-CRIT-001"
      signal: "API response exceeds 1MB uncompressed"
      evidence_pattern: "curl response size > 1048576 bytes"
      explanation: |
        Responses over 1MB indicate severe over-fetching or improper API design.
        This causes timeouts on slow connections, excessive memory usage on mobile
        devices, and potential browser crashes. Most API responses should be under
        100KB; anything over 1MB suggests pagination or filtering is missing.
      remediation: "Implement pagination, field selection (GraphQL-style), or split into multiple endpoints"

    - id: "PAYLOAD-CRIT-002"
      signal: "JavaScript bundle exceeds 500KB gzipped"
      evidence_pattern: "bundle.*.js gzip size > 512000 bytes"
      explanation: |
        JavaScript bundles over 500KB gzipped take 10+ seconds to parse on mid-range
        mobile devices. This causes significant Time to Interactive (TTI) delays
        and poor Core Web Vitals scores. Google recommends keeping JS under 300KB.
      remediation: "Implement code splitting, lazy loading, and tree shaking. Remove unused dependencies."

  high:
    - id: "PAYLOAD-HIGH-001"
      signal: "Images served without optimization (>500KB)"
      evidence_pattern: "image file size > 512000 bytes"
      explanation: |
        Unoptimized images are the largest contributor to page weight. Images over
        500KB should almost always be compressed, resized, or converted to modern
        formats like WebP or AVIF.
      remediation: "Implement image optimization pipeline with WebP conversion and responsive sizing"

    - id: "PAYLOAD-HIGH-002"
      signal: "API returns full entity when partial data requested"
      evidence_pattern: "SELECT * patterns or full object returns in API handlers"
      explanation: |
        Returning complete database records when clients only need subset of fields
        wastes bandwidth and exposes unnecessary data. This violates the principle
        of minimal data exposure and increases attack surface.
      remediation: "Implement field selection, DTOs, or GraphQL for flexible data fetching"

  medium:
    - id: "PAYLOAD-MED-001"
      signal: "No Content-Length header on responses"
      evidence_pattern: "Missing Content-Length in response headers"
      remediation: "Ensure server sets Content-Length for all non-chunked responses"

    - id: "PAYLOAD-MED-002"
      signal: "Inline base64 images in HTML/CSS exceed 10KB"
      evidence_pattern: "data:image/.*base64 strings > 10KB"
      remediation: "Move large base64 images to external files for better caching"

  low:
    - id: "PAYLOAD-LOW-001"
      signal: "JSON responses include formatting whitespace"

  positive:
    - id: "PAYLOAD-POS-001"
      signal: "Pagination implemented for list endpoints with default limits"
    - id: "PAYLOAD-POS-002"
      signal: "Field selection available via query parameters or GraphQL"

procedure:
  context:
    cognitive_mode: "critical"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Identify API Endpoints"
      description: |
        Catalog all API endpoints in the application by examining route
        definitions, OpenAPI specs, or controller files. Create a list
        of endpoints to test for payload sizes.
      duration_estimate: "20 min"

      commands:
        - purpose: "Find Express/Fastify route definitions"
          command: "grep -rn 'router\\.(get\\|post\\|put\\|patch)\\|app\\.(get\\|post)' --include='*.ts' --include='*.js' src/"
        - purpose: "Find OpenAPI spec if available"
          command: "find . -name 'openapi*.yaml' -o -name 'swagger*.json' 2>/dev/null"

      expected_findings:
        - "Complete list of API endpoints"
        - "Route patterns and their handlers"

    - id: "2"
      name: "Measure Response Sizes"
      description: |
        For each identified endpoint, measure the actual response size
        using curl or similar tools. Record both raw and gzipped sizes
        to understand compression effectiveness.
      duration_estimate: "30 min"

      commands:
        - purpose: "Measure response size with timing"
          command: "curl -w 'size:%{size_download} time:%{time_total}s\n' -o /dev/null -s $ENDPOINT"
        - purpose: "Check Content-Length header"
          command: "curl -sI $ENDPOINT | grep -i content-length"

      expected_findings:
        - "Actual payload sizes for each endpoint"
        - "Compression ratios"
        - "Response times correlated with size"

    - id: "3"
      name: "Analyze JavaScript Bundles"
      description: |
        Run bundle analysis tools to identify oversized JavaScript bundles,
        duplicate dependencies, and opportunities for code splitting.
      duration_estimate: "25 min"

      commands:
        - purpose: "Check total JS bundle size"
          command: "find dist -name '*.js' -exec du -ch {} + | tail -1"
        - purpose: "List largest JS files"
          command: "find dist -name '*.js' -exec ls -lhS {} + | head -20"

      expected_findings:
        - "Total JavaScript payload size"
        - "Largest individual bundles"
        - "Potential code splitting candidates"

    - id: "4"
      name: "Audit Image Assets"
      description: |
        Scan static assets for unoptimized images and opportunities
        for format conversion to WebP/AVIF.
      duration_estimate: "20 min"

      commands:
        - purpose: "Find large images"
          command: "find public -type f \\( -name '*.jpg' -o -name '*.png' \\) -size +500k -exec ls -lh {} +"
        - purpose: "Check for WebP usage"
          command: "find . -name '*.webp' | wc -l"

      expected_findings:
        - "List of oversized images"
        - "Modern format adoption status"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Payload Size Analysis"
        - "Bundle Analysis"
        - "Image Optimization Opportunities"
        - "Recommendations"

  confidence_guidance:
    high: "Direct size measurements from curl and file system"
    medium: "Estimated savings from optimization tools"
    low: "Projected user experience improvements"

offline:
  capability: "partial"

  cache_manifest:
    knowledge:
      - source_id: "web-vitals"
        priority: "recommended"

profiles:
  membership:
    quick:
      included: false
      reason: "Requires runtime access and comprehensive endpoint testing"
    full:
      included: true
      priority: 1

closeout_checklist:
  - id: "payload-size-001"
    item: "No API response exceeds 1MB uncompressed"
    level: "CRITICAL"
    verification: |
      for endpoint in $(cat endpoints.txt); do
        SIZE=$(curl -s -o /dev/null -w '%{size_download}' "$endpoint")
        if [ "$SIZE" -gt 1048576 ]; then echo "FAIL: $endpoint ($SIZE bytes)"; exit 1; fi
      done && echo "PASS"
    expected: "PASS"

  - id: "payload-size-002"
    item: "JavaScript bundle under 500KB gzipped"
    level: "CRITICAL"
    verification: |
      MAX_SIZE=512000
      TOTAL=$(find dist -name '*.js' -exec cat {} + | gzip -c | wc -c)
      if [ "$TOTAL" -gt "$MAX_SIZE" ]; then echo "FAIL: ${TOTAL} bytes"; else echo "PASS"; fi
    expected: "PASS"

  - id: "payload-size-003"
    item: "No images over 500KB without optimization justification"
    level: "BLOCKING"
    verification: |
      LARGE=$(find public -type f \( -name '*.jpg' -o -name '*.png' \) -size +500k | wc -l)
      if [ "$LARGE" -gt 0 ]; then echo "FAIL: $LARGE oversized images"; else echo "PASS"; fi
    expected: "PASS"

governance:
  applicable_to:
    archetypes: ["all"]

  compliance_frameworks:
    - framework: "WCAG 2.1"
      controls: ["1.4.10"]

relationships:
  commonly_combined:
    - "performance-efficiency.network-efficiency.compression-effectiveness"
    - "performance-efficiency.frontend-performance.bundle-size"
