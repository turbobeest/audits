audit:
  id: developer-experience.testing-experience.test-data-management
  name: Test Data Management Audit
  version: 1.0.0
  last_updated: '2025-01-22'
  status: active
  category: developer-experience
  category_number: 35
  subcategory: testing-experience
  tier: expert
  estimated_duration: 2-3 hours  # median: 2h
  completeness: requires_discovery
  requires_runtime: true
  destructive: false
execution:
  automatable: partial
  severity: medium
  scope: development
  default_profiles:
  - full
  - quick
  blocks_phase: false
  parallelizable: true
description:
  what: |
    Evaluates how test data is created, managed, and isolated in the test
    suite. Assesses factories, fixtures, mocking strategies, and database
    state management. Reviews how developers create test scenarios and
    ensure test isolation.
  why_it_matters: |
    Good test data management enables reliable, maintainable tests. Poor
    management leads to flaky tests, test pollution, and difficulty creating
    specific scenarios. Easy test data creation encourages comprehensive
    testing of edge cases.
  when_to_run:
  - When tests become flaky
  - When test data creation is difficult
  - After database schema changes
  - Quarterly test health review
prerequisites:
  required_artifacts:
  - type: test_suite
    description: Existing test suite
  - type: test_utilities
    description: Factory/fixture configuration
  access_requirements:
  - Test suite access
  - Database access
  - Factory configuration
discovery:
  file_patterns:
  - glob: '**/factories/**'
    purpose: Find factory files
  - glob: '**/fixtures/**'
    purpose: Find fixture files
  - glob: '**/__mocks__/**'
    purpose: Find mock files
  - glob: '**/test-utils/**'
    purpose: Find test utilities
  - glob: '**/conftest.py'
    purpose: Find pytest fixtures
  interview_questions:
  - role: Developer
    questions:
    - How do you create test data?
    - Are tests isolated from each other?
    - How do you create specific scenarios?
    - Do you experience test pollution?
knowledge_sources:
  guides:
  - id: factory-bot
    name: Factory Bot Getting Started
    url: https://github.com/thoughtbot/factory_bot
  - id: fishery
    name: Fishery TypeScript Factories
    url: https://github.com/thoughtbot/fishery
  standards:
  - id: test-isolation
    name: Test Isolation Principles
    relevance: Preventing test pollution
tooling:
  analysis_tools:
  - tool: fishery
    purpose: TypeScript test factories
  - tool: factory-bot
    purpose: Ruby test factories
  - tool: faker
    purpose: Generate realistic test data
    command: npm install @faker-js/faker
  - tool: msw
    purpose: API mocking
    command: npm install msw
signals:
  critical:
  - id: TESTDATA-CRIT-001
    signal: Tests share mutable state
    evidence_indicators:
    - Tests fail when run in different order
    - Flaky tests due to pollution
    - Global state modifications
    explanation: |
      Shared mutable state causes unpredictable failures
      and makes tests unreliable.
    remediation: |
      Isolate each test with fresh state. Use proper
      setup/teardown. Reset database between tests.
  - id: TESTDATA-CRIT-002
    signal: No test data creation utilities
    evidence_indicators:
    - Raw object literals everywhere
    - Duplicated data setup
    - Inconsistent test objects
    explanation: |
      Without factories, test data is verbose, inconsistent,
      and hard to maintain.
    remediation: |
      Implement factories using fishery, factory-bot, or
      similar for consistent test data creation.
  high:
  - id: TESTDATA-HIGH-001
    signal: Database not reset between tests
    remediation: |
      Implement database cleanup or transactions that
      rollback after each test.
  - id: TESTDATA-HIGH-002
    signal: Mocking strategy inconsistent
    remediation: |
      Standardize mocking approach across test suite.
      Document when to mock vs use real implementations.
  - id: TESTDATA-HIGH-003
    signal: Hard to create edge case data
    remediation: |
      Enhance factories with traits or variations
      for common edge cases.
  medium:
  - id: TESTDATA-MED-001
    signal: Fixture data hard to understand
    remediation: |
      Use factories that build data with clear intent.
      Document fixture purposes.
  - id: TESTDATA-MED-002
    signal: API mocking inconsistent
    remediation: |
      Use MSW or similar for consistent API mocking
      across tests.
  - id: TESTDATA-MED-003
    signal: Test data utilities not documented
    remediation: |
      Document available factories, fixtures, and
      test utilities.
  low:
  - id: TESTDATA-LOW-001
    signal: No fake data generation
    remediation: |
      Use faker for realistic test data instead
      of hardcoded values.
  - id: TESTDATA-LOW-002
    signal: Factory traits not utilized
    remediation: |
      Add traits to factories for common variations.
  positive:
  - id: TESTDATA-POS-001
    signal: Comprehensive factory library
  - id: TESTDATA-POS-002
    signal: Complete test isolation
  - id: TESTDATA-POS-003
    signal: Consistent mocking strategy
  - id: TESTDATA-POS-004
    signal: Easy creation of edge cases
procedure:
  context:
    cognitive_mode: evaluative
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Inventory Data Utilities
    description: Find all factories, fixtures, and mocks
    duration_estimate: 30 min
  - id: '2'
    name: Assess Test Isolation
    description: Check for state sharing between tests
    duration_estimate: 30 min
  - id: '3'
    name: Evaluate Factory Coverage
    description: Review factory completeness and usability
    duration_estimate: 30 min
  - id: '4'
    name: Check Mocking Strategy
    description: Review API and dependency mocking
    duration_estimate: 30 min
  - id: '5'
    name: Gather Developer Feedback
    description: Interview developers about test data experience
    duration_estimate: 30 min
output:
  deliverables:
  - type: test_data_assessment
    format: structured
    sections:
    - Utility inventory
    - Isolation assessment
    - Factory evaluation
    - Developer feedback
  - type: finding_list
    format: structured
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Test Data Management Review
    - Recommendations
closeout_checklist:
- id: testdata-001
  item: Data utilities inventoried
  level: ERROR
  verification: manual
- id: testdata-002
  item: Test isolation assessed
  level: ERROR
  verification: manual
- id: testdata-003
  item: Developer feedback collected
  level: WARNING
  verification: manual
governance:
  applicable_to:
    archetypes:
    - all-software-projects
  compliance_mappings:
  - framework: ISO 27001
    control: A.14.3.1
    description: Protection of test data
relationships:
  commonly_combined:
  - developer-experience.local-development.local-data-seeding
  - developer-experience.testing-experience.test-execution-speed
  depends_on:
  - devops-ci-cd.test-automation
  feeds_into:
  - code-quality.test-coverage
