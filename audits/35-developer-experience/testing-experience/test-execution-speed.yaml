audit:
  id: developer-experience.testing-experience.test-execution-speed
  name: Test Execution Speed Audit
  version: 1.0.0
  last_updated: '2025-01-22'
  status: active
  category: developer-experience
  category_number: 35
  subcategory: testing-experience
  tier: expert
  estimated_duration: 2-3 hours  # median: 2h
  completeness: requires_discovery
  requires_runtime: true
  destructive: false
execution:
  automatable: partial
  severity: medium
  scope: development
  default_profiles:
  - full
  - quick
  blocks_phase: false
  parallelizable: true
description:
  what: |
    Evaluates the speed of running tests locally and in CI, measuring
    full suite runtime, individual test speed, and time to feedback.
    Identifies slow tests, parallelization opportunities, and
    configuration issues that impact test execution time.
  why_it_matters: |
    Fast tests encourage developers to run them frequently, catching
    issues early. Slow tests get skipped or batched, leading to delayed
    feedback and larger debugging sessions. DORA research shows that
    test speed directly impacts deployment frequency.
  when_to_run:
  - When test suite becomes slow
  - Before major test infrastructure changes
  - Quarterly performance baseline
  - When developers stop running tests locally
prerequisites:
  required_artifacts:
  - type: test_suite
    description: Existing test suite
  - type: test_configuration
    description: Test runner configuration
  - type: ci_configuration
    description: CI test configuration
  access_requirements:
  - Test suite access
  - CI platform access
  - Test metrics access
discovery:
  file_patterns:
  - glob: '**/jest.config.{js,ts}'
    purpose: Find Jest configuration
  - glob: '**/vitest.config.{js,ts}'
    purpose: Find Vitest configuration
  - glob: '**/pytest.ini'
    purpose: Find pytest configuration
  - glob: '**/conftest.py'
    purpose: Find pytest fixtures
  - glob: '**/*.test.{js,ts,tsx}'
    purpose: Find test files
  - glob: '**/*.spec.{js,ts,tsx}'
    purpose: Find spec files
  interview_questions:
  - role: Developer
    questions:
    - How long does the full test suite take?
    - Do you run tests before every commit?
    - Which tests are slowest?
    - Do you skip tests due to time?
knowledge_sources:
  guides:
  - id: jest-performance
    name: Jest Performance Tips
    url: https://jestjs.io/docs/troubleshooting
  - id: vitest-performance
    name: Vitest Performance
    url: https://vitest.dev/guide/performance
  standards:
  - id: dora-metrics
    name: DORA Metrics
    relevance: Test speed impact on deployment
tooling:
  analysis_tools:
  - tool: jest
    purpose: JavaScript test runner
    command: jest --verbose --runInBand
  - tool: vitest
    purpose: Fast Vite-native test runner
    command: vitest run --reporter=verbose
  - tool: pytest
    purpose: Python test runner
    command: pytest --durations=10
  - tool: jest-slow-test-reporter
    purpose: Identify slow tests
    command: jest --reporters=jest-slow-test-reporter
signals:
  critical:
  - id: TESTSPEED-CRIT-001
    signal: Full test suite takes more than 15 minutes locally
    evidence_indicators:
    - Developers skip local testing
    - Only run tests in CI
    - Long wait times for feedback
    explanation: |
      Very slow tests break the development feedback loop
      and encourage skipping tests entirely.
    remediation: |
      Identify and optimize slowest tests. Implement test
      parallelization. Consider faster test runner.
  - id: TESTSPEED-CRIT-002
    signal: Individual tests take over 30 seconds
    evidence_indicators:
    - Integration tests without optimization
    - Excessive setup/teardown
    - Real I/O without mocking
    explanation: |
      Single slow tests block other tests and slow the
      entire feedback cycle.
    remediation: |
      Profile slow tests and optimize. Move slow tests
      to separate suite if necessary.
  high:
  - id: TESTSPEED-HIGH-001
    signal: Test suite takes 5-15 minutes locally
    remediation: |
      Enable parallelization, optimize slow tests, and
      consider splitting test suites.
  - id: TESTSPEED-HIGH-002
    signal: CI tests significantly slower than local
    remediation: |
      Optimize CI test environment, add caching, and
      ensure parallelization is configured.
  - id: TESTSPEED-HIGH-003
    signal: No parallelization configured
    remediation: |
      Enable test parallelization with appropriate
      worker count for available cores.
  medium:
  - id: TESTSPEED-MED-001
    signal: Test startup time is slow
    remediation: |
      Optimize test setup, reduce module loading,
      consider faster test runners like Vitest.
  - id: TESTSPEED-MED-002
    signal: Cannot run single test quickly
    remediation: |
      Configure test runner for efficient single
      test execution with caching.
  - id: TESTSPEED-MED-003
    signal: Test speed metrics not tracked
    remediation: |
      Implement test duration tracking to catch
      regressions early.
  low:
  - id: TESTSPEED-LOW-001
    signal: Slow test warnings not configured
    remediation: |
      Add test duration limits to flag slow tests.
  - id: TESTSPEED-LOW-002
    signal: No test performance documentation
    remediation: |
      Document expected test times and optimization tips.
  positive:
  - id: TESTSPEED-POS-001
    signal: Full suite runs in under 2 minutes
  - id: TESTSPEED-POS-002
    signal: Parallelization fully utilized
  - id: TESTSPEED-POS-003
    signal: Slow test tracking and alerts
  - id: TESTSPEED-POS-004
    signal: Single test runs in under 5 seconds
procedure:
  context:
    cognitive_mode: evaluative
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Measure Full Suite Time
    description: Time complete test suite execution
    duration_estimate: 30 min
  - id: '2'
    name: Identify Slow Tests
    description: Find tests taking longest time
    duration_estimate: 30 min
  - id: '3'
    name: Analyze Parallelization
    description: Review parallelization configuration
    duration_estimate: 30 min
  - id: '4'
    name: Compare Local vs CI
    description: Compare test times across environments
    duration_estimate: 30 min
  - id: '5'
    name: Gather Developer Feedback
    description: Interview developers about test speed experience
    duration_estimate: 30 min
output:
  deliverables:
  - type: test_speed_report
    format: structured
    sections:
    - Suite timing measurements
    - Slowest tests identified
    - Parallelization analysis
    - CI comparison
  - type: finding_list
    format: structured
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Performance Analysis
    - Optimization Opportunities
    - Recommendations
closeout_checklist:
- id: testspeed-001
  item: Test suite timed
  level: ERROR
  verification: manual
- id: testspeed-002
  item: Slow tests identified
  level: WARNING
  verification: manual
- id: testspeed-003
  item: Developer feedback collected
  level: WARNING
  verification: manual
governance:
  applicable_to:
    archetypes:
    - all-software-projects
  compliance_mappings:
  - framework: ISO 27001
    control: A.14.2
    description: Security in development
relationships:
  commonly_combined:
  - developer-experience.testing-experience.test-debugging
  - devops-ci-cd.ci-pipeline-performance
  depends_on:
  - devops-ci-cd.test-automation
  feeds_into:
  - developer-experience.productivity-metrics.developer-velocity
