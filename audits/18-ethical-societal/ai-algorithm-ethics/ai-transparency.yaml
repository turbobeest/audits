# ============================================================
# AUDIT: AI Transparency
# ============================================================
# Evaluates transparency practices for AI systems including
# disclosure, documentation, and stakeholder communication.

audit:
  id: "ethical-societal.ai-algorithm-ethics.ai-transparency"

  name: "AI Transparency"

  version: "1.0.0"
  last_updated: "2026-01-19"
  status: "active"

  category: "ethical-societal"
  category_number: 18
  subcategory: "ai-algorithm-ethics"

  tier: "expert"
  estimated_duration: "3-5 hours"  # median: 4h

  completeness: "requires_discovery"
  requires_runtime: false
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "documentation"

  default_profiles:
    - "full"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Evaluates AI system transparency including disclosure of AI use to affected
    parties, documentation of system capabilities and limitations, communication
    of decision logic, and organizational accountability structures. Covers both
    technical transparency (how systems work) and procedural transparency (how
    organizations govern AI).

  why_it_matters: |
    Transparency is foundational to AI accountability and trust. Users have the
    right to know when AI affects them and how decisions are made. Regulators
    increasingly require AI transparency (EU AI Act Article 52, CCPA automated
    decision rights). Lack of transparency erodes public trust and exposes
    organizations to regulatory penalties and litigation.

  when_to_run:
    - "Before deploying customer-facing AI systems"
    - "When AI transparency regulations take effect"
    - "During annual AI governance reviews"
    - "Following AI incidents or complaints about opacity"

prerequisites:
  required_artifacts:
    - type: "ai_inventory"
      description: "Registry of AI systems in deployment"
    - type: "documentation"
      description: "System documentation, model cards, and user-facing disclosures"

  access_requirements:
    - "Access to AI system documentation"
    - "User-facing interfaces and disclosures"
    - "Governance policies and procedures"

discovery:
  code_patterns:
    - pattern: "(disclosure|transparency|notification|ai_notice)"
      type: "regex"
      scope: "source"
      purpose: "Find AI disclosure implementations"
    - pattern: "(model_card|system_card|data_sheet)"
      type: "regex"
      scope: "docs"
      purpose: "Locate model documentation"

  file_patterns:
    - glob: "**/docs/*ai*"
      purpose: "Find AI documentation"
    - glob: "**/*model_card*"
      purpose: "Locate model cards"
    - glob: "**/legal/*disclosure*"
      purpose: "Find legal disclosures"

  documents_to_review:
    - type: "Model cards and system cards"
      purpose: "Evaluate technical documentation completeness"
    - type: "User-facing AI disclosures"
      purpose: "Assess transparency to affected parties"
    - type: "AI governance policies"
      purpose: "Review organizational transparency commitments"

knowledge_sources:
  specifications:
    - id: "cisa-ai-security"
      name: "CISA Guidelines for Secure AI System Development"
      url: "https://www.cisa.gov/resources-tools/resources/guidelines-secure-ai-system-development"
      offline_cache: true
      priority: "recommended"
    - id: "eu-ai-act-art52"
      name: "EU AI Act Article 52 - Transparency Obligations"
      url: "https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206"
      offline_cache: true
      priority: "required"
    - id: "ieee-7001"
      name: "IEEE 7001-2021 Transparency of Autonomous Systems"
      url: "https://standards.ieee.org/standard/7001-2021.html"
      offline_cache: true
      priority: "recommended"

  guides:
    - id: "model-cards"
      name: "Model Cards for Model Reporting"
      url: "https://arxiv.org/abs/1810.03993"
      offline_cache: true
    - id: "system-cards"
      name: "System Cards: A Framework for AI Governance"
      url: "https://partnershiponai.org/paper/system-cards/"
      offline_cache: true

tooling:
  assessment_tools:
    - tool: "Transparency checklist"
      purpose: "Structured evaluation of transparency requirements"

  scripts:
    - id: "disclosure-finder"
      language: "bash"
      purpose: "Find AI disclosure elements in codebase"
      source: "inline"
      code: |
        #!/bin/bash
        # Find AI disclosure implementations
        echo "=== AI Disclosure Patterns ==="
        grep -r -i "ai.*disclosure\|machine.learning.*notice\|automated.*decision" \
          --include="*.html" --include="*.tsx" --include="*.jsx" . 2>/dev/null

        echo "=== Model Cards ==="
        find . -name "*model_card*" -o -name "*MODEL_CARD*" 2>/dev/null

signals:
  critical:
    - id: "TRANS-CRIT-001"
      signal: "No disclosure of AI use to affected individuals"
      evidence_indicators:
        - "AI makes decisions affecting users"
        - "No notification that AI is involved"
        - "Users believe they are interacting with humans"
      explanation: |
        EU AI Act requires disclosure when AI interacts with individuals or
        makes decisions about them. Hidden AI use violates user autonomy and
        may constitute deceptive practice under consumer protection law.
      remediation: "Implement clear AI disclosure in user interfaces"

    - id: "TRANS-CRIT-002"
      signal: "AI-generated content not labeled"
      evidence_indicators:
        - "AI generates text, images, or media"
        - "No disclosure that content is AI-generated"
      explanation: |
        EU AI Act Article 52 requires labeling of AI-generated content.
        Unlabeled synthetic content enables misinformation and fraud.
      remediation: "Implement AI content labeling (visible metadata and watermarks)"

  high:
    - id: "TRANS-HIGH-001"
      signal: "No model cards or system documentation"
      explanation: "Technical documentation essential for oversight and accountability"
      remediation: "Create model cards following standard frameworks"

    - id: "TRANS-HIGH-002"
      signal: "AI capabilities overstated or limitations hidden"
      explanation: "Misleading capability claims create unrealistic expectations and harm"
      remediation: "Document limitations prominently alongside capabilities"

  medium:
    - id: "TRANS-MED-001"
      signal: "No AI system registry maintained"
      remediation: "Create and maintain organizational AI inventory"

    - id: "TRANS-MED-002"
      signal: "Technical documentation not accessible to non-experts"
      remediation: "Create layered documentation for different audiences"

  low:
    - id: "TRANS-LOW-001"
      signal: "AI governance policies not published externally"
      remediation: "Consider publishing AI principles and governance framework"

  positive:
    - id: "TRANS-POS-001"
      signal: "Clear AI disclosure in all user interfaces"
    - id: "TRANS-POS-002"
      signal: "Comprehensive model cards for all deployed models"
    - id: "TRANS-POS-003"
      signal: "Public AI transparency report published"

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Inventory AI systems"
      description: |
        Create or verify inventory of AI systems requiring transparency
        measures. Classify by risk level and transparency requirements.
      duration_estimate: "45 min"
      questions:
        - "What AI systems are deployed?"
        - "Which systems interact directly with individuals?"
        - "Which systems make decisions about individuals?"
      expected_findings:
        - "Complete AI system inventory"
        - "Risk classification for transparency"

    - id: "2"
      name: "Evaluate user-facing disclosures"
      description: |
        Review all user-facing interfaces for AI disclosure compliance.
        Verify users are informed when AI is involved.
      duration_estimate: "60 min"
      commands:
        - purpose: "Find AI disclosure UI elements"
          command: "grep -r -i 'ai\\|artificial.intelligence\\|machine.learning\\|automated' --include='*.tsx' --include='*.jsx' --include='*.html' ."
      expected_findings:
        - "AI disclosure implementation status"
        - "Gaps in user notification"

    - id: "3"
      name: "Review technical documentation"
      description: |
        Evaluate model cards, system cards, and technical documentation
        for completeness and accuracy.
      duration_estimate: "60 min"
      expected_findings:
        - "Documentation completeness assessment"
        - "Missing documentation elements"

    - id: "4"
      name: "Assess organizational transparency"
      description: |
        Review AI governance policies, accountability structures, and
        external transparency commitments.
      duration_estimate: "45 min"
      questions:
        - "Are AI governance policies documented?"
        - "Is there clear accountability for AI systems?"
        - "What external transparency commitments exist?"
      expected_findings:
        - "Governance transparency status"
        - "Accountability gaps"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "transparency_assessment"
      format: "structured"
      sections:
        - "AI System Inventory"
        - "Disclosure Compliance"
        - "Documentation Review"
        - "Governance Assessment"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Regulatory Compliance Status"
        - "Recommendations"

  confidence_guidance:
    high: "Complete system inventory and disclosure review"
    medium: "Representative sample evaluated"
    low: "Limited access to systems or documentation"

offline:
  capability: "full"

  cache_manifest:
    knowledge:
      - source_id: "eu-ai-act-art52"
        priority: "required"
      - source_id: "model-cards"
        priority: "recommended"

profiles:
  membership:
    quick:
      included: false
      reason: "Requires comprehensive documentation review"
    full:
      included: true
      priority: 2

closeout_checklist:
  - id: "trans-001"
    item: "AI system inventory complete"
    level: "CRITICAL"
    verification: "manual"
    verification_notes: "All AI systems catalogued with risk classification"
    expected: "Confirmed by reviewer"

  - id: "trans-002"
    item: "User-facing AI disclosures verified"
    level: "CRITICAL"
    verification: "manual"
    verification_notes: "AI disclosure present in all required interfaces"
    expected: "Confirmed by reviewer"

  - id: "trans-003"
    item: "Model cards exist for deployed models"
    level: "BLOCKING"
    verification: "find . -name '*model_card*' | wc -l | xargs -I{} test {} -gt 0 && echo PASS || echo FAIL"
    expected: "PASS"

governance:
  applicable_to:
    archetypes: ["ai-ml-systems", "consumer-facing", "regulated"]

  compliance_frameworks:
    - framework: "EU AI Act"
      controls: ["Article 52"]
    - framework: "IEEE 7001"
      controls: ["Transparency Levels"]

relationships:
  commonly_combined:
    - "ethical-societal.ai-algorithm-ethics.explainability"
    - "ethical-societal.ai-algorithm-ethics.human-oversight"
