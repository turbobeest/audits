# ============================================================
# AUDIT: Automated Decision Impact
# ============================================================
# Evaluates the impact of automated decision-making systems
# on individuals and ensures appropriate safeguards.

audit:
  id: "ethical-societal.ai-algorithm-ethics.automated-decision-impact"

  name: "Automated Decision Impact"

  version: "1.0.0"
  last_updated: "2026-01-19"
  status: "active"

  category: "ethical-societal"
  category_number: 18
  subcategory: "ai-algorithm-ethics"

  tier: "expert"
  estimated_duration: "4-6 hours"  # median: 5h

  completeness: "requires_discovery"
  requires_runtime: false
  destructive: false

execution:
  automatable: "partial"
  severity: "critical"
  scope: "process"

  default_profiles:
    - "full"
    - "security"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Assesses automated decision-making (ADM) systems for their impact on
    individuals' rights, opportunities, and wellbeing. Evaluates decision
    significance, affected populations, potential harms, and safeguards
    including human review and appeal processes. Conducts algorithmic impact
    assessments for high-stakes decisions.

  why_it_matters: |
    Automated decisions can significantly impact individuals' access to credit,
    employment, housing, healthcare, and justice. GDPR Article 22 restricts
    solely automated decisions with significant effects. EU AI Act classifies
    certain ADM systems as high-risk requiring extensive safeguards. Impact
    assessment ensures proportionate protection and enables informed governance.

  when_to_run:
    - "Before deploying any ADM system affecting individuals"
    - "When expanding ADM scope or affected populations"
    - "During regulatory compliance assessments"
    - "Following complaints about ADM outcomes"

prerequisites:
  required_artifacts:
    - type: "system_documentation"
      description: "ADM system purpose, scope, and design documentation"
    - type: "decision_records"
      description: "Sample automated decisions and outcomes"

  access_requirements:
    - "System design documentation"
    - "Decision outcome data"
    - "Stakeholder interview access"

discovery:
  code_patterns:
    - pattern: "(decision|approve|reject|deny|score|rank|classify)"
      type: "regex"
      scope: "source"
      purpose: "Identify decision points in code"
    - pattern: "(automated|automatic|auto_decision|no_human)"
      type: "regex"
      scope: "source"
      purpose: "Find automation flags"

  file_patterns:
    - glob: "**/decision*"
      purpose: "Find decision-making modules"
    - glob: "**/scoring*"
      purpose: "Locate scoring systems"

  interviews:
    - role: "Product owners and business analysts"
      questions:
        - "What decisions does this system make?"
        - "Who is affected by these decisions?"
        - "What are the consequences of incorrect decisions?"
      purpose: "Understand decision scope and impact"
    - role: "Affected stakeholders or representatives"
      questions:
        - "How do you learn about decisions made about you?"
        - "Do you understand why decisions are made?"
        - "Can you challenge decisions?"
      purpose: "Assess stakeholder experience"

  documents_to_review:
    - type: "Impact assessments"
      purpose: "Review existing impact analysis"
    - type: "Appeal and review procedures"
      purpose: "Assess recourse mechanisms"

knowledge_sources:
  specifications:
    - id: "cisa-ai-security"
      name: "CISA Guidelines for Secure AI System Development"
      url: "https://www.cisa.gov/resources-tools/resources/guidelines-secure-ai-system-development"
      offline_cache: true
      priority: "recommended"
    - id: "gdpr-art22"
      name: "GDPR Article 22 - Automated Individual Decision-Making"
      url: "https://gdpr-info.eu/art-22-gdpr/"
      offline_cache: true
      priority: "required"
    - id: "eu-ai-act"
      name: "EU AI Act High-Risk AI Requirements"
      url: "https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206"
      offline_cache: true
      priority: "required"

  guides:
    - id: "ada-aia"
      name: "Algorithmic Impact Assessment Framework"
      url: "https://ainowinstitute.org/aiareport2018.html"
      offline_cache: true
    - id: "canada-directive"
      name: "Canada Directive on Automated Decision-Making"
      url: "https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=32592"
      offline_cache: true

tooling:
  assessment_tools:
    - tool: "Algorithmic Impact Assessment template"
      purpose: "Structured framework for impact evaluation"
    - tool: "Stakeholder impact mapping"
      purpose: "Identify and categorize affected populations"

  scripts:
    - id: "decision-finder"
      language: "bash"
      purpose: "Find automated decision points in codebase"
      source: "inline"
      code: |
        #!/bin/bash
        echo "=== Automated Decision Points ==="
        grep -r -E "(auto_decision|automated.*decision|no.*human.*review)" \
          --include="*.py" --include="*.java" --include="*.ts" . 2>/dev/null

        echo "=== Decision Functions ==="
        grep -r -E "def.*(approve|reject|deny|score|classify)" \
          --include="*.py" . 2>/dev/null

signals:
  critical:
    - id: "ADI-CRIT-001"
      signal: "High-impact decisions made without human review option"
      evidence_indicators:
        - "Decisions affect employment, credit, housing, or similar"
        - "No human review mechanism exists"
        - "No appeal process available"
      explanation: |
        GDPR Article 22 provides right not to be subject to solely automated
        decisions with significant effects. High-impact decisions without
        human review may violate data protection law and deny due process.
      remediation: "Implement human review mechanism for high-impact decisions"

    - id: "ADI-CRIT-002"
      signal: "No impact assessment conducted for high-risk ADM"
      evidence_indicators:
        - "System makes significant decisions about individuals"
        - "No documented impact assessment"
      explanation: |
        High-risk AI systems require documented impact assessment under
        EU AI Act. Absence of assessment indicates inadequate risk governance.
      remediation: "Conduct and document algorithmic impact assessment"

  high:
    - id: "ADI-HIGH-001"
      signal: "Decision recipients not informed of automation"
      explanation: "Individuals have right to know when affected by automated decisions"
      remediation: "Implement clear notification of automated decision-making"

    - id: "ADI-HIGH-002"
      signal: "No meaningful appeal or recourse process"
      explanation: "Affected individuals must be able to challenge incorrect decisions"
      remediation: "Establish accessible appeal process with human review"

  medium:
    - id: "ADI-MED-001"
      signal: "Impact disproportionately affects vulnerable populations"
      remediation: "Implement additional safeguards for vulnerable groups"

    - id: "ADI-MED-002"
      signal: "Decision audit trail incomplete"
      remediation: "Ensure complete logging of decision inputs, logic, and outcomes"

  low:
    - id: "ADI-LOW-001"
      signal: "Impact assessment not periodically reviewed"
      remediation: "Establish regular impact assessment review cycle"

  positive:
    - id: "ADI-POS-001"
      signal: "Comprehensive algorithmic impact assessment completed"
    - id: "ADI-POS-002"
      signal: "Human-in-the-loop for all high-impact decisions"

procedure:
  context:
    cognitive_mode: "critical"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Map automated decision points"
      description: |
        Identify all automated decision points in the system. Document
        decision types, affected populations, and decision consequences.
      duration_estimate: "60 min"
      commands:
        - purpose: "Find decision functions in code"
          command: "grep -r -E '(decide|approve|reject|classify|score)' --include='*.py' --include='*.ts' ."
      questions:
        - "What automated decisions does this system make?"
        - "Who is affected by each decision?"
        - "What are the consequences of each decision type?"
      expected_findings:
        - "Complete decision inventory"
        - "Affected population mapping"

    - id: "2"
      name: "Classify decision impact levels"
      description: |
        Assess the significance and impact level of each decision type.
        Classify as high, medium, or low impact based on consequences.
      duration_estimate: "45 min"
      questions:
        - "Does this decision affect employment, credit, housing, healthcare, or similar?"
        - "Can incorrect decisions cause significant harm?"
        - "Are vulnerable populations disproportionately affected?"
      expected_findings:
        - "Impact classification for each decision"
        - "High-risk decision identification"

    - id: "3"
      name: "Evaluate safeguards"
      description: |
        Assess safeguards for high-impact decisions including human review,
        appeal processes, and error correction mechanisms.
      duration_estimate: "60 min"
      questions:
        - "Is human review available for automated decisions?"
        - "Can individuals appeal or challenge decisions?"
        - "How are errors identified and corrected?"
      expected_findings:
        - "Safeguard adequacy assessment"
        - "Gaps in protection mechanisms"

    - id: "4"
      name: "Review stakeholder communication"
      description: |
        Evaluate how affected individuals are informed about automated
        decisions and their rights to review and appeal.
      duration_estimate: "45 min"
      expected_findings:
        - "Communication adequacy assessment"
        - "Information accessibility evaluation"

    - id: "5"
      name: "Conduct impact assessment"
      description: |
        Complete algorithmic impact assessment documenting potential harms,
        mitigations, and ongoing monitoring requirements.
      duration_estimate: "90 min"
      expected_findings:
        - "Comprehensive impact assessment"
        - "Risk mitigation recommendations"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "impact_assessment"
      format: "structured"
      sections:
        - "Decision Inventory"
        - "Impact Classification"
        - "Affected Populations"
        - "Safeguard Assessment"
        - "Risk Analysis"
        - "Mitigation Recommendations"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Key Findings"
        - "Compliance Status"
        - "Recommendations"

  confidence_guidance:
    high: "Complete decision mapping and stakeholder engagement"
    medium: "Decision mapping complete but limited stakeholder input"
    low: "Based on documentation review only"

offline:
  capability: "full"

  cache_manifest:
    knowledge:
      - source_id: "gdpr-art22"
        priority: "required"
      - source_id: "eu-ai-act"
        priority: "required"

profiles:
  membership:
    quick:
      included: false
      reason: "Requires comprehensive impact assessment"
    full:
      included: true
      priority: 1

closeout_checklist:
  - id: "adi-001"
    item: "All automated decision points identified"
    level: "CRITICAL"
    verification: "manual"
    verification_notes: "Complete inventory of ADM in system"
    expected: "Confirmed by reviewer"

  - id: "adi-002"
    item: "Impact classification completed for all decisions"
    level: "CRITICAL"
    verification: "manual"
    verification_notes: "Each decision classified by impact level"
    expected: "Confirmed by reviewer"

  - id: "adi-003"
    item: "Human review available for high-impact decisions"
    level: "CRITICAL"
    verification: "manual"
    verification_notes: "Verify human-in-the-loop mechanism exists"
    expected: "Confirmed by reviewer"

  - id: "adi-004"
    item: "Algorithmic impact assessment documented"
    level: "BLOCKING"
    verification: "manual"
    verification_notes: "Complete AIA exists for high-risk systems"
    expected: "Confirmed by reviewer"

governance:
  applicable_to:
    archetypes: ["decision-automation", "fintech", "healthcare", "hr-systems"]

  compliance_frameworks:
    - framework: "GDPR"
      controls: ["Article 22"]
    - framework: "EU AI Act"
      controls: ["Annex III - High-Risk AI Systems"]

relationships:
  commonly_combined:
    - "ethical-societal.ai-algorithm-ethics.human-oversight"
    - "ethical-societal.ai-algorithm-ethics.explainability"
    - "ethical-societal.ai-algorithm-ethics.algorithmic-bias-detection"
