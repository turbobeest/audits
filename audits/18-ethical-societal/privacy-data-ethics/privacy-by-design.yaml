# ============================================================
# AUDIT: Privacy by Design
# ============================================================
# Evaluates implementation of privacy by design and by default
# principles throughout the system development lifecycle.

audit:
  id: "ethical-societal.privacy-data-ethics.privacy-by-design"

  name: "Privacy by Design"

  version: "1.0.0"
  last_updated: "2026-01-19"
  status: "active"

  category: "ethical-societal"
  category_number: 18
  subcategory: "privacy-data-ethics"

  tier: "expert"
  estimated_duration: "4-6 hours"  # median: 5h

  completeness: "requires_discovery"
  requires_runtime: false
  destructive: false

execution:
  automatable: "partial"
  severity: "high"
  scope: "architecture"

  default_profiles:
    - "full"
    - "security"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Assesses implementation of Privacy by Design (PbD) principles including
    proactive privacy measures, privacy as default settings, privacy embedded
    in design, full functionality (positive-sum), end-to-end security, visibility
    and transparency, and respect for user privacy. Evaluates architectural
    decisions, development processes, and technical implementations against
    these principles.

  why_it_matters: |
    Privacy by Design is mandated by GDPR Article 25 and represents best practice
    for building privacy-respecting systems. Retrofitting privacy is expensive
    and often incomplete. PbD reduces compliance risk, builds user trust, and
    creates competitive advantage. Organizations that embed privacy in design
    avoid costly remediation and enforcement actions.

  when_to_run:
    - "During system architecture reviews"
    - "Before major releases"
    - "When adding new data processing capabilities"
    - "During privacy program maturity assessments"

prerequisites:
  required_artifacts:
    - type: "architecture_documentation"
      description: "System architecture diagrams and design documents"
    - type: "development_processes"
      description: "SDLC documentation including privacy requirements"

  access_requirements:
    - "Architecture documentation"
    - "Design decision records"
    - "Development process documentation"
    - "Technical implementation access"

discovery:
  code_patterns:
    - pattern: "(encrypt|hash|anonymize|pseudonymize|tokenize)"
      type: "regex"
      scope: "source"
      purpose: "Find privacy-enhancing implementations"
    - pattern: "(privacy|data.?protection|gdpr)"
      type: "regex"
      scope: "config"
      purpose: "Locate privacy configurations"
    - pattern: "(default.*false|opt.?in|disabled.*default)"
      type: "regex"
      scope: "source"
      purpose: "Find privacy-preserving defaults"

  file_patterns:
    - glob: "**/privacy/**"
      purpose: "Find privacy modules"
    - glob: "**/security/**"
      purpose: "Locate security implementations"
    - glob: "**/*encrypt*"
      purpose: "Find encryption implementations"

  documents_to_review:
    - type: "Architecture Decision Records (ADRs)"
      purpose: "Review privacy-related design decisions"
    - type: "Privacy Impact Assessments"
      purpose: "Evaluate privacy risk management"
    - type: "Development guidelines"
      purpose: "Assess privacy requirements in SDLC"

knowledge_sources:
  specifications:
    - id: "gdpr-art25"
      name: "GDPR Article 25 - Data Protection by Design and Default"
      url: "https://gdpr-info.eu/art-25-gdpr/"
      offline_cache: true
      priority: "required"

  guides:
    - id: "pbd-principles"
      name: "Privacy by Design: The 7 Foundational Principles"
      url: "https://www.ipc.on.ca/wp-content/uploads/resources/7foundationalprinciples.pdf"
      offline_cache: true
    - id: "enisa-pbd"
      name: "ENISA Privacy by Design Guidelines"
      url: "https://www.enisa.europa.eu/publications/privacy-and-data-protection-by-design"
      offline_cache: true

  learning_resources:
    - id: "cavoukian-pbd"
      title: "Privacy by Design: The Definitive Workshop"
      type: "article"
      reference: "Ann Cavoukian, Information & Privacy Commissioner of Ontario"

tooling:
  static_analysis:
    - tool: "privacy-linter"
      purpose: "Identify privacy issues in code"
      offline_capable: true

  scripts:
    - id: "pbd-checker"
      language: "bash"
      purpose: "Check for privacy-enhancing implementations"
      source: "inline"
      code: |
        #!/bin/bash
        echo "=== Encryption Usage ==="
        grep -r -E "(encrypt|AES|RSA|bcrypt|argon2)" \
          --include="*.py" --include="*.ts" --include="*.java" . 2>/dev/null | head -20

        echo "=== Anonymization/Pseudonymization ==="
        grep -r -E "(anonymize|pseudonymize|hash|tokenize)" \
          --include="*.py" --include="*.ts" . 2>/dev/null | head -20

        echo "=== Privacy-Preserving Defaults ==="
        grep -r -E "(default.*false|opt.?in|private.*default)" \
          --include="*.py" --include="*.ts" --include="*.yaml" . 2>/dev/null | head -20

signals:
  critical:
    - id: "PBD-CRIT-001"
      signal: "Personal data stored unencrypted"
      evidence_indicators:
        - "PII in plain text in database"
        - "No encryption at rest for sensitive data"
      explanation: |
        GDPR Article 32 requires appropriate security measures including
        encryption. Unencrypted personal data storage fails Privacy by Design
        and creates significant breach risk.
      remediation: "Implement encryption at rest for all personal data"

    - id: "PBD-CRIT-002"
      signal: "Privacy-invasive defaults configured"
      evidence_indicators:
        - "Tracking enabled by default"
        - "Data sharing opt-out rather than opt-in"
        - "Maximum data collection as default"
      explanation: |
        Privacy by Default requires the most privacy-protective settings to be
        applied automatically. Users should not have to take action to protect
        their privacy.
      remediation: "Configure privacy-protective defaults for all settings"

  high:
    - id: "PBD-HIGH-001"
      signal: "No privacy impact assessments in development process"
      explanation: "PbD requires proactive privacy consideration in design"
      remediation: "Integrate privacy impact assessment into development lifecycle"

    - id: "PBD-HIGH-002"
      signal: "Data processed without pseudonymization where possible"
      explanation: "Pseudonymization is a key PbD technique to reduce risk"
      remediation: "Implement pseudonymization for processing where identifiers not required"

  medium:
    - id: "PBD-MED-001"
      signal: "Privacy requirements not in user stories/specifications"
      remediation: "Include privacy requirements in all feature specifications"

    - id: "PBD-MED-002"
      signal: "No privacy-focused code review checklist"
      remediation: "Add privacy criteria to code review process"

  low:
    - id: "PBD-LOW-001"
      signal: "Privacy training not required for developers"
      remediation: "Implement privacy awareness training program"

  positive:
    - id: "PBD-POS-001"
      signal: "Privacy integrated throughout SDLC"
    - id: "PBD-POS-002"
      signal: "Privacy-enhancing technologies deployed"
    - id: "PBD-POS-003"
      signal: "Regular privacy architecture reviews conducted"

procedure:
  context:
    cognitive_mode: "evaluative"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Assess PbD in development process"
      description: |
        Evaluate how privacy is integrated into the software development
        lifecycle including requirements, design, implementation, and testing.
      duration_estimate: "60 min"
      questions:
        - "Are privacy requirements captured in specifications?"
        - "Is privacy impact assessment part of design review?"
        - "Do code reviews include privacy criteria?"
        - "Is privacy included in testing?"
      expected_findings:
        - "SDLC privacy integration assessment"
        - "Process gaps identified"

    - id: "2"
      name: "Evaluate privacy architecture"
      description: |
        Review system architecture for privacy-enhancing design including
        data minimization, encryption, access controls, and segmentation.
      duration_estimate: "90 min"
      commands:
        - purpose: "Find encryption implementations"
          command: "grep -r -E '(encrypt|AES|RSA|bcrypt)' --include='*.py' --include='*.ts' ."
      expected_findings:
        - "Privacy architecture assessment"
        - "Technical controls inventory"

    - id: "3"
      name: "Check privacy defaults"
      description: |
        Verify that default configurations are privacy-protective.
        Assess settings for tracking, sharing, and data collection.
      duration_estimate: "45 min"
      commands:
        - purpose: "Find default configurations"
          command: "grep -r -E '(default|initial).*=' --include='*.yaml' --include='*.json' ."
      expected_findings:
        - "Default configuration assessment"
        - "Privacy-invasive defaults identified"

    - id: "4"
      name: "Review privacy-enhancing technologies"
      description: |
        Evaluate implementation of privacy-enhancing technologies
        including anonymization, pseudonymization, and differential privacy.
      duration_estimate: "45 min"
      expected_findings:
        - "PET implementation inventory"
        - "Opportunities for additional PETs"

    - id: "5"
      name: "Assess transparency mechanisms"
      description: |
        Review how privacy practices are communicated to users
        including privacy policies, notices, and transparency reports.
      duration_estimate: "30 min"
      expected_findings:
        - "Transparency assessment"
        - "Communication gaps"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "pbd_assessment"
      format: "structured"
      sections:
        - "SDLC Integration"
        - "Architecture Assessment"
        - "Default Configuration Review"
        - "PET Implementation"
        - "Transparency Evaluation"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "PbD Maturity Assessment"
        - "Key Findings"
        - "Recommendations"

  confidence_guidance:
    high: "Full architecture and process review completed"
    medium: "Key areas evaluated with some gaps"
    low: "Limited access to documentation or systems"

offline:
  capability: "full"

  cache_manifest:
    knowledge:
      - source_id: "gdpr-art25"
        priority: "required"
      - source_id: "pbd-principles"
        priority: "required"

profiles:
  membership:
    quick:
      included: false
      reason: "Requires comprehensive architecture review"
    full:
      included: true
      priority: 1

closeout_checklist:
  - id: "pbd-001"
    item: "Privacy integrated into development lifecycle"
    level: "CRITICAL"
    verification: "manual"
    verification_notes: "Privacy requirements in SDLC documented"
    expected: "Confirmed by reviewer"

  - id: "pbd-002"
    item: "Personal data encrypted at rest"
    level: "CRITICAL"
    verification: "grep -r -E '(encrypt|AES|RSA).*database\\|storage' --include='*.py' --include='*.ts' . | wc -l | xargs -I{} test {} -gt 0 && echo PASS || echo FAIL"
    expected: "PASS"

  - id: "pbd-003"
    item: "Privacy-protective defaults configured"
    level: "BLOCKING"
    verification: "manual"
    verification_notes: "Default settings favor privacy protection"
    expected: "Confirmed by reviewer"

governance:
  applicable_to:
    archetypes: ["all"]

  compliance_frameworks:
    - framework: "GDPR"
      controls: ["Article 25"]
    - framework: "ISO 27701"
      controls: ["7.2.5", "7.4"]

relationships:
  commonly_combined:
    - "ethical-societal.privacy-data-ethics.data-minimization"
    - "ethical-societal.privacy-data-ethics.anonymization-effectiveness"
