audit:
  id: ethical-societal.security-safety-ethics.misinformation-prevention
  name: Misinformation Prevention
  version: 1.0.0
  last_updated: '2026-01-19'
  status: active
  category: ethical-societal
  category_number: 18
  subcategory: security-safety-ethics
  tier: phd
  estimated_duration: 5-7 hours  # median: 6h
  completeness: complete
  requires_runtime: false
  destructive: false
execution:
  automatable: partial
  severity: high
  scope: organizational
  default_profiles:
  - full
  blocks_phase: false
  parallelizable: true
description:
  what: |
    Examines systems and processes for addressing misinformation
    and disinformation, assessing:
    - Misinformation policy definitions and scope
    - Fact-checking partnerships and processes
    - Content labeling and warning systems
    - Algorithmic amplification controls
    - User reporting for misinformation
    - Authoritative source surfacing
    - Election and health misinformation handling
    - Coordinated inauthentic behavior detection
    - Transparency reporting on misinformation
  why_it_matters: |
    Misinformation causes significant societal harm and creates
    platform liability:
    - Health misinformation can lead to deaths (vaccine, COVID)
    - Election misinformation threatens democratic processes
    - Platforms face increasing regulatory pressure globally
    - Algorithmic amplification accelerates misinformation spread
    - Users lose trust when platforms spread false information
    - DSA requires addressing systemic risks including misinformation
    - Inaction creates legal and reputational exposure

    Effective misinformation response protects users and society
    while maintaining platform credibility.
  when_to_run:
  - When launching news feed or content distribution features
  - Before major elections or health emergencies
  - During platform risk assessments
  - When misinformation complaints increase
prerequisites:
  required_artifacts:
  - type: misinformation_policy
    description: Misinformation and disinformation policies
  - type: content_distribution_system
    description: Algorithmic content distribution documentation
  access_requirements:
  - Misinformation policies
  - Content moderation procedures
  - Fact-checking partnership documentation
  - Algorithm and ranking documentation
discovery:
  code_patterns:
  - pattern: fact.?check|misinfo|disinfo|false.?info
    type: regex
    scope: source
    purpose: Identify misinformation handling code
  - pattern: label|warning|interstitial
    type: regex
    scope: source
    purpose: Find content labeling systems
  - pattern: authoritative|trusted|verified
    type: regex
    scope: source
    purpose: Locate authoritative source handling
  file_patterns:
  - glob: '**/fact-check*.{js,ts,py}'
    purpose: Fact-checking integration code
  - glob: '**/label*.{js,ts,py}'
    purpose: Content labeling code
  - glob: '**/misinformation/**'
    purpose: Misinformation handling systems
  documents_to_review:
  - type: Misinformation policy
    purpose: Review definitions and rules
  - type: Fact-checking procedures
    purpose: Assess verification process
  - type: Content labeling guidelines
    purpose: Review warning system design
  - type: Algorithm documentation
    purpose: Assess amplification controls
  - type: Transparency reports
    purpose: Review misinformation metrics
  interviews:
  - role: Trust & Safety team
    questions:
    - How is misinformation defined and categorized?
    - What fact-checking processes exist?
    - How are labels and warnings applied?
    purpose: Understand misinformation response
  - role: Algorithm/ML team
    questions:
    - How does the algorithm handle flagged misinformation?
    - Are authoritative sources boosted?
    - What demotion mechanisms exist?
    purpose: Assess algorithmic controls
  - role: Policy team
    questions:
    - How are election/health topics specially handled?
    - What partnerships exist with fact-checkers?
    - How is coordinated inauthentic behavior addressed?
    purpose: Review special topic handling
knowledge_sources:
  specifications:
  - id: cisa-ai-security
    name: CISA Guidelines for Secure AI System Development
    url: https://www.cisa.gov/resources-tools/resources/guidelines-secure-ai-system-development
    offline_cache: true
    priority: recommended
  - id: dsa-systemic-risk
    name: DSA - Systemic Risks and Mitigation
    url: https://digital-strategy.ec.europa.eu/en/policies/digital-services-act-package
    offline_cache: true
    priority: required
  guides:
  - id: ifcn-code
    name: IFCN Code of Principles
    url: https://www.ifcncodeofprinciples.poynter.org/
    offline_cache: true
  - id: election-integrity
    name: Election Integrity Best Practices
    url: https://www.cisa.gov/election-security
    offline_cache: true
  papers:
  - id: misinfo-research
    title: The Science of Misinformation
    url: https://www.science.org/
  learning_resources:
  - id: misinfo-response
    title: Responding to Misinformation at Scale
    type: course
    reference: Trust & Safety Professional Association
tooling:
  assessment_tools:
  - tool: Misinformation Policy Checklist
    purpose: Evaluate policy completeness
  - tool: Labeling System Audit
    purpose: Assess warning effectiveness
  - tool: Algorithm Impact Assessment
    purpose: Evaluate amplification controls
  scripts:
  - id: find-misinfo-code
    language: bash
    purpose: Locate misinformation handling code
    source: inline
    code: |
      #!/bin/bash
      # Find misinformation-related code
      grep -r -i "fact.?check\|misinfo\|disinfo\|false.?claim" \
        --include="*.js" --include="*.ts" --include="*.py" \
        . 2>/dev/null | grep -v "node_modules" | head -50
signals:
  critical:
  - id: MISINFO-CRIT-001
    signal: No misinformation policy or handling process
    evidence_indicators:
    - No misinformation definition in policies
    - No fact-checking or verification process
    - No response to reported misinformation
    explanation: |
      Without any misinformation response, platforms amplify
      false information causing user and societal harm.
    remediation: Develop comprehensive misinformation policy and response process
  - id: MISINFO-CRIT-002
    signal: Algorithm actively amplifies misinformation
    evidence_indicators:
    - No demotion for flagged content
    - Engagement-only ranking promotes sensationalism
    - No authoritative source boosting
    explanation: |
      Algorithmic amplification of misinformation accelerates
      its spread and harm, creating platform liability.
    remediation: Implement algorithmic controls to reduce misinformation spread
  high:
  - id: MISINFO-HIGH-001
    signal: No content labeling or warning system
    explanation: |
      Labels and warnings help users critically evaluate
      content without removal, preserving expression while
      reducing harm.
    remediation: Implement content labeling system for disputed or false claims
  - id: MISINFO-HIGH-002
    signal: No special handling for election misinformation
    explanation: |
      Election misinformation threatens democratic processes
      and requires specialized, rapid response.
    remediation: Develop election-specific misinformation policies and rapid response
  - id: MISINFO-HIGH-003
    signal: No fact-checking partnerships or processes
    explanation: |
      Fact-checking provides credible third-party verification
      that enables defensible content decisions.
    remediation: Partner with IFCN-certified fact-checkers or develop internal verification
  medium:
  - id: MISINFO-MED-001
    signal: Coordinated inauthentic behavior not addressed
    remediation: Implement detection for coordinated manipulation campaigns
  - id: MISINFO-MED-002
    signal: No transparency reporting on misinformation actions
    remediation: Publish regular reports on misinformation enforcement
  - id: MISINFO-MED-003
    signal: Authoritative sources not surfaced in search/feed
    remediation: Boost authoritative sources for topics prone to misinformation
  low:
  - id: MISINFO-LOW-001
    signal: No media literacy resources for users
  positive:
  - id: MISINFO-POS-001
    signal: Comprehensive misinformation policy with clear definitions
  - id: MISINFO-POS-002
    signal: IFCN-certified fact-checking partnerships
  - id: MISINFO-POS-003
    signal: Algorithmic demotion of flagged misinformation
  - id: MISINFO-POS-004
    signal: Content labeling with links to authoritative sources
procedure:
  context:
    cognitive_mode: critical
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Policy Assessment
    description: |
      Review misinformation policies for clarity, completeness,
      and appropriate scope.
    duration_estimate: 60 min
    questions:
    - How is misinformation defined?
    - What categories are addressed (health, election, etc.)?
    - What enforcement actions are specified?
    expected_findings:
    - Policy clarity assessment
    - Category coverage
    - Enforcement framework
  - id: '2'
    name: Verification Process Review
    description: |
      Assess fact-checking and verification processes
      for determining content accuracy.
    duration_estimate: 60 min
    questions:
    - What fact-checking partnerships exist?
    - How is content verified internally?
    - What is the verification timeline?
    expected_findings:
    - Fact-checking process assessment
    - Verification capabilities
    - Response time evaluation
  - id: '3'
    name: Labeling and Warning System Review
    description: |
      Evaluate content labeling and warning mechanisms
      for effectiveness and user comprehension.
    duration_estimate: 45 min
    commands:
    - purpose: Find labeling code
      command: grep -r -i 'label\|warning\|disputed' --include='*.{js,ts,tsx}' . | head -30
    questions:
    - What labels or warnings are used?
    - How visible are warnings to users?
    - What happens when users click through?
    expected_findings:
    - Label system inventory
    - Visibility assessment
    - Click-through behavior
  - id: '4'
    name: Algorithmic Controls Assessment
    description: |
      Review how algorithms handle flagged misinformation
      and surface authoritative sources.
    duration_estimate: 60 min
    questions:
    - How does the algorithm treat flagged content?
    - Are authoritative sources boosted?
    - What demotion mechanisms exist?
    expected_findings:
    - Algorithmic treatment of flagged content
    - Source authority handling
    - Amplification controls
  - id: '5'
    name: Special Topics Review
    description: |
      Assess handling of high-stakes misinformation topics
      like elections and health.
    duration_estimate: 45 min
    questions:
    - What special election policies exist?
    - How is health misinformation prioritized?
    - What rapid response capabilities exist?
    expected_findings:
    - Election misinformation handling
    - Health misinformation response
    - Rapid response capabilities
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Policy Assessment
    - Verification Process
    - Labeling System Review
    - Algorithmic Controls
    - Special Topics Handling
    - Recommendations
  confidence_guidance:
    high: Full policy review, system access, and metrics analysis
    medium: Policy review with some system documentation
    low: External policy review only
offline:
  capability: full
  cache_manifest:
    knowledge:
    - source_id: dsa-systemic-risk
      priority: required
    - source_id: ifcn-code
      priority: recommended
profiles:
  membership:
    quick:
      included: false
      reason: Requires comprehensive policy and system review
    full:
      included: true
      priority: 1
closeout_checklist:
- id: misinfo-001
  item: Misinformation policy reviewed
  level: CRITICAL
  verification: manual
  verification_notes: Confirm policy assessment complete
  expected: Confirmed by reviewer
- id: misinfo-002
  item: Verification process assessed
  level: CRITICAL
  verification: manual
  verification_notes: Verify fact-checking process reviewed
  expected: Confirmed by reviewer
- id: misinfo-003
  item: Algorithmic controls evaluated
  level: BLOCKING
  verification: manual
  verification_notes: Confirm amplification controls reviewed
  expected: Confirmed by reviewer
governance:
  applicable_to:
    archetypes:
    - platform
    - social-media
    - news-aggregator
    - search-engine
  compliance_frameworks:
  - framework: DSA
    controls:
    - Art-34
    - Art-35
    - systemic-risk-mitigation
  - framework: EU Code of Practice on Disinformation
    controls:
    - all-commitments
relationships:
  commonly_combined:
  - ethical-societal.transparency-trust.content-moderation-transparency
  - ethical-societal.transparency-trust.algorithm-disclosure
  - ethical-societal.security-safety-ethics.harassment-prevention
