audit:
  id: ethical-societal.transparency-trust.algorithm-disclosure
  name: Algorithm Disclosure
  version: 1.0.0
  last_updated: '2026-01-19'
  status: active
  category: ethical-societal
  category_number: 18
  subcategory: transparency-trust
  tier: phd
  estimated_duration: 4-6 hours  # median: 5h
  completeness: complete
  requires_runtime: false
  destructive: false
execution:
  automatable: manual
  severity: high
  scope: qualitative
  default_profiles:
  - full
  blocks_phase: false
  parallelizable: true
description:
  what: |
    Examines transparency around algorithmic systems that affect
    user experience, assessing:
    - Disclosure of AI/ML system presence and purpose
    - Explanation of recommendation/ranking algorithms
    - Automated decision-making transparency
    - Personalization and profiling disclosure
    - Algorithm impact on content visibility
    - User control over algorithmic preferences
    - Explanation of algorithmic outcomes
    - Right to human review disclosure
  why_it_matters: |
    Algorithmic transparency is increasingly a regulatory and ethical
    imperative:
    - GDPR Article 22 requires disclosure of automated decision-making
    - EU AI Act mandates transparency for high-risk AI systems
    - DSA requires disclosure of recommendation systems
    - Users cannot contest unfair algorithmic decisions they don't understand
    - Hidden algorithmic manipulation erodes trust
    - Algorithmic bias cannot be addressed without transparency
    - Platform accountability requires algorithmic visibility

    Transparent algorithm disclosure empowers users and demonstrates
    responsible AI/ML deployment.
  when_to_run:
  - When deploying new algorithmic systems
  - During AI ethics reviews
  - Before launching in EU markets (AI Act, DSA)
  - When auditing recommendation systems
prerequisites:
  required_artifacts:
  - type: algorithm_documentation
    description: Documentation of algorithmic systems in use
  - type: user_facing_disclosures
    description: Current algorithm-related user communications
  access_requirements:
  - Technical documentation of algorithmic systems
  - Product UX showing algorithm-affected features
  - Legal/compliance documentation on AI disclosure
discovery:
  code_patterns:
  - pattern: recommend|suggest|personalize|rank
    type: regex
    scope: source
    purpose: Identify recommendation/personalization systems
  - pattern: ml|machine.?learning|ai|model|predict
    type: regex
    scope: source
    purpose: Find ML/AI implementations
  - pattern: automat|decision|score|classify
    type: regex
    scope: source
    purpose: Identify automated decision systems
  file_patterns:
  - glob: '**/models/**'
    purpose: ML model files
  - glob: '**/ml/**'
    purpose: Machine learning code
  - glob: '**/recommendations/**'
    purpose: Recommendation system code
  documents_to_review:
  - type: AI/ML documentation
    purpose: Understand algorithmic systems
  - type: Product documentation
    purpose: Review user-facing algorithm explanations
  - type: Privacy policy
    purpose: Check for profiling/automated decision disclosures
  - type: Terms of service
    purpose: Review algorithmic system terms
  interviews:
  - role: ML/AI team
    questions:
    - What algorithmic systems affect user experience?
    - How do recommendation systems work at a high level?
    - What automated decisions are made about users?
    purpose: Map algorithmic systems
  - role: Product team
    questions:
    - How are algorithmic features explained to users?
    - Can users control algorithmic preferences?
    - How are algorithmic outcomes explained?
    purpose: Assess user-facing transparency
  - role: Legal/Compliance
    questions:
    - What regulatory requirements apply to algorithms?
    - How is automated decision-making disclosed?
    - Is GDPR Article 22 compliance addressed?
    purpose: Understand compliance approach
knowledge_sources:
  specifications:
  - id: gdpr-art22
    name: GDPR Article 22 - Automated Decision-Making
    url: https://gdpr-info.eu/art-22-gdpr/
    offline_cache: true
    priority: required
  - id: eu-ai-act
    name: EU AI Act
    url: https://artificialintelligenceact.eu/
    offline_cache: true
    priority: required
  - id: dsa-algorithms
    name: Digital Services Act - Recommender Systems
    url: https://digital-strategy.ec.europa.eu/en/policies/digital-services-act-package
    offline_cache: true
    priority: required
  guides:
  - id: algo-transparency-guide
    name: Algorithm Transparency Best Practices
    url: https://ainowinstitute.org/
    offline_cache: true
  - id: explainable-ai
    name: NIST Explainable AI Guidelines
    url: https://www.nist.gov/artificial-intelligence
    offline_cache: true
  papers:
  - id: algorithmic-accountability
    title: 'Algorithmic Accountability: A Primer'
    url: https://datasociety.net/library/algorithmic-accountability-a-primer/
tooling:
  assessment_tools:
  - tool: Algorithm Inventory Template
    purpose: Document all algorithmic systems
  - tool: Disclosure Checklist
    purpose: Assess disclosure completeness
  scripts:
  - id: find-ml-code
    language: bash
    purpose: Locate ML/AI related code
    source: inline
    code: |
      #!/bin/bash
      # Find ML/AI related code patterns
      grep -r -i "model\|predict\|recommend\|tensorflow\|pytorch\|sklearn" \
        --include="*.py" --include="*.js" --include="*.ts" \
        . 2>/dev/null | head -50
signals:
  critical:
  - id: ALGO-CRIT-001
    signal: Automated decisions affecting rights without disclosure
    evidence_indicators:
    - Credit/lending decisions without explanation
    - Access denials without reason
    - Automated moderation without transparency
    explanation: |
      GDPR Article 22 requires disclosure of automated decision-making
      that significantly affects individuals, with right to human review.
    remediation: Disclose automated decisions, provide explanations, and offer human review
  - id: ALGO-CRIT-002
    signal: AI system used without any user notification
    evidence_indicators:
    - Hidden AI chatbots pretending to be human
    - AI-generated content presented as human-created
    - Undisclosed AI in hiring/screening
    explanation: |
      Users have a right to know when interacting with AI systems;
      hidden AI may violate consumer protection and AI regulations.
    remediation: Clearly disclose AI system presence and nature
  high:
  - id: ALGO-HIGH-001
    signal: Recommendation algorithm unexplained to users
    explanation: |
      DSA requires platforms to disclose how recommendation systems
      work and allow users to modify their parameters.
    remediation: Explain recommendation logic and provide user controls
  - id: ALGO-HIGH-002
    signal: No user control over algorithmic personalization
    explanation: |
      Users should be able to influence how algorithms affect their
      experience, including opting out of personalization.
    remediation: Provide settings to control algorithmic personalization
  - id: ALGO-HIGH-003
    signal: Profiling without clear disclosure
    explanation: |
      GDPR requires disclosure of profiling activities and their
      consequences for the data subject.
    remediation: Clearly disclose profiling activities and their effects
  medium:
  - id: ALGO-MED-001
    signal: Algorithm explanations too technical for average user
    remediation: Provide plain language explanations of algorithmic systems
  - id: ALGO-MED-002
    signal: No explanation for specific algorithmic outcomes
    remediation: Provide individual outcome explanations when requested
  - id: ALGO-MED-003
    signal: Algorithm documentation exists but not user-accessible
    remediation: Make algorithm documentation available to users
  low:
  - id: ALGO-LOW-001
    signal: No visual indication of algorithmic content curation
  positive:
  - id: ALGO-POS-001
    signal: Clear, accessible algorithm explanations provided
  - id: ALGO-POS-002
    signal: User controls for algorithmic preferences available
  - id: ALGO-POS-003
    signal: Individual decision explanations available on request
procedure:
  context:
    cognitive_mode: critical
    ensemble_role: auditor
  steps:
  - id: '1'
    name: Algorithm Inventory
    description: |
      Map all algorithmic systems that affect user experience
      or make decisions about users.
    duration_estimate: 60 min
    commands:
    - purpose: Find ML-related code
      command: find . -type f -name '*.py' | xargs grep -l -i 'model\|predict\|sklearn\|tensorflow' 2>/dev/null
        | head -20
    questions:
    - What AI/ML systems are deployed?
    - What recommendation algorithms exist?
    - What automated decisions affect users?
    expected_findings:
    - Complete algorithm inventory
    - Decision system mapping
    - User impact assessment
  - id: '2'
    name: User-Facing Disclosure Review
    description: |
      Evaluate how algorithmic systems are explained
      to users in product and documentation.
    duration_estimate: 45 min
    questions:
    - Where are algorithms disclosed to users?
    - How clearly are algorithmic effects explained?
    - Can users understand the explanations?
    expected_findings:
    - Disclosure inventory
    - Clarity assessment
    - Comprehensibility evaluation
  - id: '3'
    name: Automated Decision Assessment
    description: |
      Review automated decision-making systems for
      GDPR Article 22 compliance.
    duration_estimate: 45 min
    questions:
    - What decisions are fully automated?
    - Do automated decisions significantly affect users?
    - Is there a path to human review?
    expected_findings:
    - Automated decision inventory
    - Impact assessment
    - Human review process status
  - id: '4'
    name: User Control Evaluation
    description: |
      Assess user controls over algorithmic personalization
      and recommendations.
    duration_estimate: 30 min
    questions:
    - Can users control recommendation preferences?
    - Can users opt out of personalization?
    - Can users request algorithm-free experience?
    expected_findings:
    - User control inventory
    - Opt-out availability
    - Control accessibility
  - id: '5'
    name: Regulatory Compliance Check
    description: |
      Verify compliance with applicable algorithm transparency
      regulations (GDPR, AI Act, DSA).
    duration_estimate: 45 min
    questions:
    - Are GDPR Article 22 requirements met?
    - Is DSA recommender system disclosure adequate?
    - Are AI Act transparency requirements addressed?
    expected_findings:
    - Regulatory compliance status
    - Gap identification
    - Remediation needs
output:
  deliverables:
  - type: finding_list
    format: structured
  - type: summary
    format: prose
    sections:
    - Executive Summary
    - Algorithm Inventory
    - Disclosure Assessment
    - User Control Evaluation
    - Regulatory Compliance
    - Recommendations
  confidence_guidance:
    high: Complete algorithm mapping, disclosure review, compliance verification
    medium: Partial algorithm inventory with disclosure review
    low: External product review without internal documentation
offline:
  capability: partial
  cache_manifest:
    knowledge:
    - source_id: gdpr-art22
      priority: required
    - source_id: eu-ai-act
      priority: required
    - source_id: dsa-algorithms
      priority: required
profiles:
  membership:
    quick:
      included: false
      reason: Requires comprehensive algorithm review
    full:
      included: true
      priority: 1
closeout_checklist:
- id: algo-001
  item: Algorithm inventory completed
  level: CRITICAL
  verification: manual
  verification_notes: Confirm all algorithmic systems documented
  expected: Confirmed by reviewer
- id: algo-002
  item: User disclosures reviewed
  level: CRITICAL
  verification: manual
  verification_notes: Verify disclosure completeness assessed
  expected: Confirmed by reviewer
- id: algo-003
  item: Automated decision compliance checked
  level: BLOCKING
  verification: manual
  verification_notes: Confirm GDPR Article 22 assessment
  expected: Confirmed by reviewer
governance:
  applicable_to:
    archetypes:
    - platform
    - saas
    - consumer-app
    - ai-service
  compliance_frameworks:
  - framework: GDPR
    controls:
    - Art-22
    - Art-13
    - Art-14
  - framework: EU AI Act
    controls:
    - transparency-obligations
  - framework: Digital Services Act
    controls:
    - recommender-system-transparency
relationships:
  commonly_combined:
  - ethical-societal.ai-ethics.bias-assessment
  - ethical-societal.transparency-trust.data-practice-transparency
  - compliance.ai.ai-act-compliance
