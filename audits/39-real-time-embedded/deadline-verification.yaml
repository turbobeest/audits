# ============================================================
# AUDIT: Deadline Verification
# Category: 39 - Real-Time & Embedded Systems
# Subcategory: timing-analysis
# ============================================================

audit:
  id: "real-time-embedded.timing-analysis.deadline-verification"
  name: "Deadline Verification Audit"
  version: "1.0.0"
  last_updated: "2025-01-22"
  status: "active"

  category: "real-time-embedded"
  category_number: 39
  subcategory: "timing-analysis"

  tier: "expert"
  estimated_duration: "4-8 hours"  # median: 6h

  completeness: "requires_discovery"
  requires_runtime: true
  destructive: false

execution:
  automatable: "partial"
  severity: "critical"
  scope: "embedded-systems"

  default_profiles:
    - "full"
    - "quick"

  blocks_phase: false
  parallelizable: true

description:
  what: |
    Verifies that all real-time tasks meet their deadline requirements under
    all operating conditions. Examines schedulability analysis methods including
    Rate Monotonic Analysis (RMA), Earliest Deadline First (EDF), and response
    time analysis. Validates deadline guarantees against worst-case scenarios
    including interrupt interference, blocking, and resource contention.

  why_it_matters: |
    Deadline verification proves system correctness before deployment. Missing
    deadlines in hard real-time systems causes safety failures - aircraft
    control surfaces not responding, airbag deployment delays, or pacemaker
    timing errors. Formal verification methods provide mathematical guarantees
    required for safety certification under DO-178C and ISO 26262.

  when_to_run:
    - "After task set changes"
    - "Before safety certification"
    - "When modifying priorities"
    - "After adding new functionality"
    - "During system integration"

prerequisites:
  required_artifacts:
    - type: "task_specifications"
      description: "Complete task set with periods, deadlines, and priorities"
    - type: "wcet_results"
      description: "WCET analysis results for all tasks"
    - type: "resource_usage"
      description: "Shared resource and mutex documentation"
    - type: "interrupt_specs"
      description: "Interrupt handlers and their timing"

  access_requirements:
    - "Access to system design documents"
    - "Access to schedulability analysis tools"
    - "Runtime tracing capability"
    - "Hardware test environment"

discovery:
  file_patterns:
    - glob: "**/tasks.c"
      purpose: "Find task definitions"
    - glob: "**/FreeRTOSConfig.h"
      purpose: "Find RTOS configuration"
    - glob: "**/scheduler*.c"
      purpose: "Find scheduler implementation"
    - glob: "**/priorities.h"
      purpose: "Find priority definitions"
    - glob: "**/timing_spec*.yaml"
      purpose: "Find timing specifications"

knowledge_sources:
  guides:
    - id: "rma-tutorial"
      name: "Rate Monotonic Analysis Tutorial"
      url: "https://www.sei.cmu.edu/reports/93tr023.pdf"
    - id: "response-time-analysis"
      name: "Response Time Analysis Guide"
      url: "https://www.cs.york.ac.uk/rts/books/RtsBook.html"

  standards:
    - id: "do-178c"
      name: "DO-178C Software Considerations"
      relevance: "Aviation deadline requirements"
    - id: "iso-26262"
      name: "ISO 26262 Functional Safety"
      relevance: "Automotive timing constraints"
    - id: "autosar"
      name: "AUTOSAR Timing Extensions"
      relevance: "Automotive timing specification"

tooling:
  analysis_tools:
    - tool: "cheddar"
      purpose: "Real-time scheduling analyzer"
    - tool: "mast"
      purpose: "Modeling and Analysis Suite"
    - tool: "times"
      purpose: "Tool for timing analysis"
    - tool: "symta-s"
      purpose: "System-level timing analysis"

signals:
  critical:
    - id: "DL-CRIT-001"
      signal: "Hard deadline miss detected in safety-critical task"
      evidence_indicators:
        - "Response time exceeds deadline"
        - "Negative schedulability slack"
        - "Deadline overrun in testing"
      explanation: |
        Hard deadline misses in safety-critical systems violate fundamental
        timing contracts. The system cannot be certified as safe until all
        deadlines are guaranteed to be met under worst-case conditions.
      remediation: "Redesign task structure, reduce WCET, or increase deadline"

    - id: "DL-CRIT-002"
      signal: "System not schedulable under worst-case analysis"
      evidence_indicators:
        - "CPU utilization exceeds bound"
        - "Response time analysis fails"
        - "Blocking time excessive"
      explanation: |
        Schedulability analysis proves deadline compliance is impossible.
        The current task configuration cannot guarantee all deadlines.
      remediation: "Reduce utilization, optimize tasks, or use different scheduling"

  high:
    - id: "DL-HIGH-001"
      signal: "Insufficient deadline margin in critical tasks"
      evidence_indicators:
        - "Response time within 10% of deadline"
        - "No safety margin for timing variations"
        - "Tight slack conditions"
      explanation: |
        Minimal margin leaves no room for timing variations, jitter, or
        unexpected delays. Small changes could cause deadline misses.
      remediation: "Increase margin through optimization or deadline adjustment"

    - id: "DL-HIGH-002"
      signal: "Blocking analysis incomplete or missing"
      evidence_indicators:
        - "Shared resources not analyzed"
        - "Mutex blocking time unknown"
        - "Priority inversion not considered"
      explanation: |
        Without blocking analysis, response time calculations are incomplete
        and may underestimate actual worst-case response times.
      remediation: "Complete blocking analysis for all shared resources"

  medium:
    - id: "DL-MED-001"
      signal: "Soft deadline violations in non-critical tasks"
      evidence_indicators:
        - "Occasional deadline misses observed"
        - "Quality of service degradation"
        - "User experience impact"
      explanation: |
        While not safety-critical, soft deadline misses affect system
        quality and may indicate underlying timing problems.
      remediation: "Optimize task or adjust priority to reduce misses"

    - id: "DL-MED-002"
      signal: "Interrupt interference not fully characterized"
      evidence_indicators:
        - "ISR overhead not included in analysis"
        - "Interrupt frequency assumptions missing"
        - "Nested interrupt impact unclear"
      explanation: |
        Interrupt interference can significantly extend response times.
        Complete analysis must account for worst-case interrupt load.
      remediation: "Include interrupt overhead in response time analysis"

  low:
    - id: "DL-LOW-001"
      signal: "Deadline specifications inconsistent with code"
      evidence_indicators:
        - "Documentation deadline differs from implementation"
        - "Timing requirements not traceable"
        - "Specification gaps"
      explanation: |
        Inconsistencies between specifications and implementation make
        verification difficult and increase risk of errors.
      remediation: "Align specifications with implementation"

  positive:
    - id: "DL-POS-001"
      signal: "All deadlines verified with adequate margin"
      evidence_indicators:
        - "Response times under 80% of deadlines"
        - "Complete schedulability analysis"
        - "Runtime validation confirms analysis"

    - id: "DL-POS-002"
      signal: "Formal deadline proofs documented"
      evidence_indicators:
        - "Mathematical schedulability proof"
        - "Complete analysis chain"
        - "Traceable to requirements"

procedure:
  context:
    cognitive_mode: "analytical"
    ensemble_role: "auditor"

  steps:
    - id: "1"
      name: "Collect Task Timing Parameters"
      description: "Gather periods, deadlines, priorities, and WCETs for all tasks"
      duration_estimate: "1 hour"

    - id: "2"
      name: "Perform Utilization Analysis"
      description: "Calculate system utilization and compare to schedulability bounds"
      duration_estimate: "30 minutes"

    - id: "3"
      name: "Conduct Response Time Analysis"
      description: "Calculate worst-case response time for each task"
      duration_estimate: "2 hours"

    - id: "4"
      name: "Analyze Blocking and Interference"
      description: "Include shared resource blocking and interrupt interference"
      duration_estimate: "1-2 hours"

    - id: "5"
      name: "Validate with Runtime Measurements"
      description: "Compare analysis results against actual runtime behavior"
      duration_estimate: "2 hours"

    - id: "6"
      name: "Document Verification Results"
      description: "Create traceable verification evidence"
      duration_estimate: "1 hour"

output:
  deliverables:
    - type: "finding_list"
      format: "structured"

    - type: "summary"
      format: "prose"
      sections:
        - "Executive Summary"
        - "Task Set Analysis"
        - "Schedulability Results"
        - "Response Time Analysis"
        - "Recommendations"

closeout_checklist:
  - id: "dl-001"
    item: "All task timing parameters collected"
    level: "CRITICAL"
    verification: "manual"
  - id: "dl-002"
    item: "Schedulability analysis completed"
    level: "CRITICAL"
    verification: "automated"
  - id: "dl-003"
    item: "Blocking analysis included"
    level: "HIGH"
    verification: "manual"
  - id: "dl-004"
    item: "Results validated with runtime tests"
    level: "HIGH"
    verification: "manual"

governance:
  applicable_to:
    archetypes: ["embedded-systems", "safety-critical", "automotive", "avionics"]

  compliance_mappings:
    - framework: "DO-178C"
      control: "6.3.4"
      description: "Timing analysis requirements"
    - framework: "ISO 26262"
      control: "Part 6, 7.4"
      description: "Software timing verification"
    - framework: "AUTOSAR"
      control: "TIMEX"
      description: "Timing extensions specification"

relationships:
  commonly_combined:
    - "real-time-embedded.timing-analysis.wcet-analysis"
    - "real-time-embedded.rtos-configuration.task-priority-analysis"
  depends_on:
    - "real-time-embedded.timing-analysis.wcet-analysis"
    - "real-time-embedded.rtos-configuration.scheduler-configuration"
  feeds_into:
    - "safety.functional-safety-analysis"
    - "certification.safety-certification"

# Glossary of domain-specific terms:
glossary:
  "WCET": "Worst-Case Execution Time - maximum possible execution time for a code path"
  "ISR": "Interrupt Service Routine - function executed in response to hardware interrupt"
  "jitter": "Variation in timing between expected and actual execution"
